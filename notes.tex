% !TEX root = notes.tex
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Use the koma-script document style
\documentclass{scrbook}
\KOMAoptions{twoside=false} % disable two-side formatting for scrbook
% alternatively, for shorter essay, use the following
% \documentclass{scrartcl}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Useful packages
\usepackage{mathtools}
\usepackage{amssymb,bm,bbold}
\usepackage{enumerate}
\usepackage[margin=0.8in]{geometry}
\usepackage{soul}

\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\F}{\mathbb{F}}
\renewcommand{\mod}{\text{ mod }}
\newcommand{\TODO}{\textbf{[ TODO ]}}
\newcommand*{\qed}{\hfill\ensuremath{\square}}
\let\emptyset\varnothing
\newcommand{\liff}{\leftrightarrow}
\newcommand{\divides}{\mid}
\newcommand{\notdivides}{\nmid}
\renewcommand{\implies}{\rightarrow}
\renewcommand{\bar}{\overline}
\renewcommand{\to}{\rightarrow}
\newcommand{\nto}{\nrightarrow}
\renewcommand{\underline}{\ul}

\DeclareMathOperator{\diam}{diam}
\DeclareMathOperator{\spann}{span}
\DeclareMathOperator{\ran}{ran}
\DeclareMathOperator{\nullity}{null}
\DeclareMathOperator{\dimension}{dim}
\DeclarePairedDelimiter\ceil{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}

%--------------------------------------------------------------------
% Hyper ref
\usepackage[dvipsnames]{xcolor}
\usepackage{hyperref}
\usepackage{cleveref}

\newcommand\myshade{90}
\colorlet{mylinkcolor}{NavyBlue}
\colorlet{mycitecolor}{Aquamarine}
\colorlet{myurlcolor}{Aquamarine}

\hypersetup{
  linkcolor  = mylinkcolor!\myshade!black,
  citecolor  = mycitecolor!\myshade!black,
  urlcolor   = myurlcolor!\myshade!black,
  colorlinks = true,
}

%--------------------------------------------------------------------
% Bibliography
\usepackage[]{natbib}
\bibliographystyle{chicago}

%=================================
% pre-defined theorem environments
\usepackage{amsthm}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{proposition}{Proposition}
\newtheorem{corollary}{Corollary}
\newtheorem{definition}{Definition}
\newtheorem*{remark}{Remark}
\newtheorem*{assumption}{Assumption}
\renewcommand\qedsymbol{$\blacksquare$}

%=================================
% useful commands
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\supp}{supp}

\def\vec#1{{\ensuremath{\bm{{#1}}}}}
\def\mat#1{\vec{#1}}

%=================================
% convenient notations
\newcommand{\XX}{\mathbb{X}}
\newcommand{\RR}{\mathbb{R}}
\newcommand{\EE}{\mathbb{E}}
\newcommand{\PP}{\mathbb{P}}

\newcommand{\sL}{\mathcal{L}}
\newcommand{\sX}{\mathcal{X}}
\newcommand{\sY}{\mathcal{Y}}

\newcommand{\ind}{\mathbb{1}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Typography, change document font
\usepackage[tt=false, type1=true]{libertine}
\usepackage[varqu]{zi4}
\usepackage[libertine]{newtxmath}
\usepackage[T1]{fontenc}

\usepackage[protrusion=true,expansion=true]{microtype}

% Disable paragraph indentation, and increase gap
\usepackage{parskip}

\title{Baby Rudin}
\author{nathanl3}

\begin{document}
\maketitle

\tableofcontents

%\bibliography{bibfile}

\chapter{The Real and Complex Number Systems}

\section{Ordered Sets}
We realize, considering the solutions to $x^2 = 2$, that the set of rational numbers $\Q$ is incomplete. We start by defining some terms:
\begin{definition}
An \textbf{order} $<$ on $S$ is a relation such that 
\begin{enumerate}
\item If $x, y \in S$, then exactly one of $x < y$, $x = y$, or $x > y$ is true.
\item If $x, y, z \in S$ with $x < y$ and $y < z$, then $x < z$. 
\end{enumerate}

A set $S$ is \textbf{ordered} if it admits an order. For example, $\Q$ is an order if we take $x < y \iff y - x$ is positive. 

If $S$ is an ordered set and $E \subseteq S$, we call $\beta \in S$ an \textbf{upper bound} for $E$ if $\beta \ge x$ for all $x \in S$. If such a $\beta$ exists, we say $E$ is \textbf{bounded above} (by $\beta$). We define lower bounds similarly. 

If $S$ is an ordered set and $E \subseteq S$ is bounded above, and there exists $\alpha \in S$ such that $\alpha$ is an upper bound for $E$ and if $\gamma < \alpha$ then $\gamma$ is not an upper bound for $E$, then we call $\alpha$ a \textbf{least upper bound} for $E$. We write $\alpha = \sup E$.

Similarly, we can define a \textbf{greatest lower bound} for $E$, which we write $\alpha = \inf E$. 

An ordered set $S$ is said to have the \textbf{least upper bound property} if every non-empty subset $E \subseteq S$ which is bounded above admits a least upper bound. We define the \textbf{greatest lower bound property} similarly. The following theorem demonstrates that these properties are in fact equivalent for all ordered sets.
\end{definition}


\begin{theorem}
If $S$ is an ordered set with the least upper bound property, and $\emptyset \ne B \subseteq S$ is bounded below, then $\inf B \in S$. 
\begin{proof}
Let $L$ be the set of lower bounds for $B$ in $S$. Since $B$ is bounded below, $L$ is non-empty; and a subset of $S$ by definition. Since $S$ has the least upper bound property, there exists some $\alpha = \sup L \in S$. We claim that $\alpha = \inf B$ and in particular, $\inf B \in S$.

To show this, it suffices to show that $\alpha$ is a lower bound for $B$, and that if $\beta > \alpha$ in $S$, then $\beta$ is not a lower bound for $B$. If $\alpha$ were not a lower bound for $B$, there must be some $x \in B$ with $x < \alpha$. However this would imply that $x$ is an upper bound for $L$ and thus $\alpha \ge \beta$, a contradiction. 

If $\beta > \alpha$ and $\beta$ were a lower bound for $B$ (so $\beta \in L$), then since $\alpha = \sup L$, we would have $\beta \le \alpha$, a contradiction.

Thus, $\alpha = \inf B \in S$. In particular, since this holds for all non-empty $B \subseteq S$ bounded below, $S$ has the greatest lower bound property.
\end{proof}
\end{theorem}

\section{Fields}
On to defining the notion of fields!

\begin{definition}
A field $F$ is a set equipped with two operations, $+$ and $\times$ with the following properties:
\begin{itemize}
\item $F$ is a commutative group under addition, with additive identity $0$. We denote the additive inverse of $x$ to be $-x$.
\item $F \setminus \{0\}$ is a commutative group under multiplication, with additive identity $1$. We denote the multiplicative inverse of $x$ to be $1/x$. 
\item $x \times (y + z) = x \times z + y \times z$ for all $x, y, z \in F$. 
\end{itemize}
\end{definition}

\begin{proposition}
If $G$ is a group with operation $\cdot$, then for $x, y, z \in G$,
\begin{enumerate}[(a)]
\item $x \cdot y = x \cdot z \implies y = z$
\item $x \cdot y = x \implies y = 1$
\item $x \cdot y = 1 \implies y = x^{-1}$
\item $(x^{-1})^{-1} = x$
\end{enumerate}
\begin{proof}
Statement (a) follows from multiplying $x^{-1}$ to both sides. (b) follows by letting $z = 1$ in (a); (c) by taking $z = x^{-1}$; and (d) follows since $x^{-1} \cdot x = 1$ and by replacing $x$ with $x^{-1}$ in (c). 
\end{proof}
Notice that these properties can be applied both to the additive and multiplicative groups in a field $F$. 
\end{proposition}

In addition to the above group properties, the distributive law leads to the following properties of fields:

\begin{proposition}
In a field $F$, for any $x, y \in F$, we have
\begin{enumerate}[(a)]
\item $0 \times x = 0$.
\item If $x \ne 0$ and $y \ne 0$, then $x \times y \ne 0$.
\item $(-x) \times y = - (x \times y) = x \times (-y)$.
\item $(-x) \times (-y) = xy$.
\end{enumerate}

\begin{proof}
For (a), notice that since $0 + 0 = 0$, we have $0 \times x = (0 + 0) \times x = 0 \times x + 0 \times x$, and the result follows from Proposition 1(b) on the additive group.

For (b), notice that if $x \times y = 0$ in this case, multiplying both sides of the equality by $y^{-1}x^{-1}$ would produce $1 = 0$, a contradiction.

For (c), notice that $0 = (x + (-x)) \times y = x \times y + (-x) \times y$, and the rest follows from Proposition 1(c). The other side follows similarly.

Statement (d) follows from (c) with $-y$ in place of $y$ and using Proposition 1(d). 
\end{proof}
\end{proposition}

Now that we've sufficiently introduced ordered sets and fields, we wonder what would happen if we combined them...

\begin{definition}
An \textbf{ordered field} $F$ is a field which is also an ordered set, with the following properties for all $x, y, z \in F$:
\begin{enumerate}
\item $x + y < x + z$ if $y < z$.
\item $x \times y > 0$ if $x > 0$ and $y > 0$
\end{enumerate}

If $x > 0$, we say $x$ is \textbf{positive}, and we say $x$ is \textbf{negative} if $x < 0$. For example, $\Q$ is an ordered field with the regular notions of $+$, $\times$ and $<$. 
\end{definition}

The following properties hold for ordered fields:
\begin{proposition}
For $x, y, z \in F$ for some ordered field $F$, we have
\begin{enumerate}
\item If $x > 0$, then $-x < 0$.
\item If $x > 0$ and $y < z$ then $xy < xz$.
\item If $x < 0$ and $y < z$ then $xy > xz$.
\item If $x \ne 0$ then $x^2 > 0$. In particular, $1 > 0$.
\item If $0 < x < y$ then $0 < y^{-1} < x^{-1}$. 
\end{enumerate}
\begin{proof}
For (a), if $x > 0$, then $0 = x + (-x) > 0 + (-x) = -x$. The other direction follows similarly. 

For (b), notice that since $y < z$, we have $z - y > 0$ and thus $x (z - y) > 0$. Then, notice that $xz = x (z - y) + xy > xy$. 

For (c), notice that $-x > 0$ by (a) so $-(xy) = (-x)y < (-x)z = -(xz)$. The result follows by adding $xy + xz$ to both sides.

For (d), if $x > 0$, then $x^2 = xx > x \times 0 > 0$, otherwise $-x > 0$ and the argument is analogous since $(-x)^2 = -(-x^2) = x^2$. In particular, $1 = 1 \times 1 = 1^2 > 0$. 

For (e), notice that since $x > 0$, we must have $x^{-1} > 0$ otherwise $1 = x \times x^{-1} < 0$, contradicting (d). A similar argument holds for $y^{-1}$, and thus $x^{-1}y^{-1} > 0$. The result follows by multiplying the inequality by the positive value $x^{-1}y^{-1}$. 
\end{proof}
\end{proposition}

\section{The Real Field}
It is tempting to combine the definitions we have introduced so far: we can imagine some ordered field which has the least upper bound property, containing the rational numbers $\Q$. In fact, this is the familiar set of real numbers, $\R$, as shown in the following theorem:

\begin{theorem}[Existence (and construction) of $\R$]
There exists an ordered field $\R$ with the least upper bound property, and in fact, it contains $\Q$ as a subfield. Specifically, this means that $\Q \subseteq \R$, and that the field operations in $\R$ coincide with the field operations in $\Q$. 
\begin{proof}
This proof is presented in the Appendix.
\end{proof}
\end{theorem}

\begin{theorem}
From here, we can derive the following properties in $\R$:
\begin{enumerate}[(a)]
\item If $x, y \in \R$ and $x > 0$, then there is a positive integer $n$ such that $nx > y$. 
\item If $x < y$ in $\R$, there exists $q \in \Q$ with $x < q < y$.
\item For every $x > 0$ in $\R$, there exists one and only one positive $y \in \R$ such that $y^n = x$, for every positive integer $n$.
\item If $a, b > 0$ and $n > 0$, then $(ab)^{1/n} = a^{1/n} b^{1/n}$.
\end{enumerate}
\begin{proof}
For (a), let $A = \{nx: n \in \N\}$. If (a) were true, $A$ would be bounded above, and clearly non-empty, and thus admits a least upper bound $\alpha = \sup A$ in $\R$. However, $\alpha - x < \alpha$ is not an upper bound for $A$, so there exists some $\alpha - x < mx \le \alpha$ in $A$. But then $\alpha < (m + 1)x \in A$, a contradiction.

For (b), notice that $y - x > 0$ so from (a), there exists $n \in \N$ such that $n(y - x) > 1$. Apply (a) again to find $m_1 > nx$ and $m_2 > -nx$ so that $-m_2 < nx < m_1$. Thus, there exists $m \in \N$ such that $m - 1 \le nx < m$. Adding $n(y - x) > 1$ to both sides of $nx \ge m - 1$ yields $ny > m$ and so dividing both sides of $nx < m < ny$ by $n > 0$ yields the result.

For (c), notice first of all that the function $f(x) = x^n$ is monotonically increasing on the positive real numbers. To see this, factor
\[
	b^n - a^n = (b - a)(b^{n-1} + b^{n-2}a + \dotsb + b^2 a^{n-3} + ba^{n-2} + a^{n-1}) > n(b-a)a^{n-1} > 0
\]
and similarly we can show $b^n - a^n < n(b-a)b^{n-1}$. These inequalities will also be helpful later. The fact that $n$-th positive real roots are unique follows immediately from the fact that $x^n$ is strictly increasing. 

Let $A = \{y > 0: y^n < x\}$. Then, $A$ is bounded above by $\max(1, x)$ and contains $\frac{x}{1+x}$. Since $\R$ satisfies the least upper bound property, $\alpha = \sup A$ exists. We claim that $\alpha^n = x$. 

Suppose otherwise. If $\alpha^n < x$, then for
\[
	0 < t < \min\left(1, \frac{x-\alpha^n}{n(\alpha + 1)^{n-1}}\right), \text{ we have }(\alpha + t)^n - \alpha^n < nt(\alpha + t)^n < nt(\alpha + 1)^n < x - \alpha^n
\]
so $(\alpha + t)^n < x$, contradicting the fact that $\alpha$ is an upper bound for $A$. 

If $\alpha^n > x$, then for
\[
	0 < t = \min\left(1, \frac{\alpha^n - x}{n\alpha^{n - 1}}\right), \text{ we have } \alpha^n - (\alpha - t)^n < nt\alpha^{n-1} = \alpha^n - x
\]
so $(\alpha - t)^n > x > z^n$ for each $z \in A$, so in particular $\alpha - t$ is a smaller upper bound than $\alpha$ for $A$, contradicting the fact that $\alpha$ is the \textbf{least} upper bound for $A$. 

For (d), notice that $a^{1/n}b^{1/n} > 0$ since both terms are positive from (c), and that $(a^{1/n}b^{1/n})^n = ab$ since multiplication is commutative, so from (c), the $n$-th positive root is unique, $(ab)^{1/n} = a^{1/n}b^{1/n}$. 
\end{proof}
\end{theorem}

\begin{definition}
Let $x \in \R_{>0}$. Let $n_0$ be the largest integer such that $n_0 \le x$. Then, given $n_0, n_1, \dotsc, n_{k-1}$, let $n_k$ be the largest integer such that 
\[
	n_0 + \frac{n_1}{10} + \dotsb + \frac{n_k}{10^k} \le x.
\]
Then, letting $E$ be the set of the numbers
\[
	n_0 + \frac{n_1}{10} + \dotsb + \frac{n_k}{10^k}, k \in \N,
\]
we have $x = \sup E$. We define $n_0.n_1n_2n_3\dots$ to be the \textbf{decimal expansion} of $x$.
\end{definition}

\section{The Extended Real Number System}
\begin{definition}
The \textbf{extended real number system} consists of $\R$ and two symbols $+\infty$ and $-\infty$, with the normal order and $-\infty < x < \infty$ for all $x \in \R$. 

It is customary to define the following results of operations:
\begin{itemize}
\item $x + \infty = +\infty$, $x - \infty = -\infty$, $\frac{x}{+\infty} = \frac{x}{-\infty} = 0$.
\item If $x > 0$, then $x \cdot (+\infty) = +\infty$.
\item If $x < 0$, then $x \cdot (+\infty) = -\infty$. 
\end{itemize}
\end{definition}

\section{The Complex Field}
\begin{definition}
A \textbf{complex number} is an ordered pair $(a, b)$ of real numbers. We denote $\C$ the set of all complex numbers. Two ordered pairs are equal iff their components are equal. Also, we define
\[
	(a, b) + (c, d) = (a + c, b + d),\ (a, b) \times (c, d) = (ac - bd, ad + bc).
\]
and note that the set of complex numbers forms a field, with $(0, 0)$ and $(1, 0)$ playing the roles of 0 and 1 respectively.

We define $i = (0, 1)$ and notice $i^2 = -1$. This notation is convenient as we can do away with the ordered pair notation and write $(a, b) = a + bi$ instead.

If $z = a + bi$ for $a, b \in \R$, then we define $\Re(z) = a$ and $\Im(z) = b$ to be the \textbf{real part} and \textbf{imaginary part} of $z$ respectively. $\bar{z} = a - bi$ is called the \textbf{conjugate} of $z$. 
\end{definition}

The following properties of complex numbers will be helpful:
\begin{theorem}
If $z, w \in \C$, then 
\begin{enumerate}[(a)]
\item $\bar{z + w} = \bar{z} + \bar{w}$.
\item $\bar{zw} = \bar{z} \cdot \bar{w}$.
\item $z + \bar{z} = \Re(z)$, $z - \bar{z} = 2i\Im(z)$.
\item $z\bar{z} \in \R_{>0}$ when $z \ne 0$.
\end{enumerate}
\begin{proof}
For all of these, we will suppose $z = a + bi$ and $w = c + di$.

For (a), notice that $z + w = (a + c) + (b + d)i$ so
\[
	\bar{z + w} = (a + c) - (b + d)i = (a - bi) + (c - di) = \bar{z} + \bar{w}.
\]

For (b), notice that $zw = (ac - bd) + (ad + bc)i$ and that
\[
	\bar{z} \cdot \bar{w} = (a - bi) \cdot (c - di) = (ac - bd) - (ad + bc)i = \bar{zw}.
\]

For (c), notice that $z + \bar{z} = 2a = 2\Re(z)$ and $z - \bar{z} = 2bi = 2i\Im(z)$.

For (d), notice that $z\bar{z} = a^2 + b^2$, which is real and positive unless $a = b = 0$ (that is, $z = 0$).
\end{proof}
\end{theorem}

Since the value $z\bar{z}$ is a non-negative real number, we can think of it as some measure of how `large' $z$ is: the following definition formalizes this:
\begin{definition}
We define $|z| = \sqrt{z\bar{z}}$, called the \textbf{magnitude} or \textbf{absolute value} of $z$, which exists and is unique from Theorem 3c. When $x \in \R$, $|x| = x$ when $x > 0$ and $-x$ otherwise. In particular, the fact that $x \le |x|$ when $x \in \R$ is sometimes useful.
\end{definition}

The following are helpful properties of the absolute value:
\begin{theorem}
If $z = a + bi, w = c + di \in \C$, then the following are true:
\begin{enumerate}[(a)]
\item $|z| \ge 0$, with equality iff $z = 0$.
\item $|z| = |\bar{z}|$.
\item $|zw| = |z| \cdot |w|$.
\item $|\Re(z)| \le |z|$.
\item $|z + w| \le |z| + |w|$.
\end{enumerate}
\begin{proof}
For (a), clearly $|0| = 0$. Otherwise, $z\bar{z}$ is a positive real number, and thus has a positive square root, which is precisely $|z|$ by definition.

For (b), notice that both sides evaluate to $\sqrt{a^2 + b^2}$.

For (c), if either $z$ or $w$ is 0, the result follows immediately. Otherwise, we can see
\[
	|zw| = \sqrt{zw \bar{zw}} = \sqrt{z\bar{z} w\bar{w}} = \sqrt{z\bar{z}} \sqrt{w\bar{w}} = |z||w|
\]
where the third equality uses Theorem 3(d) since $z\bar{z}$ and $w\bar{w}$ are both positive from Theorem 4(d).

For (d), notice that
\[
	|\Re(z)| = |a| = \sqrt{a^2} \le \sqrt{a^2 + b^2} = |z| 
\]
where the third inequality follows since $f(x) = x^2$ is monotonically increasing as shown in Theorem 3(c). Notice that equality holds iff $b = 0$, that is, $z \in \R$.

For (e), notice that
\[
	|z + w|^2 = (z + w)(\bar{z} + \bar{w}) = z\bar{z} + w\bar{w} + z\bar{w} + w\bar{z} = |z|^2 + |w|^2 + (z\bar{w}) + \bar{(z\bar{w})}.
\]
From Theorems 4(c) and 5(d), we have 
\[
(z\bar{w}) + \bar{(z\bar{w})} = 2\Re(z\bar{w}) \le |2\Re(z\bar{w})| \le 2|z||w|.
\]
Combining these yields
\[
	|z + w|^2 = |z|^2 + |w|^2 + (z\bar{w}) + \bar{(z\bar{w})} \le |z|^2 + |w|^2 + 2|z||w| = (|z| + |w|)^2.
\]
The result follows by taking square roots, since both sides are non-negative real numbers.
\end{proof}
\end{theorem}

Finally, we present a classic inequality, the Cauchy-Schwartz inequality:
\begin{theorem}
If $a_1, \dotsc, a_n, b_1, \dotsc, b_n \in \C$, then $\left| \sum_{j=1}^{n} a_j\bar{b_j} \right|^2 \le \sum_{j=1}^{n} |a_j|^2 \sum_{j=1}^{n} |b_j|^2$. 

\begin{proof}
Let $A = \sum |a_j|^2, B = \sum |b_j|^2 \in \R$ and $C = \sum a_j\bar{b_j}$, so we claim $|C|^2 \le AB$. If $B = 0$, then we must have $b_1 = b_2 = \dotsb = b_n = 0$ and the result follows immediately. Otherwise, if $B > 0$, then
\begin{align*}
0 \le \sum |B a_j - C b_j|^2 &= \sum (B a_j - C b_j)(B \bar{a_j} - \bar{C b_j}) \\
	&= B^2 \sum a_j \bar{a_j} - B\bar{C}\sum a_j \bar{b_j} - BC\sum \bar{a_j}b_j + C\bar{C} \sum b_j\bar{b_j} \\
	&= B^2 \sum|a_j|^2 - B\bar{C}C - BC\bar{C} + C\bar{C} \sum |b_j|^2 \\
	&= B^2 A - B|C|^2 - B|C|^2 + |C|^2 B \\
	&= B(AB - |C|^2)
\end{align*}
and since $B > 0$, we must have $AB - |C|^2 \ge 0$, as required. 
\end{proof}
\end{theorem}

\section{Euclidean Spaces}

Motivated by spaces like $\R^2$ and $\R^3$, we generalize this notion.
\begin{definition}
For $k \in \N$, let $\R^k$ be the set of all ordered $k$-tuples $\textbf{x} = (x_1, x_2, \dotsc, x_k)$, where $x_i \in \R$ are called the \textbf{coordinates} of $\textbf{x}$. We call these tuples \textbf{vectors}.

We define addition as component-wise addition, and scalar multiplication by a real number as component-wise multiplication, so that $\R^k$ is closed under these two operations. The fact that $\R^k$ satisfies these properties, as well as the operations satisfying the associative, commutative, and distributive laws make $\R^k$ into a \textbf{vector space over $\R$}.

We define the \textbf{inner product} of $\textbf{x}$ and $\textbf{y}$ by
\[
	\textbf{x} \cdot \textbf{y} = \sum_{j=1}^{k} x_i y_i
\]
and the \textbf{norm} of $\textbf{x}$ by
\[
	|\textbf{x}| = (\textbf{x} \cdot \textbf{x})^{1/2} = \left(\sum_{j=1}^{k} x_j^2 \right)^{1/2}
\]

Now, $\R^k$ along with its associated inner product and norm is called \textbf{Euclidean $k$-space}.
\end{definition}

We can now use this definition to prove some important properties of $\R^k$:
\begin{theorem}
Suppose $\textbf{x}, \textbf{y}, \textbf{z} \in \R^k$ and $\alpha \in \R$. Then, the following are true:
\begin{enumerate}[(a)]
\item $|\textbf{x}| \ge 0$.
\item $|\textbf{x}| = 0$ iff $\textbf{x} = 0$.
\item $|\alpha \textbf{x}| = |\alpha| |\textbf{x}|$.
\item $|\textbf{x} \cdot \textbf{y}| \le |\textbf{x}| |\textbf{y}|$.
\item $|\textbf{x} + \textbf{y}| \le |\textbf{x}| + |\textbf{y}|$.
\item $|\textbf{x} - \textbf{z}| \le |\textbf{x} - \textbf{y}| + |\textbf{y} - \textbf{z}|$. 
\end{enumerate}
\begin{proof}
The facts (a), (b), and (c) follow directly from the definitions.

For (d), this is precisely the Cauchy-Schwartz inequality restricted to $\R$, applied to the components.

For (e), we write
\begin{align*}
	|\textbf{x} + \textbf{y}|^2 &= (\textbf{x} + \textbf{y})(\textbf{x} + \textbf{y}) \\
		&= \textbf{x} \cdot \textbf{x} + \textbf{x} \cdot \textbf{y} + \textbf{y} \cdot \textbf{x} + \textbf{y} \cdot \textbf{y} \\
		&= |\textbf{x}|^2 + 2 \textbf{x} \cdot \textbf{y} + |\textbf{y}|^2 \\
		&\le |\textbf{x}|^2 + 2 \left|\textbf{x} \cdot \textbf{y}\right| + |\textbf{y}|^2 \\
		&\le |\textbf{x}|^2 + 2 |\textbf{x}| |\textbf{y}| + |\textbf{y}|^2 \\
		&= (|\textbf{x}| + |\textbf{y}|)^2
\end{align*}
and the result follows by taking the square root.

For (f), this is shown by replacing $\textbf{x}$ with $\textbf{x - y}$ and $\textbf{y}$ with $\textbf{y - z}$ in (e).
\end{proof}
\end{theorem}

The fact that $\textbf{x} \ge 0$ with equality iff $\textbf{x} = 0$, and fact (f), called the Triangle Inequality, let us regard $\R^k$ as a \textbf{metric space}. 

$\R^1 = \R$ is called the (real) line, $\R^2$ is the plane. It is noteworthy that the norms in $\R^2$ and $\C$ are consistent.

\section{Appendix: Dedekind's construction of $\R$}

Here we construct $\R$ from $\Q$ in 9 steps.

\begin{enumerate}[Step 1.]
\item \underline{Making $\R$ a set.} 

The elements of $\R$ will be certain subsets of $\Q$, called \textbf{cuts}. A cut is a set $\alpha$ with the following three properties:
\begin{enumerate}[(I)]
\item $\emptyset \subset \alpha \subset \Q$.
\item If $p \in \alpha$ and $q \in \Q$, with $q < p$, then $q \in \alpha$.
\item If $p \in \alpha$, then $p < r$ for some $r \in \alpha$.
\end{enumerate}

We will use $p, q, r, \dotsc$ for rational numbers, and $\alpha, \beta, \gamma, \dotsc$ for cuts. 

Note that condition (II) implies the following useful statements:
\begin{itemize}
\item If $p \in \alpha$ and $q \not\in \alpha$, then $p < q$.
\item If $r \not\in \alpha$ and $r < s$, then $s \not\in \alpha$.
\end{itemize}

\item \underline{Making $\R$ an ordered set.} 

Define an order $<$ on the set of cuts such that $\alpha < \beta$ iff $\alpha \subset \beta$. This is clearly transitive, so it suffices to show that exactly one of $\alpha < \beta$, $\alpha = \beta$, or $\alpha > \beta$ can be true at once. Notice that by the properties of sets, at most one of these can be true at once, so it suffices to show that at least one is.

To do this, suppose that the first two are false. Then, there exists some $q \in \alpha$ which is not in $\beta$. Then, if $p \in \beta$, then we must have $p < q$ from condition (II). However, since $q \in \alpha$ and $p < q$, this also means $p \in \alpha$, so we conclude $\beta \subset \alpha$ so $\alpha > \beta$ as required. Thus, $\R$ is now an ordered set.

\item \underline{Showing $\R$ has the least-upper-bound property.}

Let $A$ be a non-empty subset of $\R$ which is bounded above. Let $\gamma = \bigcup A$. We claim that $\gamma \in \R$ and $\gamma = \sup A$. 

To show $\gamma \in \R$, we prove each condition individually. The first part of condition (I) follows directly from the fact that $A$ is the non-empty union of non-empty subsets of $\Q$. The second follows from the fact that $A$ is bounded above by some $\beta \ne \Q$. For condition (II), pick $p \in \gamma$ and $q \in \Q$. Since $p \in \gamma = \bigcup A$, there exists some $\alpha \in A$ for which $p \in \alpha$. Then, from condition (II) on $\alpha$, we must have $q \in \alpha \subseteq \gamma$, as required. For condition (III), pick the same $p, q, \alpha$. Then, from condition (III) on $\alpha$, there must exist $r \in \alpha \subseteq \gamma$ with $p < r$, as required. Thus, $\gamma \in \R$.

To show that $\gamma = \sup A$, notice that by definition, $\gamma$ is the superset of any $\alpha \in \gamma$, so $\gamma$ is an upper bound for $A$. Let $\beta < \gamma$. Then, there must be some $p$ in $ \gamma$ but not in $\beta$. In particular, there must be some $\alpha \in A$ for which $p \in \alpha$ but not in $\beta$. However, this means $\alpha \not< \beta$ so $\beta$ is not an upper bound for $A$, as required. 

Thus, $\R$ satisfies the least-upper-bound property.

\item \underline{Defining addition on $\R$.}

For $\alpha, \beta \in \R$, we define $\alpha + \beta = \{r + s : r \in \alpha, s \in \beta\}$. For this, we let $0^*$ denote the set of all negative rational numbers. It's easily checked that $0^* \in \R$. We verify the 5 axioms which define $\R$ as a commutative additive group with $+$.

Let $\alpha, \beta, \gamma \in \R$. 
\begin{enumerate}[({A}1)]
\item $\alpha + \beta \in \R$.

Notice that $\alpha + \beta$ is non-empty since $\alpha$ and $\beta$ are non-empty. To show that $\alpha + \beta \ne \Q$, take elements $r' \not\in \alpha, s' \not\in \beta$. Then, $r' + s' > r + s$ for all $r \in \alpha, s \in \beta$, so in particular, $r' + s' \not\in \alpha + \beta$ so $\alpha + \beta \ne \Q$, showing condition (I).

For condition (II) let $p = r + s \in \alpha + \beta$ for some $r \in \alpha, s \in \beta$, and $q < p$. Then, $q - s < p - s = r$ so $q - s \in \alpha$. Thus, $q = (q - s) + s \in \alpha + \beta$. 

For condition (III), let $t > r$ in $\alpha$, so that $t + s > r + s$ in $\alpha + \beta$. 

\item $\alpha + \beta = \beta + \alpha$.

This follows from the definition and the commutativity of $\Q$:
\[
	\alpha + \beta = \{r + s : r \in \alpha, s \in \beta\} = \{s + r : s \in \beta, r \in \alpha\} = \beta + \alpha
\]

\item $(\alpha + \beta) + \gamma = \alpha + (\beta + \gamma)$. 

This follows as above from the definition and the associativity of $\Q$.

\item $\alpha + 0^* = \alpha$.

If $r \in \alpha$, and $s \in 0^*$, then $r + s < r \in \alpha$, so $\alpha + 0^* \subseteq \alpha$. For the other side, take $r \in \alpha$ and $t > r$ in $\alpha$. Then, $r - t < 0$ so $r - t \in 0^*$ and thus $r = t + (r - t) \in \alpha + 0^*$ and thus $\alpha \subseteq \alpha + 0^*$, as required.

\item $-\alpha$ exists.

Let $\beta$ be the set of $p$ such that there exists $r > 0$ such that $-p - r \not\in \alpha$. We claim that $\beta \in \R$ and $\alpha + \beta = 0^*$.

Let $s \not \in \alpha$. Then, $s + 1 \in \beta$ since $(s + 1) - 1 \not\in \alpha$, so $\beta$ is non-empty. Also, if $r \in \alpha$, then $r \not \in \beta$, so $\beta \ne \Q$, satisfying condition (I) for being a cut. For condition (II) let $p \in \beta$ and $q < p$ in $\Q$. Then, $-p - r \not\in \alpha$ for some $r > 0$. Then, $-q - (-q + p + r) = -p - r \not\in \alpha$, and $-q + p + r > r > 0$, so $q \in \beta$, proving condition (II). For condition (III), let $p \in \beta$. Then, there exists $r > 0$ so that $-p - r \not\in \alpha$. Then, $p + r/2 > p$ is in $\beta$ since $-(p + r/2) - (r/2) \not\in \alpha$ and $r/2 > 0$, proving condition (III). So $\beta \in \R$.

Let $p \in \alpha$ and $q \in \beta$. Since $q \in \beta$, there exists $r > 0$ such that $-q - r \not\in \alpha$. Thus, from condition (II) on $\alpha$, $p < -q - r$ and thus $p + q < -r < 0$ so $p + q \in 0^*$. Since our choice of $p$ and $q$ was arbitrary, $\alpha + \beta \subseteq 0^*$. 

Let $t < 0$. We want to find $p \in \alpha$ and $q \in \beta$ such that $p + q = t$. Let $s = -t/2$ so that $s > 0$. Then, by the Archimedean property, there exists an integer $n$ such that $ns \in \alpha$ but $(n + 1)s \not\in \alpha$. Take $p = ns$ and $q = -(n + 2)s = t - p$. Since $-(-(n + 2)s) - s \not\in \alpha$ and $s > 0$, $q \in \beta$, so we are done!

\end{enumerate}

\item \underline{Towards an ordered field}

Notice that $\alpha + \beta \subset \alpha + \gamma$ if $\beta \subset \gamma$, so the first condition for ordered fields is satisfied. It also follows that $\alpha > 0^*$ iff $-\alpha < 0^*$. 

\item \underline{Multiplication, but only somewhat}

Let $\R^+ = \{\alpha \in \R : \alpha > 0^*\}$ be the positive real numbers. If $\alpha, \beta \in \R^+$, define $\alpha\beta$ to be the set of $p \le rs$ in $\R^+$, for some positive $r \in \alpha$, $s \in \beta$ with $r, s > 0$. We define $1^*$ to be the set of all rational numbers less than 1.

It can be shown, similarly to the proofs of (A1) to (A5), that the axioms of multiplication and distributivity hold for multiplication on $\R^+$:

Let $\alpha, \beta > 0^*$ be arbitrary.
\begin{enumerate}[({M}1)]
\item $\alpha \beta \in \R$.

We prove the three conditions separately. For condition (I): choose $r \in \alpha$ and $s \in \beta$ such that $r, s > 0$, which exist since $\alpha, \beta > 0^*$. Then, $rs \le rs$ so $rs \in \alpha\beta$, so $\alpha\beta$ is non-empty. Now, let $p \not\in \alpha$ and $q \not\in \beta$. Then, for any $r \in \alpha$ and $s \in \beta$ with $r, s > 0$, then $r < p$ and $s < q$, so $rs < pq$, implying that $pq \not\in \alpha\beta$, so $\alpha\beta \ne \Q$, proving condition (I).

For condition (II), let $q \in \alpha\beta$ and $p < q$ in $\Q$. Then, $q \le rs$ for $r \in \alpha$, $s \in \beta$ for $r, s > 0$. Then, similarly $p < q \le rs$ so $p \in \alpha\beta$. For condition (III), let $q \in \alpha\beta$ where $q \le rs$ as above. Then, choose $t > r > 0$ and $u > s > 0$ in $\alpha$ and $\beta$ respectively. Then, $tu \le tu$ so $tu \in \alpha\beta$ with $tu > rs$. Thus, $\alpha\beta \in \R$.

\item $\alpha \beta = \beta \alpha$.

This follows directly from the definition, since
\[
	\{rs: r \in \alpha, s \in \beta, r, s > 0\} = \{sr: s \in \beta, r \in \alpha, s, r > 0\}.
\]

\item $(\alpha \beta) \gamma = \alpha (\beta \gamma)$.

We prove that both sets are the set $A$ of all $p \le rst$ for $r \in \alpha$, $s \in \beta$, $t \in \gamma$, where $r, s, t > 0$. Since the right side can be written as $(\beta \gamma) \alpha$ and is thus symmetric, it suffices to prove one side.

Let $p \in A$ so that $p \le rst$, for some $r \in \alpha$, $s \in \beta$, $t \in \gamma$ all positive. Then, $rs \in \alpha\beta$, and $p \le (rs)t$, so $p \in (\alpha \beta) \gamma$. So $A \subseteq (\alpha \beta) \gamma$. The proof of the other side is very similar, so we omit it.

\item $\alpha 1^* = \alpha$.

Let $p \in \alpha 1^*$, so that $p \le rs$ for $r \in \alpha$ with $r > 0$ and $0 < s < 1$. Then, $p \le rs < r$ so $ p \in \alpha$, showing $\alpha 1^* \subseteq \alpha$. Now, let $t \in \alpha$. If $t < 0$, then $2t < t < 0$ so $2t \in \alpha$. Then, $t \le (2t) \cdot (1/2) \in \alpha 1^*$. If $t > 0$, then let $r > t$ in $\alpha$, from condition (III) of a cut. Then, $t/r < 1$, so $t \le r \cdot (t/r) \in \alpha 1^*$, completing this proof.

\item $\alpha^{-1}$ exists.

For $\alpha > 0^*$, denote $\beta$ to be the set of all $p > 0$ such that there exists $r > 0$ with $p^{-1} - r \not\in \alpha$, along with all the non-positive rational numbers. We claim that $\beta \in \R$ and $\alpha\beta = 1^*$.

For condition (I), clearly $0 \in \beta$, so $\beta$ is non-empty. Also, for any positive $q \in \alpha$, $p = \frac{1}{q + 1} > 0$ and $p^{-1} - 1 = q \in \alpha$ so $p \not\in \beta$, and thus $\beta \ne \Q$, proving condition (I) for cuts. 

For condition (II), let $p \in \beta$ and $q < p$. If $q \le 0$, then $q \in 0^* \cup \{0\} \subset\beta$ follows by definition. Otherwise, $p > 0$ so there exists some $r > 0$ such that $p^{-1} - r \not\in \alpha$. Since $q < p$, we have $q^{-1} - r > p^{-1} - r \not\in \alpha$ so $q^{-1} - r \not\in \alpha$ and thus $q \in \beta$, as required. 

Finally for condition (III), let $p \in \beta$. We want to find $q > p$ in $\beta$. If $p < 0$, this is easy since $0 \in \beta$. Otherwise, $p > 0$, so there exists $r > 0$ such that $p^{-1} - r \not\in \alpha$. Then, let $q = (p^{-1} - r/2)^{-1} > p$ (if $p^{-1} = r/2$, choose $r/3$ instead). Then, $q^{-1} - r/2 = p^{-1} - r \not\in \alpha$, so $q \in \beta$.

Now let $t \in \alpha\beta$, so that $t \le rs$ for some positive $r \in \alpha$, $s \in \beta$. Then, $s^{-1} - u \not\in \alpha$ for some $u > 0$. Also, $r - u \in \alpha$, so $r - u < s^{-1} - u$, implying $rs < 1$, so $t \le rs < 1$ and thus $t \in 1^*$. This proves $\alpha\beta \subseteq 1^*$. 

TODO Figure out how to get $1^* \subseteq \alpha\beta$, then show distributivity. 
\end{enumerate}

\item \underline{Multiplication, for real}

Now, define multiplication on all of $\R$ by
\[
	\alpha \beta = 
	\begin{cases}
		0^*	& \text{ if } \alpha = 0^* \text{ or } \beta = 0^* \\
		\alpha \beta & \text{ if } \alpha > 0^*, \beta > 0^* \\
		-(\alpha (-\beta)) & \text{ if } \alpha > 0^*, \beta < 0^* \\
		-((-\alpha) \beta) & \text{ if } \alpha < 0^*, \beta > 0^* \\
		(-\alpha)(-\beta) & \text{ if } \alpha < 0^*, \beta < 0^*
	\end{cases}
\]

The proofs for the multiplication axioms and distributivity follow from Step 6, with repeated use of $\gamma = -(-\gamma)$. The proofs are omitted.

\textbf{\textit{This proves that $\R$ is an ordered field with the least-upper-bound property!}}

\item \underline{Relation to $\Q$}

Associate with each $q \in \Q$, a set $q^* = \{r \in \Q : r < q\}$. Notice that this definition is consistent with our definitions of $0^*$ and $1^*$ above (the asterisk was not a coincidence). These cuts satisfy the following relations:

\begin{enumerate}
\item $r^* + s^* = (r + s)^*$.
\item $r^* s^* = (rs)^*$.
\item $r^* < s^*$ iff $r < s$.
\end{enumerate} 

This shows that $\Q$ is isomorphic to $\Q^*$ whose elements are the rational cuts. This relationship is the reason we can regard $\Q$ as a subfield of $\R$. 
\end{enumerate}

\section{Exercises}
\begin{enumerate}
\item If $r$ is rational and non-zero, and $x$ is irrational, prove that $r + x$ and $rx$ are irrational.

\begin{proof}
Suppose otherwise: then $(r + x) - r$ and $(rx) / r$ would be operations on rational numbers, and thus evaluate to rational numbers. However, these both evaluate to $x$, which is irrational, a contradiction.
\end{proof}

\item Prove that there is no rational number whose square is 12.

\begin{proof}
We first prove that there is no rational number whose square is 3. Suppose that there existed $p / q \in \Q$ whose square is 3, and such that $p$ and $q$ share no factors, cancelling factors when appropriate. Then, multiplying this equality by $q^2$, we have $p^2 = 3q^2$, showing that $p$ is divisible by 3. But, this means $3p'^2 = 3q^2$, which in turn implies $q$ is divisible by 3, contradicting the fact that $p$ and $q$ share no factors.

Now, if some rational number $r$ had $r^2 = 12$, then $r/2$ would be a rational number such that $(r/2)^2 = 3$, contradicting our previous statement.
\end{proof}

\item Prove that in a field $F$, the following statements follow from the axioms of multiplication:
\begin{enumerate}[(a)]
\item If $x \ne 0$ and $xy = xz$ then $y = z$.
\item If $x \ne 0$ and $xy = x$ then $y = 1$.
\item If $x \ne 0$ and $xy = 1$, then $y = 1/x$.
\item If $x \ne 0$ then $1/(1/x) = x$.
\end{enumerate}
\begin{proof}
For (a), if $x \ne 0$, then $1/x \in F$, so we can multiply this to both sides, yielding the result. (b) follows by letting $z = 1$ in (a). (c) follows by letting $z = 1/x$ in (a). (d) follows by letting $x = 1/x$ and $y = 1/(1/x)$ in (c), noticing that $1 = 1/x \cdot x = 1/x \cdot 1/(1/x)$.
\end{proof}

\item Let $E$ be a non-empty subset of an ordered set; suppose $\alpha$ is a lower bound of $E$ and $\beta$ is an upper bound of $E$. Prove that $\alpha \le \beta$.

\begin{proof}
Since $E$ is non-empty, let $x \in E$. Then, since $\alpha$ is a lower bound for $E$, in particular, $\alpha \le x$. Similarly, $x \le \beta$, so $\alpha \le x \le \beta$, as required.
\end{proof}

\item Let $A$ be a non-empty set of real numbers which is bounded below, and $-A$ be the set of all numbers $-x$ for $x \in A$. Prove that $\inf A = -\sup(-A)$. 

\begin{proof}
Since $A$ is non-empty and bounded below, and $\R$ satisfies the least upper bound property, $\alpha = \inf A$ exists. We claim that $-\alpha$ is the least upper bound to $-A$.

First, notice that $-\alpha \ge -x$ for all $-x \in -A$, since $\alpha \le x$ for all $x \in A$. Also, if $-\beta < -\alpha$ were a smaller upper bound for $-A$, then $\beta$ would be a larger lower bound for $A$, contradicting the fact that $\alpha$ is the \textbf{greatest} lower bound for $A$.
\end{proof}

\item Fix $b > 1$.
\begin{enumerate}[(a)]
\item If $m, n, p, q \in \Z$ with $n, q > 0$ and $r = m/n = p/q$, prove that $(b^m)^{1/n} = (b^p)^{1/q}$ so it makes sense to define $b^r = (b^m)^{1/n}$.

\begin{proof}
Let $x = (b^m)^{1/n}$ and $y = (b^p)^{1/q}$. Now, notice that $x^{nq} = (x^n)^q = (b^m)^q = b^{mq}$ and similarly $y^{nq} = b^{np}$. Since $m/n = p/q$, we have $qm = np$, so in fact $x^{nq} = y^{nq}$, so the result follows by the uniqueness of positive real $nq$-th roots.
\end{proof}

\item Prove $b^{r+s} = b^r b^s$ if $r, s \in \Q$. 

\begin{proof}
Write $r = m/n$ and $s = p/q$ for $m, n, p, q \in \Z$ with $n, q > 0$. Then, $r + s = (mq + np) / nq$. Now, notice that from properties of integer powers, $b^{mq + np} = b^{mq} b^{np}$. So,
\[
	(b^{r+s})^{nq} = (b^{(mq + np) / nq})^{nq} = b^{mq + np} = b^{mq} b^{np} = b^{rnq} b^{snq} = (b^r b^s)^{nq}
\]
and the result follows from the uniqueness of $nq$-th positive real roots. 
\end{proof}

\item If $x$ is real, define $B(x)$ to be the set of all numbers $b^t$, where $t$ is rational and $t \le x$. Prove that
\[
	b^r = \sup B(r)
\]
when $r$ is rational. Hence, we can define $b^x = \sup B(x)$ for every real $x$. 

\begin{proof}
We first prove a helpful lemma: if $q > 0$ in $\Q$, then $b^q > 1$. Let $q = m/n$ for $m, n \in \N$ and $n \ne 0$. Since $x^m$ and $x^n$ are monotonically increasing, then if $b > 0$,
\[
	1 < b^{m/n} \iff 1^n = 1 < b^m \iff 1 < b
\]
so $b^q > 1$ as required. It follows that if $r \le t$, then $b^r \le b^t$: simply consider $b^t - b^r = b^r (b^{t-r} - 1) \ge 0$, since both terms are non-negative.

In fact, the previous statement shows that $b^r$ is indeed an upper bound for $B(r)$: if $t \le r$ and thus $b^t \in B(r)$, then $b^t \le b^r$. Since $r \le r$, $b^r \in B(r)$, so any upper bound for $B(r)$ must be at least $b^r$. Thus $b^r$ must be the least upper bound for $B(r)$, as required. 
\end{proof}

\item Prove $b^{x+y} = b^x b^y$ for all $x, y \in \R$.

\begin{proof}
First, we want to show that $b^{x} b^{y}$ is an upper bound for $B(x + y)$. Suppose that $q \le x + y$ in $\Q$. Then, we can write $q = u + v$ for $u \le x, v \le y$ in $\Q$ (from the Archimedean property, we can choose choose $u \in \Q$ in the non-empty interval $[q - y, x]$), so that $b^q = b^{u+v} = b^u b^v$. However, since $u \le x$ and $v \le y$, $b^u \le b^x$ and $b^v \le b^y$, so $b^q = b^u b^v \le b^x b^y$ as required.

Now, suppose $r < b^x b^y$. We need to find some $q \le x + y$ in $\Q$ such that $b^q > r$, to show that $r$ is not an upper bound for $B(x + y)$. 

Dividing both sides by $b^x$ yields $r/b^x < b^y = \sup B(y)$, so there exists some $v \le y$ in $\Q$ such that $b^v > r/b^x$ so $r < b^x b^v$. Dividing this new inequality by $b^v$ yields $r / b^v < b^x = \sup B(x)$ so there exists $u \le x$ in $\Q$ such that $b^u > r / b^v$. Thus, $r < b^u b^v = b^{u + v}$ with $q = u + v \le x + y$, as required. 
\end{proof}
\end{enumerate}

\item Fix $b > 1, y > 0$, and prove that there is a unique real $x$ such that $b^x = y$, by completing the following outline. (This $x$ is called the \textbf{logarithm of $y$ to the base $b$}.)

\begin{enumerate}[(a)]
\item For any positive integer $n$, we have $b^n - 1 \ge n(b - 1)$. 
\begin{proof}
Factor $b^n - 1 = (b - 1)(b^{n - 1} + b^{n - 2} + \dotsb + b + 1)$. Since $b^k > 1$ for every positive integer $k$ (inductively), the above expression is greater than or equal to $(b - 1)(1 + 1 + \dotsb + 1) = n(b - 1)$, where there are $n$ 1's, as required.
\end{proof}

\item Hence $b - 1 \ge n(b^{1/n} - 1)$.
\begin{proof}
Since $f(x) = x^n$ is monotonically increasing, $b^{1/n} > 1$ since $b > 1$, so substituting $b^{1/n}$ for $b$ in (a) yields the result.
\end{proof}

\item If $t > 1$ and $n > (b - 1)/(t - 1)$, then $b^{1/n} < t$.
\begin{proof}
We have 
\[
	n > \frac{b - 1}{t - 1} \ge \frac{n(b^{1/n} - 1)}{t - 1}
\]
so cancelling the positive $n$ from the outermost expressions, multiplying by the positive value $t - 1$, and adding 1 to both sides yields the result.
\end{proof}

\item If $w$ is such that $b^w < y$, then $b^{w + 1/n} < y$ for sufficiently large $n$; to see this, apply part (c) with $t = y \cdot b^{-w}$.
\begin{proof}
Following the prompt, we notice that letting $t = y \cdot b^{-w} > 1$ in (c), if $n > (b - 1)/(y \cdot b^{-w} - 1) \in \R$, then $b^{1/n} < y \cdot b^{-w}$, which after multiplying both sides by the positive value $b^w$, gives the result.
\end{proof}

\item If $b^w > y$, then $b^{w - 1/n} > y$ for sufficiently large $n$.
\begin{proof}
Similarly, letting $t = b^w / y$ in (c) yields $b^{1/n} < b^w / y$ for $n > (b - 1)/(b^w / y - 1) \in \R$, after which rearranging for $y$ yields the result. 
\end{proof}

\item Let $A$ be the set of all $w$ such that $b^w < y$, and show that $x = \sup A$ satisfies $b^x = y$.
\begin{proof}
Suppose otherwise. If $b^x < y$, then from (d), there exists some $n \in \N$ such that $b^{x + 1/n} < y$, so $x + 1/n \in A$, contradicting the fact that $x$ is an upper bound for $A$. 

Similarly, if $b^x > y$, then from (e), there exists some $n \in \N$ such that $b^{x - 1/n} > y$, and so for any $w \in A$, we have $b^w < y < b^{x - 1/n}$ and thus $w < x - 1/n$ from the lemma in Exercise 6(c), making $x - 1/n$ a smaller upper bound for $A$, a contradiction.
\end{proof}

\item Prove that this $x$ is unique.
\begin{proof}
Suppose that $x \ne y$ in $\R$ and $b^x = b^y$. Without loss of generality, suppose $x < y$. But then $b^x < b^y$ from the statement proved in Exercise 6(c), contradicting our assumption, so we are done.
\end{proof}
\end{enumerate}

\item Prove that no order can be defined in the complex field that turns it into an ordered field. Hint: $-1$ is a square.

\begin{proof}
Suppose otherwise. Then, notice that since $1 = 1^2$ and $-1 = i^2$ are both non-zero squares, they are both positive. Thus, their sum, 0, would have to be positive, a contradiction.
\end{proof}

\item Suppose $z = a + bi$ and $w = c + di$. Define $z < w$ if $a < c$,  and also if $a = c$ but $b < d$. Prove that this turns the set of all complex numbers into an ordered set. (This type of order relation is called a \textbf{dictionary order} or \textbf{lexicographic order}, for obvious reasons.) Does this ordered set have the least-upper-bound property?

\begin{proof}
First, we show that exactly one of $z < w$, $z = w$, or $z > w$ is true. Suppose that $z \ne w$, so that $a \ne c$ or $b \ne d$. If $a \ne c$, then either $a < c$, in which case $z < w$, or $a > c$, in which case $z > w$. Otherwise, either $b < d$, in which case $z < w$, or $b > d$, in which case $z > w$. 

Next, we show that this order is transitive. Suppose $a + bi < c + di$ and $c + di < e + fi$. If $a < c$, then since $c \le e$, $a < e$ and thus $a + bi < e + fi$. If $a = c$, then $b < d$. If further $c = e$, then $b < d < f$ and thus $a + bi < e + fi$. If further $c < e$, then $a = c < e$ so $a + bi < e + fi$. In all cases, $a + bi < e + fi$.

This ordered set does not have the least-upper-bound property: consider the set $A = i\R = \{ir : r \in \R\}$, which is bounded above by $1$. We claim that though $A$ is non-empty and bounded above, there does not exist a least upper bound. Let $\alpha$ be an upper bound for $A$. Notice that $\alpha$ must have a non-negative real component. If $\alpha$ has a strictly positive real component, say $r$, then $r/2$ will be smaller than $r$ but still larger than all of $A$. Thus, a least upper bound will never have positive real component. If $\alpha$ had real component 0, then $\alpha + 1 \in A$ would be larger than it, a contradiction. Thus, no least upper bound for $A$ exists.
\end{proof}

\item Suppose $z = a + bi$, $w = u + vi$, and
\[
	a = \left(\frac{|w| + u}{2}\right)^{1/2},\ b = \left(\frac{|w| - u}{2}\right)^{1/2}.
\]
Prove that $z^2 = w$ if $v \ge 0$ and that $(\bar{z})^2 = w$ if $v \le 0$. Conclude that every complex number (with one exception!) has two complex square roots.

\begin{proof}
Notice that $(a + bi)^2 = (a^2 - b^2) + i(2ab)$, so
\[
	z^2 =  \left(\frac{|w| + u}{2} - \frac{|w| - u}{2} \right) + 2i \left( \sqrt{\frac{|w| + u}{2}} \cdot \sqrt{\frac{|w| - u}{2}} \right) = u + i \sqrt{|w|^2 - u^2} = u + i|v|
\]
so $z^2 = u + iv$ when $v \ge 0$. Similarly,
\[
	\bar{z}^2 = (a^2 - b^2) - 2iab = u - i|v| = u + iv
\]
if $v < 0$. Thus, if $v \ge 0$, then $z$ and $-z$ are two complex square roots of $w$, and similarly $\pm \bar{z}$ are square roots of $w$ if $v < 0$. The exception here is of course when $z = -z$, namely when $z = 0$ and thus $w = z^2 = 0$.
\end{proof}

\item If $z$ is a complex number, prove that there exists an $r \ge 0$ and a complex number $w$ with $|w| = 1$ such that $z = rw$. Are $w$ and $r$ always uniquely determined by $z$?

\begin{proof}
Let $r = |z| \ge 0$ and $w = z / |z|$. Notice that $|w| = |z| / ||z|| = 1$, and $z = rw$ by definition. $w$ and $r$ are uniquely defined for all $z \in \C$ except 0, in which case $r = 0$ and $w$ can be any complex number with unit absolute value.

Suppose $z \ne 0$ and $z = r_1 w_1 = r_2 w_2$ with the required conditions. Take absolute values to get $|z| = |r_1||w_1| = |r_2||w_2|$, which implies $|r_1| = |r_2|$. Since $r_1, r_2 \ge 0$, we must have $r_1 = r_2$, uniquely determining $w_1$ and $w_2$, as required.
\end{proof}

\item If $z_1, \dotsc, z_n$ are complex, prove that
\[
	|z_1 + z_2 + \dotsb + z_n| \le |z_1| + |z_2| + \dotsb + |z_n|.
\]

\begin{proof}
We proceed by induction on $n$. The base case is given by Theorem 7(e), as applied to complex numbers taken as ordered pairs of real numbers. Then, for $n > 2$, assuming the statement is true for $n - 1$ inductively, we have
\begin{align*}
	|z_1 + z_2 + \dotsb + z_{n-1} + z_n| &\le |z_1 + z_2 + \dotsb + z_{n-1}| + |z_n| \\
		&\le |z_1| + |z_2| + \dotsb + |z_{n-1}| + |z_n|,
\end{align*}
completing the induction.
\end{proof}

\item If $x, y \in \C$, prove that 
\[
	||x| - |y|| \le |x - y|.
\]

\begin{proof}
Notice $|x| = |(y - x) - y| \le |y - x| + |y|$ so $|x - y| = |y - x| \ge |x| - |y|$. 

Similarly, $|y| = |(y - x) + x| \le |y - x| + |x|$ so $|x - y| \ge |y| - |x|$. Combining these two inequalities yields
\[
	-|x - y| \le |x| - |y| \le |x - y| 
\]
and so
\[
	||x| - |y|| \le |x - y|,
\]
as required.
\end{proof}

\item If $z \in \C$ such that $|z| = 1$, compute
\[
	|1 + z|^2 + |1 - z|^2
\]

\begin{proof}
Simply write
\[
	|1 + z|^2 + |1 - z|^2 = (1 + z)(1 + \bar{z}) + (1 - z)(1 - \bar{z}) = 1 + z + \bar{z} + z\bar{z} + 1 - z - \bar{z} + z\bar{z} = 4.
\]
\end{proof}

\item Under what conditions does equality hold in the Schwartz inequality?

\begin{proof}
Notice that in the proof, equality holds iff $\sum |Ba_j - Cb_j|^2 = 0$, and equivalently $a_j = Cb_j/B$ for each $j$. In particular, if the $a_j$ are each the same multiple of $b_j$, then equality will hold.
\end{proof}

\item Suppose $k \ge 3$, $\textbf{x}, \textbf{y} \in \R^k$, $|\textbf{x} - \textbf{y}| = d > 0$, and $r > 0$. Prove:
\begin{enumerate}[(a)]
\item If $2r > d$, there are infinitely many $\textbf{z} \in \R^k$ such that 
\[
	|\textbf{z} - \textbf{x}| = |\textbf{z} - \textbf{y}| = r.
\]

\begin{proof} Let $\textbf{m} = \frac{1}{2} ( \textbf{x} + \textbf{y} )$. Without loss of generality, suppose $\textbf{y} = -\textbf{x}$, translating when necessary. Also, let $t = \sqrt{r^2 - d^2/4}$, which is well defined since $2r > d$. Then, the set of vectors on the hyperplane orthogonal to the line crossing $\textbf{x}$ and $\textbf{y}$ with distance $t$ to $\textbf{m}$ satisfy the required equation, and there are infinitely many.
\end{proof}

\item If $2r = d$, there is exactly one such $\textbf{z}$.

\begin{proof}
If such a $\textbf{z}$ existed, then $d = |\textbf{x} - \textbf{y}| \le |\textbf{x} - \textbf{z}| + |\textbf{z} - \textbf{y}| = 2r = d$, so equality must hold in the triangle inequality. This happens when the three points are co-linear, and there is a unique point which satisfies this, namely $\textbf{z} = \textbf{m}$ as defined above.
\end{proof}

\item If $2r < d$, there are no such $\textbf{z}$.
\begin{proof}
If such a $\textbf{z}$ existed, then $d = |\textbf{x} - \textbf{y}| \le |\textbf{x} - \textbf{z}| + |\textbf{z} - \textbf{y}| = 2r < d$, a contradiction.
\end{proof}
\end{enumerate}

How must these statements be modified if $k < 3$?

\begin{proof}
If $k = 2$, then (a) will have 2 solutions instead, and everything else remains the same. If $k = 1$, (a) will have no solutions.
\end{proof}

\item Prove that
\[
	|\textbf{x} + \textbf{y}|^2 + |\textbf{x} - \textbf{y}|^2 = 2 |\textbf{x}|^2 + 2 |\textbf{y}|^2
\]
if $x, y \in \R^k$. Interpret this geometrically, as a statement about parallelograms.

\begin{proof}
We expand:
\begin{align*}
|\textbf{x} + \textbf{y}|^2 + |\textbf{x} - \textbf{y}|^2 &= (\textbf{x} + \textbf{y}) \cdot (\textbf{x} + \textbf{y}) + (\textbf{x} - \textbf{y}) \cdot (\textbf{x} - \textbf{y}) \\
	&= \textbf{x} \cdot \textbf{x} + \textbf{x} \cdot \textbf{y} + \textbf{y} \cdot \textbf{x} + \textbf{y} \cdot \textbf{y} + \textbf{x} \cdot \textbf{x} - \textbf{x} \cdot \textbf{y} - \textbf{y} \cdot \textbf{x} + \textbf{y} \cdot \textbf{y} \\
	&= 2 |\textbf{x}|^2 + 2 |\textbf{y}|^2
\end{align*}

The interpretation of this is that in a parallelogram, the sums of the squares of the lengths of the diagonals is equal to the sum of the squares of the lengths of the four sides.
\end{proof}

\item If $k \ge 2$ and $\textbf{x} \in \R^k$, prove that there exists $\textbf{y} \in \R^k$ such that $\textbf{y} \ne 0$ but $\textbf{x} \cdot \textbf{y} = 0$. Is this also true if $k = 1$?

\begin{proof}
If $\textbf{x} = 0$, then any non-zero vector will do. If $\textbf{x}$ has only one non-zero component, then choose $i$ such that $x_i = 0$ and let $\textbf{y}$ be the vector with $y_i = 1$ and $y_j = 0$ if $j \ne i$. Otherwise, if $\textbf{x} = (x_1, \dotsc, x_k)$, there exists $x_i \ne 0$. Then, let $y_j = x_j$ if $j \ne i$, and $y_i = \frac{x_1^2 + x_2^2 + \dotsc + x_k^2 - x_i^2}{x_i}$. Then, 
\[
	\textbf{x} \cdot \textbf{y} = \sum_{j=1}^{k} x_j y_j = \left(\sum_{j=1}^{k} x_j x_j\right) - x_i^2 - x_iy_i = 0
\]
as required. Notice that $\textbf{y}$ is non-zero since there exists $y_k = x_k \ne 0$ for $k \ne i$ by presumption.

This statement is not true for $k = 1$: consider $\textbf{x} = (1)$.
\end{proof}

\item Suppose $\textbf{a}, \textbf{b} \in \R^k$. Find $\textbf{c} \in \R^k$ and $r > 0$ such that
\[
	|\textbf{x} - \textbf{a}| = 2 |\textbf{x} - \textbf{b}|
\]
iff $|\textbf{x} - \textbf{c}| = r$.

\begin{proof}
This is an example of \textbf{Circles of Apollonius}. $\textbf{c} = \frac{1}{3} \left(4\textbf{b} - \textbf{a}\right)$, $r = \frac{2}{3} |\textbf{b} - \textbf{a}|$. 
\end{proof}

\item With reference to the Appendix, suppose that property (III) were omitted from the definition of a cut. Keep the same definitions of order and addition. Show that the resulting ordered set has the least-upper-bound property, that addition satisfies axioms (A1) to (A4) (with a slightly different zero-element!) but that (A5) fails.

\begin{proof}
TODO
\end{proof}
\end{enumerate}

\chapter{Basic Topology}

\section{Finite, Countable and Uncountable Sets}

\begin{definition}
Let $A, B$ be two sets such that every element $x$ of $A$ is associated an element of $B$, denoted by $f(x)$. Then, $f$ is a \textbf{function from $A$ to $B$} or a \textbf{mapping from $A$ into $B$}. The set $A$ is called the \textbf{domain} of $A$, and the elements $f(x)$ are called the \textbf{values} of $f$. The set of all values of $f$ is called the \textbf{range} of $f$.

Let $A, B$ be two sets and $f$ be a mapping of $A$ into $B$. If $E \subseteq A$, then $f(E)$ is defined to be the set of all elements $f(x)$ for $x \in E$. We call $f(E)$ the \textbf{image} if $E$ under $f$. In this notation, $f(A)$ is the range of $f$. It is clear that $f(A) \subseteq B$. If $f(A) = B$, we say that $f$ maps $A$ \textbf{onto} $B$, or that $f$ is \textbf{surjective}. 

\underline{It is important to note the difference between into and onto}.

If $E \subseteq B$, then $f^{-1}(E)$ denotes the set of all $x \in A$ such that $f(x) \in E$. $f^{-1}(E)$ is the \textbf{inverse image} of $E$ under $f$. If $y \in B$, $f^{-1}(y)$ is the set of all $x \in A$ such that $f(x) = y$.

If $f^{-1}(y)$ consists of at most one element of $A$ for each $y \in B$, then $f$ is a \textbf{one-to-one}, or \textbf{injective} mapping of $A$ into $B$. A mapping $f$ which is both injective and surjective is called \textbf{bijective}, or a  \textbf{1-1 correspondence}. 

If there exists a bijection between $A$ and $B$, we say that $A$ and $B$ have the same \textbf{cardinal number}, or briefly that $A$ and $B$ are \textbf{equivalent}, and we write $A \sim B$. This relation has the reflexive, symmetric, and transitive properties, and is thus called an \textbf{equivalence relation}.

For any positive integer $n$, let $J_n$ be the set $\{1, 2, 3, \dotsc, n\}$, and $J$ be the set consisting of all positive integers. For any set $A$, we say
\begin{enumerate}[(a)]
\item $A$ is \textbf{finite} if $A \sim J_n$ for some $n$.
\item $A$ is \textbf{infinite} if $A$ is not finite.
\item $A$ is \textbf{countable} if $A \sim J$.
\item $A$ is \textbf{uncountable} if $A$ is neither finite nor countable.
\item $A$ is \textbf{at most countable} if $A$ is finite or countable.
\end{enumerate}

Countable sets are sometimes called \textbf{enumerable} or \textbf{denumerable}. Notice that if $A, B$ are both finite, then $A \sim B$ iff they contain the same number of elements. The notion of bijection extends this idea to infinite sets.
\end{definition}

For example, the set of all integers $\Z$ is countable: consider the ordering
\[
	0, 1, -1, 2, -2, 3, -3, \dotsc
\]
given by the bijection
\[
	f(n) = \begin{cases}
		\frac{n}{2} & \text{ if $n$ even} \\
		-\frac{n-1}{2} & \text{ if $n$ odd}
		\end{cases}
\]

An interesting property of $\Z$ is thus that it is equivalent to one of its proper subsets. This is never true of finite sets, so in fact a set is infinite if it is equivalent to one of its proper subsets. 

\begin{definition}
A \textbf{sequence} is a function $f$ defined on the set $J$ of positive integers. If $f(n) = x_n$ for $n \in J$, then we denote $f$ by the symbol $\{x_n\}$ or sometimes $x_1, x_2, \dotsc$. The values $x_n$ of $f$ are called the \textbf{terms} of the sequence. If $A$ is a set and $x_n \in A$ for each $n \in J$, then $\{x_n\}$ is a \textbf{sequence in $A$}, or a \textbf{sequence of elements in $A$}.
\end{definition}

\begin{theorem}
Every infinite subset of a countable set $A$ is countable. 

\begin{proof}
Let $\{x_n\}$ be a sequence of distinct elements in $A$. Then, for any infinite subset $E$ of $A$, we can take the subsequence $\{x_{n_k}\}$ of $\{x_n\}$ corresponding to $E$, so $E$ is countable.
\end{proof}
\end{theorem}

The above theorem shows that countable sets are the `smallest infinity' in some sense. 

\begin{definition}
Let $A$ and $\Omega$ be sets, and suppose that for each element $\alpha \in A$, there is associated a subset of $\Omega$ which we denote by $E_{\alpha}$. We call the set whose elements are the sets $E_{\alpha}$ a \textbf{collection} or \textbf{family} of sets, denoted $\{E_\alpha\}$. 

The \textbf{union} of the sets $E_\alpha$ is the set $S$ such that $x \in S$ iff $x \in E_\alpha$ for at least one $\alpha \in A$, denoted
\[
	S = \bigcup_{\alpha \in A}{E_\alpha}.
\]

The \textbf{intersection} of the sts $E_{\alpha}$ is the set $P$ such that $x \in P$ iff $x \in E_\alpha$ for every $\alpha \in A$, denoted
\[
	P = \bigcap_{\alpha \in A}{E_\alpha}.
\]

If $A \cap B$ is not empty, we say that $A$ and $B$ \textbf{intersect}, otherwise they are \textbf{disjoint}.
\end{definition}

The operations $\cup$ and $\cap$ are commutative and associative, but they also distribute:

\begin{theorem}
For sets $A, B, C$, we have
\[
	E = A \cap (B \cup C) = (A \cap B) \cup (A \cap C) = F.
\]

Suppose that $x \in E$. Then, $x \in A$ and at least one of $x \in B$ or $x \in C$. Thus at least one of $x \in (A \cap B)$ or $x \in (A \cap C)$, so $x \in F$.

Similarly, if $x \in F$, then at least $x$ is in at least one of $A \cap B$ or $A \cap C$, so $x \in A$, and at least one of $B$ or $C$, so $x \in E$, completing the proof.
\end{theorem}

\begin{theorem}
Let $\{E_n\}$ where $n \in J$ be a sequence of countable sets, and let $S$ be their countable union. Then $S$ is countable.

\begin{proof}
Let every $E_n$ be arranged in a sequence $\{x_{nk}\}_{k \in J}$. Then, consider the sequence
\[
	\underbrace{x_{11}}, \underbrace{x_{21}, x_{12}}, \underbrace{x_{31}, x_{22}, x_{13}}, \underbrace{x_{41}, x_{32}, x_{23}, x_{14}}, \dotsc
\]
which enumerates $S$. If any two of the sets $E_n$ have elements in common, these will appear more than once in $S$. So the sequence is at most countable, but since $E_1 \subseteq S$, it is at least countable, so it is countable.
\end{proof}
\end{theorem}

\begin{corollary}
Suppose $A$ is at most countable, and for every $\alpha \in A$, $B_\alpha$ is at most countable. Then, $T = \bigcup_{\alpha \in A} B_\alpha$ is at most countable.

This follows since $T$ is equivalent to a subset of $S$ in the above theorem.
\end{corollary}

\begin{theorem}
Let $A$ be a countable set, and $B_n$ be the set of all $n$-tuples $(a_1, \dotsc, a_n)$ in $A$, where the $a_k$ need not be distinct. Then $B_n$ is countable.

\begin{proof}
$B_1 = A$ is countable. Suppose that $B_{n-1}$ is countable for $n > 1$. Then, the elements of $B_n$ are of the form $(b, a)$ for $b \in B_{n-1}$ and $a \in A$, so the set of all pairs $(b, a) \sim A$ and is thus countable. Then, $B_n$ is the countable union of countable sets, and is thus countable. The result follows by induction on $n$.
\end{proof}
\end{theorem}

\begin{corollary}
The set of all rational numbers is countable.

\begin{proof}
Associate with each $r = m/n \in \Q$ the pair $(m, n)$ of integers. The set of pairs $(m, n)$ is countable, and thus $\Q$ is countable.
\end{proof}
\end{corollary}

But not all infinite sets are countable:

\begin{theorem}
The set $A$ of all sequences in $\{0, 1\}$ is uncountable.

\begin{proof}
Suppose otherwise, so that $A$ is countable, and thus admits a sequence $\{s_n\}$. Then, construct a sequence $t \in A$ such that $t_j = 1 - s_{jj}$ so $t_j \ne s_{jj}$ for all $j \in J$. Then, $t \not\in \{s_n\}$ since it differs from each sequence at at least one point. Thus, $t \not\in A$, a contradiction.
\end{proof}
\end{theorem}

Notice the above theorem can be combined with the binary representation of real numbers to show that the real numbers are uncountable.

\section{Metric Spaces}

\begin{definition}
A set $X$, whose elements are \textbf{points}, is a \textbf{metric space} if for any two points $p, q \in X$ there is a real number $d(p, q)$ called the \textbf{distance} from $p$ to $q$, such that
\begin{enumerate}[(a)]
\item $d(p, q) \ge 0$, with equality iff $p = q$.
\item $d(p, q) = d(q, p)$.
\item $d(p, q) \le d(p, r) + d(r, q)$ for any $r \in X$.
\end{enumerate}
Any function with these three properties is called a \textbf{distance function}, or a \textbf{metric}.
\end{definition}

We can define metrics in the Euclidean spaces $\R^k$, with the distance $d(\textbf{x}, \textbf{y}) = |\textbf{x} - \textbf{y}|$. It is important to note that every subset of a metric space is still a metric space under the same distance function.

\begin{definition}
We denote the \textbf{segment} $(a, b)$ to be the set of real numbers $x$ such that $a < x < b$. Similarly, the \textbf{interval} $[a, b]$ is the set of all real numbers $x$ such that $a \le x \le b$. 

If $a_i < b_i$ for all $i \in J_k$, then the set of all points $\textbf{x} = (x_1, \dotsc, x_k) \in \R^k$ such that $a_i \le x_i \le b_i$ is called a \textbf{$k$-cell}.

If $\textbf{x} \in \R^k$ and $r > 0$, the \textbf{open} (or \textbf{closed} respectively) \textbf{ball} $B$ is the set of all $\textbf{y} \in \R^k$ such that $|\textbf{y} - \textbf{x}| < r$ (or $\le r$ respectively).

A set $E \subseteq \R^k$ is \textbf{convex} iff $\lambda \textbf{x} + (1 - \lambda) \textbf{y} \in E$ whenever $\textbf{x}, \textbf{y} \in E$ and $\lambda \in (0, 1)$.

Balls and $k$-cells are convex.  
\end{definition}

\begin{definition}
Let $X$ be a metric space. Then, 
\begin{enumerate}[(a)]
\item A \textbf{neighbourhood} of $p$ is a set $N_r(p)$ consisting of all $q$ such that $d(p, q) < r$ for some $r > 0$, where $r$ is the \textbf{radius} of $N_r(p)$.

\item A point $p$ is a \textbf{limit point} of the set $E$ if \underline{every} neighbourhood of $p$ contains a point $q \ne p$ such that $q \in E$. (That is, points in $E$ get arbitrarily close to $p$.)

\item If $p \in E$ is not a limit point, it is called an \textbf{isolated point}.

\item A set $E$ is \textbf{closed} iff every limit point of $E$ is in $E$.

\item A point $p$ is an \textbf{interior point} of $E$ if there is a neighbourhood $N$ of $p$ such that $N \subseteq E$.

\item $E$ is \textbf{open} if every point in $E$ is an interior point of $E$.

\item The \textbf{complement} of $E$, denoted $E^c$, is the set of all points in $X$ but not in $E$.

\item $E$ is \textbf{perfect} if $E$ is closed and every point of $E$ is a limit point of $E$.

\item $E$ is \textbf{bounded} if there exists a real number $M$ and a point $q \in X$ such that $d(p, q) < M$ for all $p \in E$.

\item $E$ is \textbf{dense} in $X$ if every point in $X$ is a limit point of $E$, or a point of $E$ (or both). (So points in $E$ get arbitrarily close to any point in $X$).
\end{enumerate}
\end{definition}

\begin{theorem}
Every neighbourhood is an open set.

\begin{proof}
Let $E = N_r(p)$ be a neighbourhood, and $q$ be any point in $E$. Then, $d(p, q) < r$ so $d(p, q) = r - h$ for some positive $h$. Then for any $s \in N_h(q)$, we have
\[
	d(s, r) \le d(s, q) + d(q, p) < h + (r - h) = r
\]
so $s \in E$ and thus $N_h(q) \subseteq E$. Thus $E$ is open.
\end{proof}
\end{theorem}

\begin{theorem}
If $p$ is a limit point of $E$, then every neighbourhood of $p$ contains infinitely many points of $E$. 

\begin{proof}
Suppose not, so that some neighbourhood $N_r(p)$ contains finitely many points in $E$. Then, there exists some closest point $q \ne p$ in that neighbourhood with $d(q, p) = h > 0$. Then, the neighbourhood $N_{h/2}(p)$ contains no points in $E$ which are not $p$, contradicting the definition of a limit point.
\end{proof}
\end{theorem}

\begin{corollary}
A finite point set has no limit points.

\begin{proof}
If $p$ were a limit point in a finite point set $E$, then some neighbourhood must have infinitely many points in $E$, a contradiction.
\end{proof}
\end{corollary}

\begin{theorem}
Let $\{E_{\alpha}\}$ be a possibly infinite collection of sets. Then
\[
	A = \left( \bigcup_{\alpha} E_\alpha \right)^c = \bigcap_{\alpha} E_\alpha^c = B.
\]

\begin{proof}
Let $x \in A$. Since it is not in $\bigcup_\alpha E_\alpha$, $x$ is not in any of the $E_\alpha$. Thus, it is in each of the $E_\alpha^c$, so $x \in B$.

Let $y \in B$. By definition, $y$ is in $E_\alpha^c$, so it is not in any of the $E_\alpha$. Thus, $y \not\in \bigcup_\alpha E_\alpha$ so $y \in A$, completing the proof.
\end{proof}
\end{theorem}

\begin{theorem}
A set $E$ is open iff its complement is closed.

\begin{proof}
Suppose $E^c$ is not closed. Then, there exists a limit point of $E^c$, say $x$ which is not in $E^c$ (and thus in $E$). However this means that there are points in $E^c$ in neighbourhoods arbitrarily close to $x$: so no neighbourhood around $x$ will be a subset of $E$, so $E$ is not open, proving the contrapositive of the forward statement.

Now suppose $E$ is not open, so there exists some $x \in E$ for which no neighbourhood is entirely contained within $E$. Thus, every neighbourhood of $x$ contains some point in $E^c$, so $x$ is a limit point of $E^c$ not in $E^c$, so $E^c$ is not closed, proving the contrapositive of the backwards statement, completing the proof.
\end{proof}
\end{theorem}

\begin{corollary}
A set $F$ is closed iff its complement is open. \qed
\end{corollary}

\begin{theorem}
With the previous theorems, we can prove the following:
\begin{enumerate}[(a)]
\item For any possibly infinite collection $\{G_\alpha\}$ of open sets, $A = \bigcup_\alpha G_\alpha$ is open.

\item For any possibly infinite collection $\{F_\alpha\}$ of closed sets, $B = \bigcap_\alpha F_\alpha$ is closed.

\item For any finite collection $G_1, \dotsc, G_n$ of open sets, $C = \bigcap_{i=1}^{n} G_i$ is open.

\item For any finite collection $F_1, \dotsc, F_n$ of closed sets, $D = \bigcup_{i=1}^{n} F_i$ is closed.
\end{enumerate}

\begin{proof}
For (a), let $x \in A$ be arbitrary. Then, $x \in G_\alpha$ for some open set $G_\alpha$, so $N_r(x) \subseteq G_\alpha \subseteq A$. Thus, $x$ is interior in $A$ and $A$ is open. For (b), notice that $\{F_\alpha^c\}$ is a collection of open sets, so by (a), $\bigcup_\alpha F_\alpha^c = \left(\bigcap_\alpha F_\alpha\right)^c$ is open, so $B = \bigcap_\alpha F_\alpha$ is closed.

For (c), let $x \in C$. Then, there are neighbourhoods $N_{r_i}(x) \subseteq G_i$ for some positive $r_i$. Then, taking $r = \min_{i=1}^{n} r_i$, we have $N_r(x) \subseteq N_{r_i}(x) \subseteq G_i$ for each $i \in J_n$, so $N_r(x) \subseteq C$ so $x$ is interior to $C$, and thus $C$ is open. Statement (d) reduces to (c) with reasoning similar to (b).
\end{proof}
\end{theorem}

Notice that in parts (c) and (d) in the previous theorem, finiteness of the collections is essential. Otherwise, the minimum of the radii of your neighbourhoods could be 0, and no neighbourhood would exist. For instance, take $G_n = (-1/n, 1/n)$.

\begin{definition}
If $X$ is a metric space, and $E \subseteq X$ and $E'$ is the set of all limit points of $E$ in $X$, then the \textbf{closure} of $E$ is the set $\overline{E} = E \cup E'$. 
\end{definition}

\begin{theorem}
If $X$ is a metric space with $E \subseteq X$, then
\begin{enumerate}[(a)]
\item $\overline{E}$ is closed.
\item $E = \overline{E}$ iff $E$ is closed.
\item $\overline{E} \subseteq F$ for every closed set $F \subseteq X$ with $E \subseteq F$.
\end{enumerate}
Notice that (a) and (c) imply $\overline{E}$ is the \underline{smallest} closed subset of $X$ containing $E$, so the name `closure' is appropriate.

\begin{proof}
For (a), if $p \in X$ and $p \not\in \overline{E}$, then $p$ is neither a point of $E$ nor a limit point of $E$. Hence, $p$ has a neighbourhood which does not intersect $E$, so $\overline{E}^c$ is open and $\overline{E}$ is closed.

For (b), if $E$ is closed, then $E' \subseteq E$ so $\overline{E} = E$. If $\overline{E} = E$, then (a) implies $E$ is closed.

For (c), let $F \subseteq X$ be a closed set such that $E \subseteq F$. Let $x \in \overline{E}$. If $x \in E$, then clearly $x \in F$. If $x \in E'$ but not in $F$, then $x$ would be a limit point of $F \supset E$ not in $F$, contradicting the fact that $F$ is closed.
\end{proof}
\end{theorem}

\begin{theorem}
Let $E$ be a non-empty set of real numbers which is bounded above. Let $y = \sup E$, then $y \in \overline{E}$, hence $y \in E$ if $E$ is closed.

\begin{proof}
Suppose that $y$ were not in $\overline{E}$, so it is neither a point in $E$ nor a limit point of $E$, so there exists a neighbourhood $(y - \epsilon, y + \epsilon)$ which does not contain any elements in $E$. But then $y - \epsilon/2$ would be a smaller upper bound for $E$ than $y$, contradicting the minimality of $y$, proving the first statement.

Then, if $E$ is closed, $y = \sup E \in \overline{E} = E$.
\end{proof}
\end{theorem}

\begin{remark}
Suppose $E \subseteq Y \subseteq X$ where $X$ is a metric space. We say $E$ is an open subset of $X$ when every point $p \in E$ has associated to it a positive real number $r$ such that $d(p, q) < r$ implies $q \in E$. But we know $Y$ is also a metric space under the same distance function, so we can extend our definitions to $Y$.

We say $E$ is \textbf{open relative to $Y$} when to each $p \in E$, there exists a positive $r$ such that $q \in E$ whenever $d(p, q) < r$ and $q \in Y$. 
\end{remark}

\begin{theorem}
Suppose $Y \subseteq X$. Then a subset $E \subseteq Y$ is open relative to $Y$ iff $E = Y \cap G$ for some open subset $G$ of $X$. 

\begin{proof}
Suppose $E \subseteq Y$ is open relative to $Y$. Then, for every $p \in E$, we associate some positive $r_p$ such that $N_{r_p}(p) \cap Y \subseteq E$. Let $G = \bigcup_{p \in E} N_{r_p}(p) \subseteq X$. Since each $N_{r_p}(p)$ is open, the infinite union $G$ is open. Then, clearly $E \subseteq Y \cap G$. By our choice of $N_{r_p}(p)$, $N_{r_p}(p) \cap Y \subseteq E$ for each $p \in E$, so $G \cap Y \subseteq E$. Thus, $E = G \cap Y$. 

Conversely, if $G$ is open in $X$ and $E = G \cap Y$, then every $p \in E$ has a neighbourhood $N_{r_p}(p) \subseteq G$, so $N_{r_p}(p) \cap Y \subseteq E$ and thus $E$ is open relative to $Y$.
\end{proof}
\end{theorem}

\section{Compact Sets}

\begin{definition}
Let $X$ be a metric space and $E \subseteq X$. Then, an \textbf{open cover} of $E$ is a collection $\{G_\alpha\}$ of open subsets of $X$ such that $E \subseteq \bigcup_\alpha G_\alpha$. 
\end{definition}

\begin{definition}
A subset $K$ of a metric space $X$ is said to be \textbf{compact} if every open cover of $K$ contains a \underline{finite} subcover.

Formally, if $\{G_\alpha\}$ is an open cover of $K$, then there exist indices $\alpha_1, \dotsc, \alpha_n$ such that $K \subseteq G_{\alpha_1} \cup \dotsb \cup G_{\alpha_n}$. 

\end{definition}

Clearly every finite set is compact. 

\begin{theorem}
Suppose $K \subseteq Y \subseteq X$. Then $K$ is compact relative to $X$ iff $K$ is compact relative to $Y$.

\begin{proof}
Suppose $K$ is compact relative to $Y$, and we have some open cover $\{G_\alpha\}$ in $X$. Then, letting $H_\alpha = Y \cap G_\alpha$, $\{H_\alpha\}$ is still an open cover of $K$ since $K \subseteq Y$. In fact, each $H_\alpha$ is open relative to $Y$ from Theorem 20, and a subset of $Y$, so $\{H_\alpha\}$ is an open cover of $K$ in $Y$. Since $K$ is compact in $Y$, there exists some finite subcover $\{H_{\alpha_k}\}_{k=1}^{n}$ of $K$. Then, $G \subseteq \bigcup_{k=1}^{n} H_{\alpha_i} \subseteq \bigcup_{k=1}^{n} G_{\alpha_i}$ so $\{G_{\alpha_k}\}_{k=1}^{n}$ is a finite subcover of $K$. 

Now, suppose $K$ is compact relative to $X$, and we have some open cover $\{H_\alpha\}$ in $Y$. Since each $H_\alpha$ is open relative to $Y$, we can write $H_\alpha = G_\alpha \cap Y$ for some open subset $G_\alpha$ of $X$. Then, $\{G_\alpha\}$ is an open cover of $K$ in $X$ and thus a finite subcover $\{G_{\alpha_k}\}_{k=1}^{n}$ exists. Then $\{H_{\alpha_k}\}_{k=1}^{n}$ is a finite subcover of $K$ in $Y$, so $K$ is compact relative to $Y$, completing the proof.
\end{proof}
\end{theorem}

\begin{theorem}
Compact subsets of metric spaces are closed.

\begin{proof}
Let $K$ be compact in $X$. Let $x \in E^c$. For each $y \in E$, let $G_y$ be some neighbourhood of $y$ with radius less than $\frac12 d(x, y)$. Then, $\{G_y\}$ forms an open cover of $K$. Since $K$ is compact, there exist $y_1, \dotsc, y_n$ such that $G_{y_1}, \dotsc, G_{y_n}$ forms a finite subcover of $K$. 

Then, there exists a closest point $y^*$ within $y_1, \dotsc, y_n$ to $x$, with distance $r$ from $x$. Then, there are no points in $E$ closer than $r/2$ to $x$, so $E^c$ contains a neighbourhood of $x$ completely contained in $E^c$ so $E^c$ is open and thus $E$ is closed.
\end{proof}
\end{theorem}

\begin{theorem}
Closed subsets of compact sets are compact.

\begin{proof}
Let $F \subseteq K \subseteq X$ be closed relative to $X$ and $K$ compact. Then, let $\{G_\alpha\}$ be an open cover of $F$, and append the open set $F^c$ to make it an open cover of $G \subseteq X$. Then, since $K$ is compact, there exists some finite subcover $\{G_{\alpha_k}\}_{k=1}^{n}$ of $K$. Then the finite subcover without $F^c$ is also a finite subcover of $F$, so $F$ is compact.
\end{proof}
\end{theorem}

\begin{corollary}
If $F$ is closed and $K$ is compact, then $F \cap K$ is compact.

\begin{proof}
$F \cap K \subseteq K$ is closed as the finite intersection of closed sets, and thus compact by the previous theorem.
\end{proof}
\end{corollary}

\begin{theorem}
If $\{K_\alpha\}$ is a collection of compact subsets of a metric space $X$ such that the intersection of every finite subcollection of $\{K_\alpha\}$ is non-empty, then $\bigcap K_\alpha$ is non-empty. 

\begin{proof}
Let $K$ be some element of $\{K_\alpha\}$. Suppose, for the sake of contradiction, that there are no points in $K$ which are in every $K_\alpha$. That is, for every $x \in K$, there is some $K_\alpha^c$ such that $x \in K_\alpha^c$. So $K \subseteq \bigcup_\alpha K_\alpha^c$, so $\{K_\alpha^c\}$ forms an open cover of $K$, so since $K$ is compact, there exists a finite subcover $\{K_{\alpha_k}^c\}_{k=1}^{n}$ of $K$. But then $K \cap K_{\alpha_1} \cap \dotsc \cap K_{\alpha_n} = \emptyset$, contrary to our assumption.
\end{proof}
\end{theorem}

\begin{corollary}[Cantor's intersection theorem]
If $\{K_n\}$ is a sequence of non-empty compact sets such that $K_n \supseteq K_{n+1}$, then $\bigcap_{n=1}^{\infty} K_n$ is non-empty.

\begin{proof}
Notice that $K_{k_1} \cap \dotsb \cap K_{k_n} = K_k$ where $k = \max(k_1, \dotsc, k_n)$, so any finite intersection is non-empty. Thus, the result follows by applying the above theorem.
\end{proof}
\end{corollary}

\begin{theorem}
If $E$ is an infinite subset of a compact set $K$, then $E$ has a limit point in $K$.

\begin{proof}
Suppose that $E$ has no limit points in $K$. Then, every $x \in K$ will have some sufficiently small neighbourhood $N_x$ which contains at most one point in $E$. However, no finite subcollection of $\{N_x\}$ can cover $E$ and thus $K$, contradicting the fact that $K$ is compact.
\end{proof}
\end{theorem}

\begin{theorem}[Nested intervals]
If $\{I_n\}$ is a sequence of intervals in $\R$ such that $I_n \supseteq I_{n+1}$, then $\bigcap_{n=1}^{\infty} I_n$ is not empty.

\begin{proof}
Let $I_n = [a_n, b_n]$, and $A$ be the set of all $a_n$ which is non-empty and bounded above, say by $b_1$. Then, let $\alpha = \sup A$. For any $m, n$, we have $a_n \le a_{n+m} \le b_{n+m} \le b_m$, so $x \le b_m$ for any $b_m$. Thus, $x \in I_m$ for all $m$, and thus $\bigcap_{n=1}^{\infty} I_n$ is non-empty.
\end{proof}
\end{theorem}

\begin{theorem}
Let $k$ be a positive integer. If $\{I_n\}$ is a sequence of $k$-cells such that $I_n \supseteq I_{n+1}$ for all $n$, then $\bigcap_{n=1}^{\infty} I_n$ is non-empty.

\begin{proof}
Taking the intervals corresponding to each dimension, we can invoke the previous theorem to find values $x_i$ in the intersections of each of the intervals, so $\textbf{x} = (x_1, \dotsc, x_k) \in \bigcap_{n=1}^{\infty} I_n$.
\end{proof}
\end{theorem}

\begin{theorem}
Every $k$-cell is compact.

\begin{proof}
Suppose $I = [a_1, b_1] \times \dotsb \times [a_k, b_k]$. Then, let $\delta = \left| \textbf{b} - \textbf{a} \right|$, where $\textbf{a} = (a_1, \dotsc, a_k)$ and $\textbf{b} = (b_1, \dotsc, b_k)$. Then, notice that $|\textbf{x} - \textbf{y}| \le \delta$, whenever $\textbf{x}, \textbf{y} \in I$. 

Now suppose for the sake of contradiction that some open cover $\{G_\alpha\}$ admits no finite subcover of $I$. Subdividing each interval in half determines $2^k$ smaller $k$-cells whose union is $I$. At least one of these cells, $I_1$ cannot be covered by any finite subcollection of $\{G_\alpha\}$. Continue this indefinitely to get a sequence of nested intervals $\{I_n\}$, all of which cannot be covered by a finite subcollection of $\{G_\alpha\}$. 

By the previous theorem, there exists some $\textbf{x}$ in every one of these intervals, so $\textbf{x} \in G_\alpha$ for some $\alpha$. Since $G_\alpha$ is open, there must exist some neighbourhood $N_r(\textbf{x})$ completely contained in $G_\alpha$. However, since the diameter of the intervals decreases by a factor of 2 each time, for sufficiently large $n$, $I_n \subseteq N_r(\textbf{x}) \subseteq G_\alpha$, contradicting the fact that $I_n$ cannot be covered by any finite subcollection of $\{G_\alpha\}$, completing the proof.
\end{proof}
\end{theorem}

\begin{theorem}[Heine-Borel]
The following are equivalent for sets $E \subseteq \R^k$:
\begin{enumerate}[(a)]
\item $E$ is closed and bounded.
\item $E$ is compact.
\item Every infinite subset of $E$ has a limit point in $E$.
\end{enumerate}

\begin{proof}
The fact that (b) implies (c) is precisely Theorem 25. 

To show that (c) implies (a), suppose that every infinite subset of $E$ has a limit point in $E$, but $E$ is not closed and bounded. 

\begin{itemize}
\item 
If $E$ is not closed, there exists a limit point $x$ of $E$ which is not contained in $E$. We construct an infinite subset of $E$ which has only $x$ as a limit point. Let $x_1$ be an arbitrary point in $N_1(x) \cap E$ and $r_1 = d(x, x_1)$. Now, let $x_n$ be a point in $E$ which is closer than $\min(1/n, r_{n-1}/2)$ to $x$. This must exist since $x$ is a limit point. This defines a sequence $\{x_n\}$. Let $X$ be the infinite set of these points. Then clearly $x$ is a limit point of $X$. However, we still have to show that it is the only limit point of $X$. Let $y \ne x$ be another limit point. Since $d(x, y) > 0$ and the $r_n$ are monotonically decreasing, there exists some $n$ such that $r_n \le d(x, y) \le r_{n+1}$. taking $r_0 = d(x, y)$ and $r < \min(r_0 - r_n, r_0 - r_{n+1})$, the neighbourhood with radius $r$ around $y$ has no points in $X$ and is thus not a limit point of $X$. 

\item
Similarly, if $E$ is not bounded, let $w \in E$ be arbitrary. Then we can create a sequence $\{x_n\}$ such that $d(w, x_n) > n$ and $x_n \in E$. Then, if $y \in E$, then there are only finitely many $x_n$ such that $d(w, x_n) < d(w, y) + 1$, so there are not infinitely many $x_n$ in $N_1(y) \cap E$, so $y$ is not a limit point. Thus, $X$ has no limit points in $E$.

\end{itemize}

Finally, to show (a) implies (b), suppose $E$ is closed and bounded. Since $E$ is bounded, we can surround it with a sufficiently large $k$-cell $I$. That is, $E \cap I = E$ is compact, as the intersection of a closed set and a compact set.
\end{proof}
\end{theorem}

\begin{remark}
Notice that the above theorem was specific to $\R^k$. One may ask how much of the theorem extends to general metric spaces. In general, (b) and (c) are equivalent in any metric space, but (a) does not imply (b) and (c).
\end{remark}

\begin{theorem}[(Weierstrass)]
Every bounded infinite subset of $\R^k$ has a limit point in $\R^k$. 

\begin{proof}
Let $E \subseteq \R^k$ be bounded. Then, $E \subseteq I$ for some $k$-cell $I$. Since $I$ is compact, $E$ is an infinite subset of $I$ and thus has a limit point in $I \subseteq \R^k$ from the above theorem.
\end{proof}
\end{theorem}

\section{Perfect Sets}

\begin{theorem}
Let $P$ be a non-empty perfect set in $\R^k$. Then, $P$ is uncountable. 

\begin{proof}
Suppose $P$ is non-empty but not uncountable. Since $P$ has limit points, it must be infinite, and thus countable. Enumerate the points of $P$ as $x_1, x_2, \dotsc$. 

Let $V_1$ be any neighbourhood of $x_1$. Suppose we have $V_n$ such that $V_n \cap P$ is non-empty. Since every point of $P$ is a limit point of $P$, there exists some neighbourhood $V_{n+1}$ such that $\overline{V_{n+1}} \subseteq V_n$, $x_n \not\in \overline{V_{n+1}}$, and $V_{n+1} \cap P$ is non-empty. 

Put $K_n = \overline{V_n} \cap P$. Notice that $\overline{V_n}$ is closed and bounded and thus compact. The $K_n$ are thus compact as closed subsets of $\overline{V_n}$. Notice $K_n$ form a decreasing sequence of compact sets, each of which are non-empty by construction, so $\bigcap_{n=1}^{\infty}$ must be non-empty. In particular, since $K_1 \subseteq P$, there must be some $x_k$ in this intersection. However, the construction forbids this.
\end{proof}
\end{theorem}

\begin{corollary}
Every interval $[a, b]$ with $a < b$ is uncountable. In particular, the set of all real numbers is uncountable.

\begin{proof}
Every interval is perfect and thus uncountable. The set of real numbers is larger.
\end{proof}
\end{corollary}

Are combinations of intervals the only perfect sets? No: we construct a perfect set in $\R$ with no segment, the \textbf{Cantor set}. 

Let $E_0 = [0, 1]$. Remove the segment $(1/3, 2/3)$ so that $E_1 = [0, 1/3] \cup [2/3, 1]$. Removing the middle thirds indefinitely yields a decreasing sequence of compact sets, whose infinite intersection is non-empty. Call this set the Cantor set.

The Cantor set contains no segment, since every segment of the form
\[
	\left(\frac{3k + 1}{3^m}, \frac{3k + 2}{3^m}\right)
\]
has a point in common with $P$. It can be shown that every segment $(\alpha, \beta)$ shares a segment of the above form, so the Cantor set contains no segment.

To show that $P$ is perfect, let $x \in P$ and let $S$ be any segment containing $x$. Let $I_n$ be an interval chosen such that $n$ is so large that $I_n \subseteq S$. Then, let either endpoint is in $P$, so $x$ is a limit point and $P$ is perfect.

\section{Connected Sets}

\begin{definition}
Two subsets $A, B$ of a metric space $X$ are said to be \textbf{separated} if both $A \cap \overline{B}$ and $\overline{A} \cap B$ are empty. 

A set $E \subseteq X$ is said to be \textbf{connected} if it is \underline{not} a union of two non-empty separated sets.
\end{definition}

\begin{theorem}
A subset $E$ of the real line $R$ is connected iff it has the property that if $x, y \in E$ and $x < z < y$, then $z \in E$. 

\begin{proof}
Suppose otherwise, so that for some $x, y \in E$, there exists some $z \in \R$ such that $x < z < y$ but $z \not\in E$. Then we claim $A = E \cap (-\infty, z)$ and $B = E \cap (z, \infty)$ form a separating pair for $E$. 

Clearly $A \cup B = E$. Also, clearly $A$ and $B$ are non-empty, since they contain $x$ and $y$ respectively. Now, notice that everything in $\overline{A}$ is $\le z$, and everything in $B$ is $> z$. Thus, they are disjoint. A similar argument holds for the other pair. Thus, $A$ and $B$ form a separating pair for $E$, contradicting the fact that $E$ is connected.

Conversely, suppose that $E$ is not connected, and in particular admits the separation $(A, B)$.  Then, let $x \in A$ and $y \in B$, and suppose without loss of generality that $x < y$. Let $z = \sup(A \cap [x, y]) \in \overline{A}$. Since $A$ and $B$ are separated, $z \not\in B$. 

If $z \not\in A$, then $x < z < y$ but $z \not\in A \cup B = E$. Otherwise, if $z \in A$, then it mustn't be in $\overline{B}$, so there exists $z_1 \in (z, y)$ such that $z_1 \not\in B$. Then $x < z_1 < y$ with $z_1 \not\in E$. In either case, the contrapositive holds, completing the proof.
\end{proof}
\end{theorem}

\section{Exercises}
\begin{enumerate}
\item % Question 1
Prove that the empty set is a subset of every set.

\begin{proof}
The definition of set inclusion is vacuously true here.
\end{proof}

\item % Question 2
A complex number $z$ is said to be \textbf{algebraic} if there are integers $a_0, \dotsc, a_n$ not all zero such that
\[
	a_0z^n + \dotsc + a_nz^0 = 0.
\]
Prove that the set of all algebraic numbers is countable. Hint: For every positive integer $N$, there are only finitely many equations with $n + |a_0| + \dotsc + |a_n| = N$.

\begin{proof}
For any $n$, let $S_n$ be the set of tuples $(k, a_0, a_1, \dotsc, a_k)$ such that $k + |a_0| + \dotsc + |a_k| = n$. Notice that this set is finite, and that each corresponding equation can only have finitely many roots. Thus, the set of algebraic numbers $A_n$ whose polynomials map to a given $S_n$ is finite. Then, $A = \bigcup_{i=1}^{\infty} A_i$ is countable.
\end{proof}

\item % Question 3
Prove that there exist real numbers which are not algebraic.

\begin{proof}
If every real number were algebraic, there would be countably many of them, contradicting the uncountability of the reals.
\end{proof}

\item % Question 4
Is the set of all irrational real numbers countable?

\begin{proof}
If the set of irrational real numbers were countable, then $\R = \Q \cup (\R \setminus \Q)$ would be countable, contradicting the uncountability of the reals.
\end{proof}

\item % Question 5
Construct a bounded set of real numbers with exactly three limit points.

\begin{proof}
Let $A = \{k + 1/n : n \in \N, k \in \{0, 1, 2\}\}$. We claim that the limit points of $A$ are precisely 0, 1, and 2. Clearly, all three are limit points (for any $r > 0$, take $1/n < r$ by the Archimedean property of $\R$; then $k + 1/n$ is within $r$ of $k$).

Let $y \not\in \{0, 1, 2\}$. Consider $k \in \{0, 1, 2\}$. If $y < k$ or $y > k + 1$, then taking some radius smaller than the distance to $[k, k + 1]$ fails. Otherwise, we have $y - k \in [1/(n+1), 1/(n-1)]$ for some $n$. Taking a radius smaller than the distance to the nearest of the three points $k + 1/(n+1), k + 1/n, k + 1/(n-1)$ fails.
\end{proof}

\item % Question 6
Let $E'$ be the set of all limit points of a set $E$. Prove that $E'$ is closed. Prove that $E$ and $\overline{E}$ have the same limit points. (Recall that $\overline{E} = E \cup E'$.) Do $E$ and $E'$ always have the same limit points?

\item % Question 7
Let $A_1, A_2, \dotsc$ be subsets of a metric space.
\begin{enumerate}[(a)]
\item If $B_n = \bigcup_{i=1}^{n} A_i$, prove that $\overline{B_n} = \bigcup_{i=1}^{n} \overline{A_i}$. 

\begin{proof}
Let $C = \bigcup_{i=1}^{n} \overline{A_i}$. Let $x \in \overline{B_n} = B_n \cup B_n'$. If $x \in B_n$, then $x \in A_k \subseteq \overline{A_k} \subseteq C$. If $x \in B_n'$, then construct a sequence $\{x_k\}$ such that $d(x_k, x) < 1/k$ and $x_k \in B_n$. Since $\{x_n\}$ is countable, there exists at least one set $A_j$ for which $x_k \in A_j$ infinitely many times. Thus, $x \in A_j' \subseteq \overline{A_j} \subseteq C$. Putting this together, $\overline{B_n} \subseteq C$.

Now, let $y \in C$. If $y \in A_j$ for some $j$, then $y \in A_j \subseteq B_n \subseteq \overline{B_n}$. If $y \in A_j'$ for some $j$, then every neighbourhood of $y$ contains an element $y_k \in A_j \subseteq B_n$, so $y \in B_n' \subseteq \overline{B_n}$. The result follows.
\end{proof}

\item If $B = \bigcup_{i=1}^{\infty} A_i$, prove that $\overline{B} \supseteq \bigcup_{i=1}^{\infty} \overline{A_i}$. Show, by an example, that this inclusion can be proper.
\begin{proof}
Let $x \in \bigcup_{i=1}^{\infty} \overline{A_i}$, then $x \in \overline{A_j}$ for some $j$. Either $x \in A_j \subseteq B \subseteq \overline{B}$, or $x \in A_j'$, so there are elements $x_k \in A_j \subseteq B$ in every neighbourhood of $x$, ie. $x \in \overline{B}$.

The inclusion can be proper: let $A_n$ be the set of rationals such that $q = m/n$ in lowest form. Then, $B = \Q$, whose closure is $\R$, whereas the right side is still $\Q$, as $\overline{A_i} = A_i$ for all $i$.
\end{proof}
\end{enumerate}

\item % Question 8
Is every point of every open set $E \subseteq \R^2$ a limit point of $E$? Answer the same question for closed sets in $\R^2$.

\begin{proof}
For open sets, yes. Every interior point has a neighbourhood completely contained within $E$, so every smaller neighbourhood will contain (infinitely many) points in $E$. The same is not true in general for closed sets. For example, consider $\{(0, 1/n): n \in \N\} \cup \{(0, 0)\}$, in which $1$ is not a limit point. 
\end{proof}

\item % Question 9
Let $E^\circ$ denote the set of all interior points of a set $E$, called the \textbf{interior} of $E$.
\begin{enumerate}[(a)]
\item Prove that $E^\circ$ is always open.
\begin{proof}
This is immediate.
\end{proof}

\item Prove that $E$ is open iff $E^\circ = E$.
\begin{proof}
If $E$ is open, then every point in $E$ is interior, so $E^\circ = E$. Similarly, if $E = E^\circ$, then $E$ is open from (a).
\end{proof}

\item If $G \subseteq E$ and $G$ is open, prove that $G \subseteq E^\circ$. 
\begin{proof}
Let $x \in G$. Then $x$ is an interior point of $G \subseteq E$, and thus an interior point of $E$.
\end{proof}

\item Prove that the complement of $E^\circ$ is the closure of the complement of $E$.
\begin{proof}
Let $x \not\in E^\circ$, so $x$ is not an interior point of $E$. So every neighbourhood of $x$ is not completely contained in $E$, so there exists a point in $E^c$ in every neighbourhood of $x$. In other words, $x \in {E^c}' \subseteq \overline{E^c}$. 

Now let $y \in \overline{E^c}$. If $y \in E^c$, then $y \not\in E^\circ \subseteq E$. If $y \in {E^c}'$, then every neighbourhood of $y$ contains an element of $E^c$, and thus no neighbourhood of $y$ is completely contained in $E$, so $y \not\in E^\circ$.
\end{proof}

\item Do $E$ and $\overline{E}$ always have the same interiors?
\begin{proof}
No: let $A = \{1/n : n \in \N\} \cup \{0\}$ be a subset of $\R$ and let $E = A^c$ . Then, $\overline{E} = \R$ so its interior is $\R$. However, 0 is not an interior point of $E$: every neighbourhood contains at least one point $1/n$ not in $E$. 
\end{proof}

\item Do $E$ and $E^\circ$ always have the same closures?
\begin{proof}
No: consider $E = \Q$. Then $\overline{E} = \R$ and $E^\circ = \emptyset$, whose closure is also empty.
\end{proof}
\end{enumerate}

\item % Question 10
Let $X$ be an infinite set. For $p, q \in X$, define $d(p, q) = 1 - \delta_{p, q}$. Prove that this is a metric. Which subsets of the resulting metric space are open? Which are closed? Which are compact?

\begin{proof}
By definition, $d(p, q) \ge 0$, with equality iff $p = q$. Now let $p, q, r \in X$. Then if $p \ne r$, then $d(p, r) = 1$, while $d(p, q) + d(q, r)$ is at least 1, since at least one of the terms must be non-zero. If $p = r$, then either $q = r = p$ in which case equality holds, or $q \ne r$, in which case $0 \le 2$. Thus $d$ is a metric.

Notice that for any $E \subseteq X$, a neighbourhood of size $1/2$ around any point $x \in E$ consists only of the point $x$ (any other point has $d(x, y) = 1 > 1/2$). Thus every point in any set $E$ is an interior point, so every set is open. Similarly, considering any set $F \subseteq X$, $F^c$ is open, so $F$ is closed. 

Now, notice that finite sets are always compact. Infinite sets can be covered by singletons, but thus admit no finite subcover. Thus, a set in $X$ is compact iff it is finite. 
\end{proof}

\item % Question 11
For $x, y \in \R$, define
\begin{align*}
	d_1(x, y) &= (x - y)^2 \\
	d_2(x, y) &= \sqrt{|x - y|} \\
	d_3(x, y) &= |x^2 - y^2| \\
	d_4(x, y) &= |x - 2y| \\
	d_5(x, y) &= \frac{|x - y|}{1 + |x - y|}.
\end{align*}
Determine, for each of these, whether it is a metric or not.

\begin{proof}
We prove them individually:
\begin{enumerate}[${d}_1(x, y)$:]
\item This is not a metric: it violates the Triangle inequality with $(x, y, z) = (0, 1, 2)$.
\item This is a metric: this is clearly non-negative, and zero iff $|x - y| = 0$ and thus $x = y$. Also, the Triangle inequality holds.
\item This is not a metric since $d(-1, 1) = 0$ while $1 \ne -1$.
\item This is not a metric since $d(2, 1) = 0$ while $2 \ne 1$.
\item Maybe.
\end{enumerate}
\end{proof}

\item % Question 12
Let $K = \{1/n : n \in \N\} \cup \{0\} \subseteq \R$. Prove that $K$ is compact without invoking Heine-Borel.

\begin{proof}
Let $\{G_\alpha\}$ be any open cover of $K$. Then, $0 \in K$ is in some $G_\alpha$, and since $G_\alpha$ is open, there must exist some neighbourhood $N_r(0) \subseteq G_\alpha$. Thus, if $n > 1/r$, $1/n \in G_\alpha$. Taking this, and one open set for each of the remaining $1/n$ yields a finite cover for $K$.
\end{proof}

\item % Question 13
Construct a compact set of real numbers whose limits form a countable set.

\begin{proof}
Let $A = \{(1 + 2^{-m}) / n: m, n \in \N\}$. Notice that $\{1/n : n \in \N\} \cup \{0\} \subseteq A'$. We claim these are the only limit points. Let $y \in [0, 2]$ not in the above set of limit points. Then, $\frac{1}{n + 1} < y < \frac{1}{n}$ for some $n$. Now for every $k > n$ in $\N$, $\frac{1}{m_k + 1} < y - \frac{1}{k} \le \frac{1}{m_k}$ for some $m_k \in \N$. Notice that as $k$ increases, $m_k$ decreases, so the interval $\left[\frac{1}{m_k + 1}, \frac{1}{m_k}\right]$ only gets larger. Thus, there are no elements in 
\[
	A \cap \left( \frac{1}{n + 1} + \frac{1}{m_{n+1} + 1}, \frac{1}{n + 1} + \frac{1}{m_{n+1}} \right), 
\]
a neighbourhood of $y$ by construction. Thus $y$ is not a limit point, and thus $A$ has countably many limit points. 
\end{proof}

\item % Question 14
Give an example of an open cover of the segment $(0, 1)$ which has no finite subcover.

\begin{proof}
Let $G_n = (1/(n+2), 1/n)$ for $n \in \N$. This is a cover since for any $r \in (0, 1)$, there exists $n$ such that $1/(n + 2) < r < 1/n$ so $r \in G_n$. However, notice that $1/(n + 1)$ is \underline{only} in $G_n$, so every subcover of $(0, 1)$ would have to contain $G_n$ for every $n \in \N$, forcing it to be countable, as required.
\end{proof}

\item % Question 15
Show that Cantor's intersection theorem becomes false if the condition of compactness is weakened to either solely closed or bounded.

\begin{proof}
Suppose the restriction is weakened to closed sets. Then let $K_r = \{x \in \R : x \le r\}$, each of which is closed. Also, 
\[
	K_{a_1} \cap \dotsc \cap K_{a_n} = K_{\min(a_1, \dotsc, a_n)} \ne \emptyset
\]
but $\bigcap_{r \in \R} K_r = \emptyset$.

Now let $F_k = (0, 1/k)$ be bounded sets. Then
\[
	F_{k_1} \cap \dotsc \cap F_{k_n} = F_{\max(k_1, \dotsc, k_n)} \ne \emptyset
\]
but $\bigcap_{k \in \N} F_k = \emptyset$.
\end{proof}

\item % Question 16
Regard $\Q$ as a metric space with $d(p, q) = |p - q|$. Let $E$ be the set of all $p \in \Q$ with $2 < p^2 < 3$. Show that $E$ is closed and bounded in $\Q$ but not compact. Is $E$ open in $\Q$?

\begin{proof}
$E$ is bounded below and above by 1 and 2 respectively. Also, $E$ is closed since $\Q$ is dense in $\R$. To show $E$ is not compact, we employ a similar construction as in Exercise 14. $E$ is open in $\Q$, since a neighbourhood sufficiently small can be chosen around every point, completely contained in $E$.
\end{proof}

\item % Question 17
Let $E$ be the set of all $x \in [0, 1]$ whose decimal expansion contains only the digits 4 and 7. Is $E$ countable? Is $E$ dense in $[0, 1]$? Is $E$ compact? Perfect?

\begin{proof}
$E$ is uncountable: there is a bijection between $E$ and the real numbers between 0 and 1, simply by replacing 4's with 0's and 7's with 1's and interpreting the resulting string as a binary expansion. $E$ is not dense in $[0, 1]$ since there are no elements of $E$ in $(0.5, 0.6)$, as the first digit will always be 5. $E$ is clearly bounded. 

Suppose that $x$ contained a digit other than 4 or 7. That is, suppose $x = 0.x_1 x_2 x_3 \dots x_k\dots$ with $x_k \not\in \{4, 7\}$. Then, choosing a neighbourhood of size $2 \cdot 10^{-(k+1)}$ assures that either $x_k$ or $x_{k+1}$ will not be either a 4 or a 7. Thus, the neighbourhood will contain no elements in $E$. Thus, the contrapositive states that every limit point of $E$ must be in $E$, so $E$ is closed and thus compact.

Let $x \in E'$. We can find elements $x_n$ in $E$ arbitrarily close to $x$ by switching the $n$-th digit between a 4 and a 7, acquiring elements in $E$ which are a distance $3 \cdot 10^{-n}$ from $x$. Thus, $E$ is also perfect.
\end{proof}

\item % Question 18
Is there a non-empty perfect set in $\R$ which contains no rational number?

\begin{proof}
Yes: enumerate the rational numbers between 0 and 1 as $q_n$. Then, let $A$ be the set of real numbers between 0 and 1 such that the $n$-th ternary digit of any $x \in A$ is chosen to be different from the $n$-th ternary digit of $q_n$. In this way, $A$ contains no rational numbers.

$A$ is non-empty: this must be the case if $[0, 1]$ is to be uncountable. $A$ is closed: suppose $x$ is a limit point of $A$ so that we can find elements of $A$ arbitrarily close to $x$. In particular, we can find elements of $A$ whose fist $n$ ternary digits match. If $x$ were not in $P$, then there would be some $n$ for which $x_n = (q_n)_n$, but we can find some element of $P$ which matches $x$ to more than $n$ digits, a contradiction. Finally, $A$ is perfect since we can always generate close elements in $P$ to any $x$ by choosing the other possibility for any one of the digits. 
\end{proof}

\item % Question 19
Prove the following:
\begin{enumerate}
\item If $A, B$ are closed and disjoint in some metric space $X$, they are separate.

\begin{proof}
Since $A$ and $B$ are closed, $A = \overline{A}$ and $B = \overline{B}$, so $(A, \overline{B})$ and $(\overline{A}, B)$ are both disjoint sets (they are both $(A, B)$).
\end{proof}

\item Prove the same for disjoint open sets.
\begin{proof}
Suppose otherwise, and without loss of generality, suppose $x \in \overline{A} \cap B$. Then, some neighbourhood of $x$ is completely contained in $B$. Also, there exists some element of $A$ in this neighbourhood, so there exists $y \in A \cap B$, contradicting the disjointness of $A$ and $B$.
\end{proof}

\item Fix $p \in X$, $\delta > 0$, and define $A = \{q \in X: d(p, q) < \delta\}$. Define $B$ similarly, with $>$ instead of $<$. Show $A$ and $B$ are separated.

\begin{proof}
If $B$ is empty, we are done. (Notice $A$ is never empty: $p \in A$).

Let $\alpha = \sup_{q \in A} d(p, q)$, which exists since the set is bounded above by $\delta$. Similarly, let $\beta = \inf_{q \in B} d(p, q)$, since the set is bounded below by $\delta$ and non-empty by assumption. We have $\alpha \le \delta \le \beta$. Now $\overline{A} = \{q \in X: d(p, q) \le \alpha\}$ and $\overline{B} = \{q \in X: d(p, q) \ge \beta\}$, so the result follows since $\alpha \le \beta$ so the required sets are disjoint.
\end{proof}
\item Prove that every connected metric space with at least two points is uncountable. Hint: Use (c).

\begin{proof}
Suppose $a, b$ are distinct elements of a connected metric space $X$. Let $\delta = d(\alpha, \beta) > 0$. Then, for every $r \in (0, \delta)$, let $A_r$ and $B_r$ be the sets of elements of $X$ with distance less than, or greater than respectively, $r$. Then, there must be an element $z_r$ in $X$ with $d(z_r, a) = r$, otherwise $A_r$ and $B_r$ form a separation of $X$, as in (c). Thus, there exists an injection from the uncountable set $(0, \delta)$ to $X$ so $X$ is uncountable.
\end{proof}
\end{enumerate}

\item % Question 20
Are closures and interiors of connected sets always connected? (Look at subsets of $\R^2$.)

\begin{proof}
Closures of connected sets are connected. Suppose $E$ is connected but $\overline{E}$ is not. Then, $\overline{E}$ admits a separation $(A, B)$. Then, $(A \cap E, B \cap E)$ forms a separation of $E$, a contradiction. However, this is not the same for interiors: take $A = N_1(-2) \cup N_1(2) \cup L(-2, 2) \subseteq \C$ where $L(a, b)$ is the line segment between $a$ and $b$. Then $A^\circ = N_1(-2) \cup N_1(2)$ which is disconnected.
\end{proof}

\item % Question 21
Let $A, B$ be separated subsets of $\R^k$. Suppose $a \in A$, $b \in B$, and define $p(t) = (1 - t)a + tb$ for $t \in \R$. Put $A_0 = p^{-1}(A)$ and $B_0 = p^{-1}(B)$.

\begin{enumerate}
\item Prove that $A_0$ and $B_0$ are separated subsets of $\R^1$. 
\begin{proof}
Notice firstly that both sets are non-empty as they contain $0$ and $1$ respectively. Now suppose, for the sake of contradiction that $t \in \overline{A_0} \cap B_0$, so that there are $t_0$ arbitrarily close to $t$ in $A_0$, and also $t \in B_0$. This implies there are $p(t_0)$ arbitrarily close to $p(t)$ in $A$ and also $p(t) \in B$, so $p(t) \in \overline{A} \cap B$, contradicting the fact that $A, B$ are separated.
\end{proof}
\item Prove that there exists $t_0 \in (0, 1)$ such that $p(t_0) \not\in A \cup B$.
\begin{proof}
Suppose otherwise, so that $A_0 \cup B_0 = [0, 1]$. Let $\beta = \inf B_0 \in \overline{B_0}$. We know $\beta \not\in A_0$ since $A_0 \cap \overline{B_0} = \emptyset$. However, since $A_0 \cup B_0 = [0, 1]$, there are points in $A_0$ arbitrarily close to $\beta$. This implies $\beta \in \overline{A_0}$ so $\beta \not\in B_0$. This implies $\beta \not\in A_0 \cup B_0 = [0, 1]$ which is impossible, forming our desired contradiction.
\end{proof}

\item Prove that every convex subset of $\R^k$ is connected.
\begin{proof}
If a subset $E$ were not connected, then the above construction shows that there exists an incomplete line in $E$, so it fails to be convex.
\end{proof}
\end{enumerate}

\item % Question 22
A metric space is called \textbf{separable} if it contains a countable dense subset. Show that $\R^k$ is separable. Hint: Consider the set of points which have only rational coordinates.

\begin{proof}
Let $\Q^k$ be the set of $k$-tuples of rational numbers. Notice that in every open ball, we can completely enclose a $k$-cell. This $k$-cell is determined by $k$ intervals in $\R$, each of which contain a rational number since $\Q$ is dense. Taking these as coordinates yields an element of $\Q^k$ in the original neighbourhood. Now $\Q^k$ is countable by an earlier theorem, so $\R^k$ is separable.
\end{proof}

\item % Question 23
A collection $\{V_\alpha\}$ of open subsets of $X$ is said to be a \textbf{base} for $X$ if the following is true: For every $x \in X$ and every open set $G \subseteq X$ containing $x$, we have $x \in V_\alpha \subseteq G$ for some $\alpha$. In other words, every open set in $X$ is the union of a subcollection of $\{V_\alpha\}$.

Prove that every separable metric space has a \underline{countable} base. Hint: take all neighbourhoods with rational radius and center in some countable dense subset of $X$.

\begin{proof}
As the hint suggests, take $\{V_\alpha\} = \{N_r(x): x \in D, r \in \Q\}$, for some countable dense subset $D$ of $X$. Then, let $G$ be an open set. Then, $G$ is the union of all the elements of $\{V_\alpha\}$ which are subsets of $G$. This works since $\R$ satisfies the least-upper-bound property, so a sequence of rationals can approximate any radius arbitrarily closely). Also, $\{V_\alpha\}$ is countable since there exists a surjection from it to $D \times \Q$ which is countable.
\end{proof}

\item % Question 24
Let $X$ be a metric space in which every infinite subset has a limit point. Prove that $X$ is separable.

\begin{proof}
Fix $\delta > 0$ and pick $x_1 \in X$. Then, choose $x_{j+1} \in X$ inductively such that $d(x_i, x_{j+1}) \ge \delta$ for $i = 1, \dotsc, j$, if possible. This process must terminate after a finite number of steps, otherwise the set $A = \{x_n : n \in \N\}$ is an infinite set without a limit point. Then, $X$ can be covered by finitely many neighbourhoods of size $\delta$. 

Take $\delta = 1/n, n \in \N$. Then, let $K$ be the union of all the sets of centers ($x_i$) in the above construction, for each $\delta = 1/n$. We claim $K$ is dense. Let $x \in X$ and $r > 0$. We aim to find some $y \in N_r(x) \cap Y$. Let $n \in \N$ such that $1/n < r$. If no elements of $K$ are in $N_{1/n}(x) \subseteq N_r(x)$, then the above construction for $x_i$ could have proceeded one more step, contradicting our construction. Thus $K$ is a countable dense set in $X$, so $X$ is separable.
\end{proof}

\item % Question 25
Prove that every compact metric space $K$ has a countable base, and that $K$ is therefore separable. Hint: For every positive integer $n$, there are finitely many neighbourhoods of radius $1/n$ whose union covers $K$.

\begin{proof}
For $n \in \N$, consider the cover $\{N_{1/n}(x): x \in K\}$. Since $K$ is compact, some finite subset of these neighbourhoods must cover $K$. From the same conclusion as in Exercise 24, the set $G$ of all the centres of the neighbourhoods for $n \in \N$ forms a countable dense set in $K$, so $K$ is separable.
\end{proof}

\item % Question 26
Let $X$ be a metric space in which every infinite subset has a limit point. Prove that $X$ is compact. 

\begin{proof}
By Exercise 24, $X$ is separable. By Exercise 23, $X$ has a countable base, say $\{V_n\}$. Then every open cover of $X$ has a countable subcover $\{G_n\} \subseteq \{V_n\}$. Suppose that there exists no finite subcover of $\{G_n\}$ which covers $X$. Then, the complement $F_n = \left( G_1 \cup \dotsc \cup G_n\right)^c$ is non-empty for each $n$ but $\bigcap F_n$ is empty. Let $E$ be a set which contains a point from each $F_n$, and let $x \in X$ be a limit point of $E$, which exists by presumption. But then $x \not\in G_n$ for any $G_n$, a contradiction.
\end{proof}

\item % Question 27
Define a point $p$ in a metric space $X$ to be a \textbf{condensation point} of a set $E \subseteq X$ if every neighbourhood of $p$ contains uncountably many points of $E$.

Suppose $E \subseteq \R^k$ is uncountable, and let $P$ be the set of all condensation points of $E$. Prove that $P$ is perfect and that at most countably many points of $E$ are not in $P$. In other words, show that $P^c \cap E$ is at most countable. Hint: Let $\{V_n\}$ be a countable base of $\R^k$, let $W$ be the union of those $V_n$ for which $E \cap V_n$ is at most countable, and show that $P = W^c$.

\begin{proof}
We follow the construction of $W$ outlined in the hint. Let $x \in W^c$. Then $x$ is not in any $V_n$ for which $E \cap V_n$ is at most countable. In fact, this means that if $x \in V_n$, then $E \cap V_n$ must be uncountable. Now consider $N_r(x)$. It is an open set, so it can be written as the union of some subcollection $V_{n_1} \cup \dotsc \cup V_{n_k}$ of $\{V_n\}$, of which each $V_{n_i} \cap E$ is uncountable. So $N_r(x) \cap E \supseteq V_{n_1} \cap E$ is an uncountable set, so $x \in P$.

Now, let $y \in W$, so $y \in V_n$ for some $n$ such that $E \cap V_n$ is at most countable. Then, $V_n$ contains some neighbourhood of $y$ which contains at most countably many points in $E$, so $y \not\in P$. Thus $W \subseteq P^c$ and so $P \subseteq W^c$, so we conclude $P = W^c$. 

The fact that $P^c \cap E = W \cap E$ is at most countable follows by construction. Now we claim $W^c$ is perfect. The fact that $W^c$ is closed follows directly from the fact that it is the complement of a countable union of open sets. It suffices to show that each point of $W^c$ is a limit point of $W^c$. Let $x \in W^c$. If some neighbourhood of $x$ did not contain any points in $W^c$, then there must be only points in $W \cap E$. However, there are at most countably many of these points, and any neighbourhood of $x$ is uncountable. Thus the result follows.
\end{proof}

\item % Question 28
Prove that every closed set in a separable metric space is the union of a (possibly empty) perfect set and a set which is most countable. (Corollary: Every countable closed set in $\R^k$ has isolated points.) Hint: Exercise 27.

\begin{proof}
If $F$ is at most countable, we are done. Otherwise, if $F$ is uncountable, the proof from Exercise 27 extends to $F \subseteq X$, so if $P$ is the set of condensation points of $F$, then $F = P \cup (F \setminus P)$ with $F \setminus P$ at most countable, as required.

For the corollary, let $E$ be a countable closed set in the separable metric space $\R^k$. If it had no isolated points, it would be perfect and thus uncountable, a contradiction.
\end{proof}

\item % Question 29
Prove that every open set in $\R$ is the union of an at most countable collection of disjoint segments. Hint: Exercise 22.

\begin{proof}
Let $A$ be open. For every $x$, let $I_x = (a, b)$ be the largest segment in $A$ containing $x$. That is, let $a = \inf\{z: (z, x) \in A\}, b = \sup\{y: (x, y) \subseteq A\}$ in the extended reals $\overline{\R}$. Then, $a, b \not\in A$ otherwise a larger interval exists (since $A$ is open). Also, every $c \in (a, b)$ must be in $A$ as otherwise if $x \le c$, there would exist some $x \le c < y < b$ for which $(x, y) \not\subseteq A$ and similarly for the other case. 

Now, if $(a, b)$ and $(c, d)$ share at least one point, then $c < b$ and $d > a$. Since $a, c \not\in A$, we must have $a \ge c$ and $c \ge a$, so $a = c$. Similarly $b = d$ so the intervals are the same. That is, if two intervals share any point, they must be the same interval. Now, every interval $I_x$ contains at least one rational since $\Q$ is dense, so there exists an injection from our set of open sets to the countable set of rational numbers. Thus, our set is countable, as required.
\end{proof}

\item % Question 30
Imitate the proof of Theorem 31 to obtain the following result:

If $\R^k = \bigcup_{n=1}^{\infty} F_n$ where $F_n$ is a closed subset of $\R^k$, then at least one $F_n$ has a non-empty interior.

Equivalently: If $G_n$ are dense open subsets of $\R^k$, then $\bigcap_{n=1}^{\infty} G_n$ is not empty (in fact, it is dense in $\R^k$).

(This is a special case of Baire's theorem; see Exercise 3.22 for the general case).

\begin{proof}
Let $x_1 \in G_1$, so it has a neighbourhood $V_1$ whose closure is in $G_1$. Since $G_2$ is dense, $V_1$ contains a point $x_2$ in $G_2$ for which there exists a neighbourhood whose closure is completely in $V_1 \cap G_2$. Repeat this process indefinitely, choosing $x_n$ in $V_{n-1} \cap G_n$ and some neighbourhood $V_n$ around it whose closure is completely contained in $V_{n-1} \cap G_n$. This yields a nested sequence of non-empty closed and bounded sets $\{\overline{V_n}\}$, so $\bigcap_{n=1}^{\infty} \overline{V_n}$ is non-empty. But inductively
\[
	\overline{V_n} \subseteq V_{n-1} \cap G_n \subseteq \overline{V_{n-1}} \cap G_n \subseteq \left[\bigcap_{k=1}^{n-1} G_k\right] \cap G_n = \bigcap_{k=1}^{n} G_k
\]
so any element in $\bigcap_{n=1}^{\infty} \overline{V_n}$ is also in $\bigcap_{k=1}^{\infty} G_k$, so the latter is non-empty, proving the given equivalent statement.
\end{proof}
\end{enumerate}

\chapter{Numerical Sequences and Series}

\section{Convergent Sequences}
\begin{definition}
A sequence $\{p_n\}$ in a metric space $X$ \textbf{converges} if there exists $p \in X$ such that for every $\epsilon > 0$, there exists an integer $N$ such that $n \ge N$ implies $d(p_n, p) < \epsilon$. In this case, we say $p$ \underline{is the limit of} $\{p_n\}$, or $p_n \to p$, or $\lim_{n \to \infty} p_n = p$. A sequence which does not converge \textbf{diverges}. A sequence is \textbf{bounded} if its range is bounded.
\end{definition}

We prove some important properties of convergent sequences in metric spaces.

\begin{theorem} % Theorem 3.2
Let $\{p_n\}$ be a sequence in a metric space $X$. 
\begin{enumerate}[(a)]
\item $\{p_n\}$ converges to $p \in X$ iff every neighbourhood of $p$ contains all but finitely many $n$.
\item If $p, p' \in X$ and $\{p_n\}$ converges to both $p$ and $p'$, then $p = p'$. 
\item If $\{p_n\}$ converges, then it is bounded.
\item If $E \subseteq X$ and $p$ is a limit point of $E$, then there is a sequence $\{p_n\}$ in $E$ such that $p_n \to p$. 
\end{enumerate}

\begin{proof}
For (a), suppose that $p_n \to p$. Then every neighbourhood of size $\epsilon > 0$ must contain all $p_n$ for some $n \ge N$ by definition. Now suppose every neighbourhood of $p$ contains all but finitely many $p_n$. Then for any $\epsilon > 0$, the neighbourhood of size $\epsilon$ contains all but finitely many $p_n$, so there exists $N$ such that $n \ge N$ implies $p_n \in N_\epsilon(x)$. 

For (b), if $p \ne p'$, then $d(p, p') = r > 0$. Selecting $\epsilon < r/2$ will force all but finitely many $p_n$ lie in $N_{r/2}(p) \cap N_{r/2}(p') = \emptyset$, a contradiction.

For (c), let $N$ such that $n \ge N$ implies $d(p, p_n) < 1$. Then, $d(p, p_n) \le \max\{d(p, p_1), \dotsc, d(p, p_{N-1}), 1\}$.

For (d), take $p_n$ to be some element of $E$ in $N_{1/n}(p)$, which exists since $p$ is a limit point of $E$. This converges to $p$, given $N > 1/\epsilon$. 
\end{proof}
\end{theorem}

The following theorem states we can combine convergent sequences the way we expect. 

\begin{theorem} % Theorem 3.3
Suppose $\{s_n\}, \{t_n\}$ are complex sequences and $s_n \to s, t_n \to t$.
\begin{enumerate}[(a)]
\item $(s_n + t_n) \to s + t$.
\item $cs_n \to cs$, $c + s_n \to c + s$.
\item $s_nt_n \to st$.
\item $1/s_n \to 1/s$ given $s_n, s \ne 0$.
\end{enumerate}

\begin{proof}
For (a), let $\epsilon > 0$ be arbitrary and choose $N_s, N_t$ such that $n \ge N_s$ ($n \ge N_t$) implies $|s_n - s| < \epsilon/2$ ($|t_n - t| < \epsilon/2$). Then, if $n \ge \max(N_s, N_t)$,
\[
	|s_n + t_n - (s + t)| \overset{\Delta}{\le} |s_n - s| + |t_n - t| < \epsilon
\]
and the result follows.

For the first part of (b), if $c = 0$, the result is immediate. Otherwise, let $\epsilon > 0$ and $N \in \N$ such that $n \ge N$ implies $|s - s_n| < \epsilon/|c|$. Then $n \ge N$ implies $|cs - cs_n| < \frac{|c| \epsilon}{|c|} = \epsilon$, completing the proof. The second part is similarly easy.

For (c), we use the following manipulation:
\[
	s_nt_n - st = s_nt_n - s_nt + s_nt - st = s_n(t_n - t) + (s_n - s)t
\]
Choose $N_s$ such that $n \ge N_s$ implies $|s_n - s| < \epsilon/2|t|$ and $N_t$ such that $n \ge N_t$ implies $|t_n - t| < \epsilon/2S$, where $S = \max_{n\in\N} |s_n|$. Then, if $n \ge \max(N_s, N_t)$, 
\[
	|s_nt_n - st| = |s_n(t_n - t) + (s_n - s)t| \le |s_n(t_n - t)| + |(s_n - s)t| = |s_n||t_n - t| + |s_n - s||t| \le S \cdot \frac{\epsilon}{2S} + \frac{\epsilon}{2|t|} \cdot |t| = \epsilon
\]
as required. If $|t| = 0$, then choose $N_s$ such that $n \ge N_s$ implies $|t_n| < \epsilon / S$, and the result follows.

For (d), we can use (c) to conclude $(1/s_n) s_n \to 1$, and since $s_n \to s$, we must have $1/s_n \to 1/s$.
\end{proof}
\end{theorem}

\begin{theorem} % Theorem 3.4
The following statements are true:
\begin{enumerate}
\item Suppose $\textbf{x}_n \in \R^k$ and $\textbf{x}_n = (\alpha_{1,n}, \dotsc, \alpha_{k,n})$. Then $\{\textbf{x}_n\}$ converges to $\textbf{x} = (\alpha_1, \dotsc, \alpha_k)$ iff each $\{\alpha_{i,n}\}$ converges to $\alpha_i$.

\item Suppose $\{\textbf{x}_n\}, \{\textbf{y}_n\}$ are sequences in $\R^k$, and $\{c_n\}$ is a sequence of real numbers, and $\textbf{x}_n \to \textbf{x}$, $\textbf{y}_n \to \textbf{y}$, and $c_n \to c$. Suppose further that $\textbf{x}_n = (\alpha_{1,n}, \dotsc, \alpha_{k,n})$ and $\textbf{y}_n = (\beta_{1,n}, \dotsc, \beta_{k,n})$. 

Then,
\[
	\textbf{x}_n + \textbf{y}_n \to \textbf{x} + \textbf{y},\ \textbf{x}_n \cdot \textbf{y}_n \to \textbf{x} \cdot \textbf{y},\ c_n\textbf{x}_n \to c \textbf{x}
\] 
\end{enumerate}
\begin{proof}
For (a), suppose $\{\textbf{x}_n\}$ converges to $\textbf{x}$. So for $\epsilon > 0$, we can choose $N \in \N$ such that $n \ge N$ implies $|\textbf{x}_n - \textbf{x}| < \epsilon$. Then for any $i$, $|\alpha_{i,n} - \alpha_i| < \epsilon$ and the result follows.

Suppose each $\{\alpha_{i,n}\}$ converges to $\alpha_i$. Let $\epsilon > 0$. For each $i$, we can choose $N_i \in \N$ such that $|\alpha_{i,n} - \alpha_i| < \epsilon/\sqrt{k}$ so that if $n \ge \max(N_1, \dotsc, N_k)$, then
\[
	|\textbf{x}_n - \textbf{x}| = \sqrt{\sum_{i=1}^{k} |\alpha_{i,n} - \alpha_i|^2} \le \sqrt{k \cdot \frac{\epsilon^2}{k}} = \epsilon,
\]
completing the proof.

For the first part of (b), 
\[
	(\textbf{x}_n + \textbf{y}_n)_{i} = \alpha_{i,n} + \beta_{i,n} \to \alpha_i + \beta_i = (\textbf{x} + \textbf{y})_i
\]
so the result follows from part (a).

For the second part, 
\[
	\textbf{x}_n \cdot \textbf{y}_n = \sum_{i=1}^{k} \alpha_{i,n} \beta_{i,n} \to \sum_{i=1}^{k} \alpha_i \beta_i = \textbf{x} \cdot \textbf{y}.
\]

For the final part,
\[
	(\beta_n \textbf{x}_n)_i = \beta_n \alpha_{i,n} \to \beta \alpha_i = (\beta \textbf{x})_i
\]
so the result follows from part (a).
\end{proof}
\end{theorem}

\begin{definition} % Question 3.5
Given a sequence $\{p_n\}$, consider an increasing sequence of positive integers $\{n_k\}$. Then the sequence $\{p_{n_k}\}$ is a \textbf{subsequence} of $\{p_n\}$. If $\{p_{n_k}\}$ converges, its limit is called a \textbf{subsequential limit} of $\{p_n\}$.
\end{definition}

\begin{theorem} % Theorem from Def 3.5
$\{p_n\}$ converges to $p$ iff every subsequence of $\{p_n\}$ converges to $p$. 

\begin{proof}
Suppose $p_n \to p$. Then for any $\epsilon > 0$, there exists $N \in \N$ such that $n \ge N$ implies $|p_n - p| < \epsilon$. Then if $\{p_{n_k}\}$ is a subsequence of $p_n$, then there exists some $K \in \N$ such that $k \ge K$ implies $n_k \ge N$. So for $k \ge K$, we have $|p_{n_k} - p| < \epsilon$. 

If every subsequence of $p_n$ converges to $p$, then in particular, the subsequence with $n_k = k$ (the entire sequence) converges, so we are done!
\end{proof}
\end{theorem}

\begin{theorem} % Theorem 3.6
The following are true:
\begin{enumerate}
\item If $\{p_n\}$ is a sequence in a compact metric space $X$, then some subsequence of $\{p_n\}$ converges to a point of $X$.

\item Every bounded sequence in $\R^k$ contains a convergent subsequence.

\begin{proof}
For (a), let $K$ be the image of $\{p_n\}$. Then if $K$ is finite, there exists some $p \in K$ which is attained infinitely often. The subsequence of these points converges to $p$. Otherwise, $K$ is an infinite subset of a compact metric space, and thus admits a limit point in $X$. The result follows from Theorem 3.2(d).

The result in (b) follows from (a) since bounded subsets of $\R^k$ lie inside a compact subset of $\R^k$ (namely the closure of the image of the sequence). 
\end{proof}
\end{enumerate}
\end{theorem}

\begin{theorem} % Theorem 3.7
The subsequential limits of a sequence $\{p_n\}$ in a metric space $X$ form a closed subset of $X$.

\begin{proof}
Let $E^*$ be the set of all subsequential limits of $\{p_n\}$ and let $q$ be a limit point of $E^*$. Choose $n_1$ such that $p_{n_1} \ne q$. If this doesn't exist, $E^*$ has one point and we are done. Put $\delta = d(q, p_n)$. Then build $n_k$ inductively, so that given $n_1, \dotsc, n_{i-1}$, we choose $x \in E^*$ such that $d(x, q) < 2^{-i} \delta$. Since $x \in E^*$, we can choose $n_i > n_{i-1}$ such that $d(x, p_{n_i}) < 2^{-i} \delta$. Then $d(q, p_{n_i}) < 2^{1-i} \delta$ so $p_{n_i} \to q$ so $q \in E^*$.
\end{proof}
\end{theorem}

\section{Cauchy Sequences}

\begin{definition}
A sequence $\{p_n\}$ in a metric space $X$ is said to be a \textbf{Cauchy sequence} if for every $\epsilon > 0$, there exists an integer $N$ such that $d(p_n, p_m) < \epsilon$ if $n, m \ge N$.

Let $E$ be a non-empty subset of a metric space $X$ and let $S$ be the set of all real numbers of the form $d(p, q)$ with $p, q \in E$. Then $\diam E = \sup S$ is the \textbf{diameter} of $E$.

Clearly a sequence $\{p_n\}$ is Cauchy iff $\diam E_N \to 0$, where $E_n = \{p_{n}, p_{n+1}, \dotsc\}$.
\end{definition}

\begin{theorem} % Theorem 3.10
The following are true:
\begin{enumerate}
\item If $E$ is a subset of a metric space $X$, then $\diam E = \diam \overline{E}$. 

\item If $K_n$ is a sequence of compact sets in $X$ such that $K_n \supseteq K_{n+1}$ and $\diam K_n \to 0$, then $\bigcap_{n=1}^{\infty} K_n$ consists of exactly one point.
\end{enumerate}

\begin{proof}
For (a), notice that $E \subseteq \overline{E}$ so $\diam E \le \diam \overline{E}$. If $\diam \overline{E} > \diam E$, there exists a pair of elements $x, y \in \overline{E}$ with $|x - y| > \diam E$. If one of $x, y$ is not in $E$, then a neighbourhood of size less than $(|x - y| - \diam E)/2$ around the element in $\overline{E}$ has no elements in $E$, a contradiction. A similar argument can be made if both are not in $E$. 

For (b), we know from Nested interval theorem that $S = \bigcap_{n=1}^{\infty} K_n$ is non-empty. If $S$ had more than one point, say $a$ and $b$, then $\diam S_n \ge d(a, b) > 0$ all $n$ and thus $\diam S_n \nto 0$, a contradiction.
\end{proof}
\end{theorem}

\begin{theorem} % Theorem 3.11
The following are true:
\begin{enumerate}
\item In any metric space $X$, every convergent sequence is a Cauchy sequence.

\item If $X$ is a compact metric space and if $\{p_n\}$ is a Cauchy sequence in $X$, then $\{p_n\}$ converges to some point of $X$.

\item In $\R^k$, every Cauchy sequence converges.
\end{enumerate}

\begin{proof}
For (a), let $\epsilon > 0$. Then there exists $N$ such that $n \ge N$ implies $d(p_n, p) \le \epsilon/2$. Then for any $m, n \ge N$, we have $d(p_n, p_m) \le d(p_n, p) + d(p_m, p) < \epsilon$. 

For (b), let $E_n = \{p_n, p_{n+1}, \dotsc\}$. Then since $\{p_n\}$ is Cauchy, $\diam \overline{E_n} \to 0$. Also, $\overline{E_n}$ are subsets of $X$ and thus compact. Finally, $\overline{E_n} \supseteq \overline{E_{n+1}}$ by definition. By Theorem 3.10, $\bigcap_{n=1}^{\infty} \overline{E_n}$ consists of one point. Let this point be $p$. Since $\diam \overline{E_n} \to 0$, points in $\{p_n\}$ get arbitrarily close to $p$ so $\{p_n\}$ converges to $p \in X$.

For (c), Cauchy sequences are bounded, and thus their image is contained in a compact subset of $\R^k$. The result follows from (b).
\end{proof}
\end{theorem}

\begin{definition} % Definition 3.12
A metric space in which every Cauchy sequence converges is \textbf{complete}. 

Theorem 3.11 says that \underline{all compact metric spaces and all Euclidean spaces are complete}. 

Also, \underline{every closed subset of a complete metric space is complete}.
\end{definition}

\begin{definition} % Definition 3.13
A sequence $\{s_n\}$ of real numbers is said to be
\begin{itemize}
\item \textbf{monotonically increasing} if $s_n \le s_{n+1}$ for all $n$,
\item \textbf{monotonically decreasing} if $s_n \ge s_{n+1}$ for all $n$
\end{itemize}

The class of monotonic sequences consists of the increasing and decreasing sequences.
\end{definition}

\begin{theorem} % Theorem 3.14
Suppose $\{s_n\}$ is monotonic. Then $\{s_n\}$ converges iff it is bounded.

\begin{proof}
Suppose $\{s_n\}$ is increasing and bounded. Then its image admits a least upper bound $\alpha$. For every $\epsilon > 0$, there exists $N$ such that $s - \epsilon < s_N \le s$, otherwise $s - \epsilon$ would be a smaller upper bound. For $n \ge N$, $s - \epsilon < s_N \le s_n \le s$, as required.

The converge follows from Theorem 3.2(c).
\end{proof}
\end{theorem}

\section{Upper and Lower Limits}

\begin{definition} % Definition 3.15, 3.16
If $\{s_n\}$ is a sequence of real numbers such that for any $M \in \R$ there exists $N \in \N$ such that $n \ge N$ implies $s_n \ge M$, then we say $s_n \to +\infty$. 

Similarly, if for any $M \in \R$, there exists $N \in \N$ such that $n \ge N$ implies $s_n \le M$, then we say $s_n \to -\infty$. 

Let $\{s_n\}$ be a sequence of real numbers. Let $E$ be the set of possibly infinite subsequential limits. Then, let $s^* = \sup E$ and $s_* = \inf E$, called the \textbf{upper} and \textbf{lower limits} of $\{s_n\}$ respectively. 

We say
\[
	\limsup_{n \to \infty} s_n = s^* \text{ and } \liminf_{n \to \infty} s_n = s_*.
\]
\end{definition}

\begin{theorem} % Theorem 3.17
Let $\{s_n\}$ be a sequence of real numbers. Let $E$ be the set of possibly infinite subsequential limits of $\{s_n\}$, and $s^* = \limsup s_n$. Then the following are true:

\begin{enumerate}
\item $s^* \in E$.
\item If $x > s^*$, there is an integer $N$ such that $n \ge N$ implies $s_n < x$. 
\end{enumerate}
Moreover, $s^*$ is the only number with these properties.

\begin{proof}
For (a), if $s_n \to \pm \infty$, then every subsequence goes to $\pm \infty$ so $s^* \in E$. Otherwise, it is bounded and thus $E$ is closed by Theorem 3.7, so $s^* = \sup E \in \overline{E} = E$. 

For (b), notice that is this weren't the case, then there are $s_n \ge x$ for $n$ arbitrarily large. Taking these $s_n$ as a subsequence yields a subsequence with limit $\ge x > s_n$, contradicting the maximality of $s^*$ in $E$.

Finally, let $a, b \in E \subseteq \R$ both satisfy these above properties. Without loss of generality, $a > b$. Let $x \in \R$ such that $b < x < a$. Then statement (b) holds for $b$ so $s_n < x < a$ for $n \ge N$. Then $a$ cannot satisfy (a).
\end{proof}
\end{theorem}

For example, the sequence containing all rational numbers $\{s_n\}$ has every real number as a subsequential limit. Also, its $\limsup$ is $+\infty$ and $\liminf$ is $-\infty$.

Also, it is noteworthy that a sequence converges iff its $\limsup$ is equal to its $\liminf$. 

\begin{theorem} % Question 3.19
If $s_n \le t_n$ for $n \ge N$, where $N$ is fixed, then
\[
	\liminf_{n \to \infty} s_n \le \liminf_{n \to \infty} t_n \text{ and } \limsup_{n \to \infty} s_n \le \limsup_{n \to \infty} t_n
\]

\begin{proof}
The cases with infinities are simple casework. Thus, suppose all values involved are finite real numbers. Suppose, for the sake of contradiction that $\liminf_{n \to \infty} s_n > \liminf_{n \to \infty} t_n$. Then, there exists some $y \in E_t$ strictly less than \underline{all} the $x \in E_s$, where $E_s$ and $E_t$ are the sets of subsequential limits of $\{s_n\}$ and $\{t_n\}$ respectively. 

Consider the subsequence $\{t_{n_k}\}$ which converges to this $y$. Suppose without loss of generality that each $n_k \ge N$. Then each term in $\{s_{n_k}\}$ is at most the corresponding term in $\{t_{n_k}\}$. In particular, some subsequence $\{s_{n_{k_i}}\}$ converges to a value at most $y$, a contradiction, since some $x \in E_s$ is at most $y$.

The corresponding proof for $\limsup$ follows similarly.
\end{proof}
\end{theorem}

\section{Some Special Sequences}

\begin{theorem} % Theorem 3.20
We compute the limits of some helpful sequences, using the helpful fact that if $0 \le x_n \le s_n$ for $n \ge N$, then $s_n \to 0$ implies $x_n \to 0$. 

\begin{enumerate}
\item If $p > 0$, then $n^{-p} \to 0$.
\item If $p > 0$, then $p^{1/n} \to 1$.
\item $n^{-n} \to 1$.
\item If $p > 0$ and $\alpha \in \R$, then $\frac{n^{\alpha}}{(1 + p)^n} \to 0$. 
\item If $|x| < 1$, then $x^n \to 0$.
\end{enumerate}

\begin{proof}
For (a), take $n > (1/\epsilon)^{1/p}$.

For (b), $p = 1$ is obvious. If $p > 1$, let $x_n = p^{1/n} - 1 > 0$. Then, by the binomial theorem, $1 + nx_n \le (1 + x_n)^n = p$ so $0 < x_n \le \frac{p - 1}{n}$ and the rightmost terms go to 0. $p < 1$ follows by taking reciprocals.

For (c), let $x_n = n^{1/n} - 1 > 0$. Then $n = (1 + x_n)^n \ge \frac{n(n-1)}{2} x_n^2$. Then $0 \le x_n \le \sqrt{\frac{2}{n - 1}}$. and the result follows.

For (d), let $k > \max(0, \alpha)$ be an integer. For $n > 2k$, 
\[
	(1 + p)^n > \binom{n}{k} p^k = \frac{n(n - 1) \cdots (n - k + 1)}{k!} p^k > \frac{n^k p^k}{2^k k!}.
\]

Hence
\[
	0 < \frac{n^\alpha}{(1 + p)^n} < \frac{2^k k!}{p^k} n^{\alpha - k}
\]
which approaches zero since $\alpha - k < 0$ and by (a).

Statement (e) follows by taking $\alpha = 0$ in (d). 
\end{proof}
\end{theorem}

\section{Series}

\begin{definition} % Definition 3.21
Given $\{a_n\}$ we associate a sequence $\{s_n\}$ where
\[
	s_n = \sum_{k=1}^{n} a_k = a_1 + a_2 + \dotsb + a_k,
\]
where $s_n$ are called the \textbf{partial sums} of $\{a_n\}$.

We also write
\[
	\{s_n\} = a_1 + a_2 + a_3 + \dotsb = \sum_{n=1}^{\infty} a_n.
\]

If $s_n \to s$, we say the series \textbf{converges}, and that
\[
	\sum_{n=1}^{\infty} a_n = s.
\]
\end{definition}

The notion of Cauchy sequences on the partial sums can be extended to series:
\begin{theorem} % Theorem 3.22
$\sum a_n$ converges iff for every $\epsilon > 0$, there exists an integer $N$ such that
\[
	\left| \sum_{k=m}^{n} a_k \right| < \epsilon
\]
for all $n \ge m \ge N$. 

\begin{proof}
Notice that $\sum_{k=m}^{n} a_k = s_n - s_m$, so the condition is equivalent to the sequence $\{s_n\}$ being Cauchy. The result follows from the fact that Cauchy sequences and convergent sequences are equivalent in $\R^k$.
\end{proof}
\end{theorem}

In particular, taking $m = n$ we have $|a_n| < \epsilon$ for $n \ge N$. More formally,

\begin{theorem} % Theorem 3.23
If $\sum a_n$ converges, then $a_n \to 0$.
\end{theorem}

\begin{theorem} % Theorem 3.24
A series of non-negative terms converges if and only if its partial sums form a bounded sequence.

\begin{proof}
The partial sums form a monotonically increasing sequence, so the result follows as in Theorem 3.14.
\end{proof}
\end{theorem}

We now prove a helpful theorem called the \underline{`Comparison test'}. 

\begin{theorem} % Theorem 3.25
The following are true:
\begin{enumerate}[(a)]
\item If $|a_n| \le c_n$ for $n \ge N_0$, where $N_0$ is some fixed integer, and if $\sum c_n$ converges, then $\sum a_n$ converges.

\item If $a_n \ge d_n \ge 0$ for $n \ge N_0$, and if $\sum d_n$ diverges, then $\sum a_n$ diverges.
\end{enumerate}

\begin{proof}
For (a), let $\{s_n\}$ be the sequence of partial sums of $a_n$ and $C = \sum c_n$. Also, notice that $c_n \ge 0$. Let $\epsilon > 0$. Then since $\sum c_n$ converges, there exists an integer $N$ such that for $n \ge m \ge N$,
\[
	\left|\sum_{k=m}^{n} c_k\right| < \epsilon.
\]
Then, for any $n \ge m \ge N$,
\[
	\left| \sum_{k=m}^{n} a_k \right| \overset{\Delta}{\le} \sum_{k=m}^{n} |a_k| \le \sum_{k=m}^{n} c_k \le \left|\sum_{k=m}^{n} c_k\right| < \epsilon
\]
so $\sum a_n$ converges.

For (b), suppose without loss of generality that $\sum d_n$ diverges to $+\infty$. Then let $M$ be a real number. Then for $n \ge N$, 
\[
	\sum_{k=1}^{n} a_k \ge \sum_{k=1}^{n} d_k > M
\]
so $\sum a_n$ diverges too.
\end{proof}
\end{theorem}

\section{Series of Non-negative Terms}

\begin{theorem} % Theorem 3.26
If $0 \le x < 1$, then
\[
	\sum_{n=0}^{\infty} x^n = \frac{1}{1 - x}.
\]
If $x \ge 1$, the series diverges.

\begin{proof}
If $0 \le x < 1$, let $s_n = \sum_{k=0}^{n} x^k$. It can be shown by induction that $s_n = \frac{1 - x^{n+1}}{1 - x}$. Then,
\[
	\left|s_n - \frac{1}{1 - x}\right| = \left| \frac{1}{1 - x} - \frac{x^{n+1}}{1 - x} - \frac{1}{1 - x}\right| = x^{n + 1} \cdot \frac{1}{1 - x} \to 0
\]
so the result follows.

If $x \ge 1$, then $s_n \ge n$. The result follows immediately.
\end{proof}
\end{theorem}

The following theorem states that a rather `thin' subsequence of decreasing sequences determines the convergence of $\sum a_n$.
\begin{theorem}[Cauchy] % Theorem 3.27
Suppose $a_1 \ge a_2 \ge \dotsb \ge 0$. Then the series $\sum a_n$ converges if and only if the series
\[
	S := \sum_{k=0}^{\infty} 2^k a_{2^k} = a_1 + 2a_2 + 4a_4 + \dotsb
\]
converges.

\begin{proof}
Let $\{b_n\}$ be a sequence related to $a_n$ such that $b_n = a_{f(n)}$ where $f(n)$ is the largest power of two at most $n$. That is, the sequence $\{b_n\}$ starts $(a_1, a_2, a_2, a_4, a_4, a_4, a_4, \dotsb)$. Since $a_n$ is decreasing, $\{b_n\}$ is a strictly decreasing sequence where each term is at least the corresponding $a_n$. Also, notice $S$ is $\sum b_n$, so the fact that $\sum a_n$ converges if $S$ converges follows by the comparison test.

Now suppose $\sum a_n$ converges. Then, 
\[
	\sum_{i=1}^{2^k} = a_1 + a_2 + (a_3 + a_4) + \dotsc + (a_{2^{k-1}+1} + \dotsb + a_{2^k}) \ge \frac{1}{2} a_1 + a_2 + 2a_4 + \dotsc + 2^{k-1} a_{2^k} = \frac{1}{2} \sum_{i=1}^{2^k} b_i
\]
so the result follows again by the comparison test.
\end{proof}
\end{theorem}

\begin{theorem} % Theorem 3.28
The series $\sum n^{-p}$ converges if $p > 1$ and diverges if $p \le 1$. 

\begin{proof}
We can write $2^k a_{2^k} = \frac{2^k}{2^{kp}} = 2^{(1-p)k}$ so $\sum_{k=0}^{\infty} (2^{(1-p)})^k$ converges iff $0 \le 2^{1-p} < 1$ from Theorem 3.26, which occurs when $p > 1$. The result follows by the previous theorem, since the original sequence was decreasing.
\end{proof}
\end{theorem}

\begin{theorem} % Theorem 3.29
If $p > 1$, then
\[
	\sum_{n=2}^{\infty} \frac{1}{n (\log n)^p}
\]
converges. Otherwise, the series diverges.

\begin{proof}
Write
\[
	2^k a_{2^k} = \frac{2^k}{2^k (\log 2^k)^p} = \frac{1}{(k \log 2)^p} = \frac{c}{k^p}
\]
with $c = \frac{1}{(\log 2)^p}$ so by Theorem 3.27, $\sum a_n$ converges iff
\[
	c \sum_{k=1}^{\infty} \frac{1}{k^p}
\]
converges, but that happens iff $p > 1$ by the previous theorem.
\end{proof}
\end{theorem}

\section{The Number $e$}

\begin{definition}
We define
\[
	e = \sum_{n=0}^{\infty} \frac{1}{n!}.
\]
This is well-defined since
\[
	s_n = 1 + 1 + \frac{1}{1 \cdot 2} + \frac{1}{1 \cdot 2 \cdot 3} + \dotsb + \frac{1}{1 \cdot 2 \cdot \dotsb \cdot n} < 1 + 1 + \frac{1}{2} + \frac{1}{2^2} + \dotsb + \frac{1}{2^{n-1}} < 3
\]
\end{definition}

There is an equivalent definition:
\begin{theorem} % Theorem 3.31
We have
\[
	\lim_{n \to \infty} \left(1 + \frac{1}{n}\right)^n = e.
\]

\begin{proof}
Let $s_n = \sum_{k=0}^{n} \frac{1}{k!}$ and $t_n = \left(1 + \frac{1}{n}\right)^n$. By the binomial theorem,
\[
	t_n = \sum_{k=0}^{n} \binom{n}{k} \frac{1}{n^k} = \sum_{k=0}^{n} \frac{1}{k!} \cdot \frac{n!}{(n-k)! n^k} = \sum_{k=0}^{n} \frac{1}{k!} \prod_{i=1}^{k-1} \left(1 - \frac{i}{n}\right).
\]
Clearly $t_n \le s_n$ termwise, so $\limsup_{n \to \infty} t_n \le e$.

Also, if $m \le n$, then
\[
	t_n \ge \sum_{k=0}^{m} \frac{1}{k!} \prod_{i=1}^{k-1} \left(1 - \frac{i}{n}\right)
\]
which, as $n$ increases, becomes
\[
	\liminf_{n \to \infty} t_n \ge \sum_{k=0}^{m} \frac{1}{m!}.
\]
Letting $m$ go to infinity yields $e \le \liminf_{n \to \infty} t_n$ so the result follows.
\end{proof}
\end{theorem}

As a sidenote, the following bound on the error of the partial sums proves helpful:
\begin{remark}
Notice that
\[
	0 < e - s_n = \sum_{k=n+1}^{\infty} \frac{1}{k!} < \frac{1}{(n + 1)!} \sum_{k=0}^{\infty} \frac{1}{(n + 1)^k} = \frac{1}{n!n}
\]
which shows that this infinite sum representation converges extremely quickly.
\end{remark}

\begin{theorem} % Theorem 3.32
$e$ is irrational.

\begin{proof}
Suppose otherwise, so that $e = p/q$ for positive integers $p, q$. By the above remark, $0 < q!(e - s_q) < \frac{1}{q}$. Then both $q!s_q$ and $q!e$ are integers, so the above inequality implies the existence of an integer between 0 and $1/q$, a contradiction.
\end{proof}
\end{theorem}

\section{The Root and Ratio Tests}

\begin{theorem}[Root Test] % Theorem 3.33
Given $\sum a_n$, put $\alpha = \limsup_{n \to \infty} \sqrt[n]{|a_n|}$. Then,
\begin{enumerate}[(a)]
\item If $\alpha < 1$, then $\sum a_n$ converges.
\item If $\alpha > 1$, then $\sum a_n$ diverges.
\item If $\alpha = 1$, the test gives no information.
\end{enumerate}

\begin{proof}
For (a), we know then that for large enough $n$, $\sqrt[n]{|a_n|} \le \alpha$ so $|a_n| \le \alpha^n$. The result follows from the comparison test. For (b), notice that for large enough $n$, $|a_n| \ge 1$, so the series diverges by the contrapositive of Theorem 3.23.

For (c), the series $\sum 1/n$ and $\sum 1/n^2$ work.
\end{proof}
\end{theorem}

\begin{theorem}[Ratio Test] % Theorem 3.34
The series $\sum a_n$ converges if $\limsup_{n \to \infty} \left| \frac{a_{n+1}}{a_n}\right| < 1$ and diverges if $\left|\frac{a_{n+1}}{a_n}\right| \ge 1$ for all $n \ge n_0$ where $n_0$ is some fixed integer.

\begin{proof}
For the first part, for $n \ge N$, we will have $\left|\frac{a_{n+1}}{a_n}\right| = \beta < 1$. Then $|a_n| \le |a_N| \beta^{n-N}$ so the result follows by comparing with a geometric series. For the second part, the fact that $|a_{n+1}| \ge |a_n|$ eventually, means that $a_n \nto 0$, so the series cannot converge.
\end{proof}
\end{theorem}

The previous two tests are very useful for determining convergence. In most cases, the ratio test is easier to use, but we show in the following theorem than the root test is stronger.

\begin{theorem} % Theorem 3.37
For any sequence $\{c_n\}$ of positive numbers,
\[
	\liminf_{n \to \infty} \frac{c_{n+1}}{c_n} \le \liminf_{n \to \infty} \sqrt[n]{c_n} \le \limsup_{n \to \infty} \sqrt[n]{c_n} \le \limsup_{n \to \infty} \frac{c_{n+1}}{c_n}
\]

\begin{proof}
Let $\alpha = \limsup_{n \to \infty} \frac{c_{n+1}}{c_n}$. If $\alpha = +\infty$, we are done. Otherwise, suppose some subsequence $\{c_{n_k}\}$ had the property that $\lim_{k \to \infty} \sqrt[n_k]{c_{n_k}} = \beta > \alpha$. Then, there must exist infinitely many terms $\{c_n\}$ with $c_n^n > \alpha^n$. But this cannot occur if the ratios of consecutive terms does not exceed $\alpha$ infinitely often, a contradiction. The left inequality is similar.
\end{proof}
\end{theorem}

\section{Power Series}

\begin{definition} % Definition 3.38
Given a sequence $\{c_n\}$ of complex numbers, the series
\[
	\sum_{n=0}^{\infty} c_nz^n
\]
is called a \textbf{power series}. The numbers $c_n$ are called the \textbf{coefficients} of the series, and $z$ is a complex number.
\end{definition}

\begin{theorem} % Theorem 3.39
Given a power series as above, let
\[
	\alpha = \limsup_{n \to \infty} \sqrt[n]{|c_n|}, R = \frac{1}{\alpha}.
\]
Then $\sum c_nz^n$ converges if $|z| < R$ and diverges when $|z| > R$.

\begin{proof}
The value for $\alpha$ is derived from the result of the root test, so this proof is just like unwrapping a present you wrapped for yourself.
\end{proof}
\end{theorem}

\section{Summation by Parts}

\begin{theorem}
Given two sequences $\{a_n\}, \{b_n\}$, put $A_n = \sum_{k=0}^{n} a_k$ if $n \ge 0$ and $A_{-1} = 0$. Then, if $0 \le p \le q$, we have
\[
	\sum_{n=p}^{q} a_nb_n = \sum_{n=p}^{q-1} A_n(b_n - b_{n+1}) + A_qb_q - A_{p-1}b_p.
\]

\begin{proof}
Expand the sum and telescope differently:
\begin{align*}
\sum_{n=p}^{q} a_nb_n &= \sum_{n=p}^{q} (A_n - A_{n-1})b_n \\
	&= A_qb_q - A_{q-1}b_q + A_{q-1}b_{q-1} - A_{q-2}b_{q-1} + \dotsb + A_{p+1}b_{p+1} - A_pb_{p+1} + A_pb_p - A_{p-1}b_p \\
	&= A_qb_q + (A_{q-1}(b_{q-1} - A_{q-1}b_q) + \dotsb + A_p(b_p - A_pb_{p+1}) - A_{p-1}b_p \\
	&= \sum_{n=p}^{q-1} A_n(b_n - b_{n+1}) + A_qb_q - A_{p-1}b_p
\end{align*}
as required.
\end{proof}
\end{theorem}

\begin{theorem} % Theorem 3.42
Let $\{a_n\}$ be a sequence such that
\begin{enumerate}[(a)]
\item The partial sums $A_n$ of $\sum a_n$ form a bounded sequence.
\item $b_0 \ge b_1 \ge \dotsb$.
\item $b_n \to 0$.
\end{enumerate}
Then $\sum a_nb_n$ converges.

\begin{proof}
The above theorem suggests using the Cauchy criterion. Let $\epsilon > 0$ and suppose the $A_n$ are bounded by $M$. We first manipulate:
\begin{align*}
\left|\sum_{n=p}^{q} a_nb_n \right| &= \left|\sum_{n=p}^{q-1} A_n(b_n - b_{n+1}) + A_qb_q - A_{p-1}b_p\right| \\
	&\le M \left[\left|\sum_{n=p}^{q-1} (b_n - b_{n+1})\right| + |b_q| + |b_p|\right] \\
	&= 2Mb_q
\end{align*}
so choosing $N$ such that $q \ge p \ge N$ implies $b_q < \epsilon/(2M)$, completing the proof.
\end{proof}
\end{theorem}

\begin{theorem} % Theorem 3.43
Suppose $\{c_n\}$ is a sequence such that
\begin{enumerate}[(a)]
\item $|c_1| \ge |c_2| \ge \dotsb$.
\item $c_{2m-1} \ge 0$, $c_{2m} \le 0$.
\item $c_n \to 0$.
\end{enumerate}
Then $\sum c_n$ converges.

\begin{proof}
This follows from the previous theorem, letting $a_n = (-1)^{n+1}$ and $b_n = |c_n|$. 
\end{proof}
\end{theorem}

\begin{theorem} % Theorem 3.44
Suppose the radius of convergence of $\sum c_nz^n$ is 1, and that $|c_0| \ge |c_1| \ge \dotsb$ and $c_n \to 0$. Then $\sum c_nz^n$ converges at every point on the circle $|z| = 1$ except possibly at $z = 1$.

\begin{proof}
Let $a_n = z^n$ and $b_n = |c_n|$. Then the $A_n$ are bounded by $\frac{2}{|1 - z|}$, so Theorem 3.42 applies.
\end{proof}
\end{theorem}

\section{Absolute Convergence}

A series $\sum a_n$ is said to converge absolutely if $\sum |a_n|$ converges.

\begin{theorem} % Theorem 3.45
If $\sum a_n$ converges absolutely, then $\sum a_n$ converges.

\begin{proof}
Let $\epsilon > 0$ be arbitrary and $N$ such that the Cauchy criterion holds for $n \ge m \ge N$. Then, for these same $n, m$, we have
\[
	\left| \sum_{k=m}^{n} a_k \right| \le \sum_{k=m}^{n} |a_k| < \epsilon
\]
so $\sum a_n$ converges by the Cauchy criterion.
\end{proof}
\end{theorem}

Notice that absolute convergence is convergence if your terms are positive. Series which converge but not absolutely converge \textbf{non-absolutely}.

We see that we can manipulate absolutely convergent sums much like finite sums. Let's explore the types of operations we can perform on general series.

\begin{theorem} % Theorem 3.47
If $\sum a_n = A$ and $\sum b_n = B$, then $\sum (a_n + b_n) = A + B$ and $\sum ca_n = cA$ for any $c$.

\begin{proof}
The first statement follows after noticing that the partial sums of $\sum (a_n + b_n)$ are simply the sums of the partial sums of $\sum a_n$ and $\sum b_n$. The second statement follows similarly.
\end{proof}
\end{theorem}

Can we multiply infinite series? The answer is slightly more complicated.

\begin{definition} % Theorem 3.48
Given $\sum a_n$ and $\sum b_n$, we put
\[
	c_n = \sum_{k=0}^{n} a_k b_{n-k}
\]
and call $\sum c_n$ the \textbf{product} of the two series. This is motivated by considering the coefficients of the related generating series $\sum a_nz^n$ and $\sum b_nz^n$.
\end{definition}

The following theorem, due to Mertens, characterizes a large set of situations where this notion of product is consistent.

\begin{theorem}[Mertens] % Theorem 3.50
Suppose that
\begin{enumerate}[(a)]
\item $\sum a_n$ converges absolutely.
\item $\sum a_n = A$.
\item $\sum b_n = B$.
\item $c_n = \sum_{k=0}^{n} a_kb_{n-k}$ as above.
\end{enumerate}
Then $\sum c_n = AB$.

\begin{proof}
Let $A_n, B_n$ and $C_n$ be the $n$-th partial sums of $a_n, b_n, c_n$ respectively. Also, let $\beta = B_n - B$. We manipulate $C_n$, essentially switching the order of summations:
\begin{align*}
C_n &= a_0b_0 + (a_0b_1 + a_1b_0) + (a_0b_2 + a_1b_1 + a_2b_0) + \dotsb + (a_0b_n + a_1b_{n-1} + \dotsb + a_nb_0) \\
	&= a_0B_n + a_1B_{n-1} + \dotsb + a_nB_0 \\
	&= a_0(B + \beta_n) + a_1(B + \beta_{n-1}) + \dotsb + a_n(B + \beta_0) \\
	&= A_nB + a_0\beta_n + a_1\beta_{n-1} + \dotsb + a_n\beta_0.
\end{align*}

Thus if we let 
\[
	\gamma_n = a_0\beta_n + a_1\beta_{n-1} + \dotsb + a_n\beta_0,
\]
it suffices to prove that $\gamma_n \to 0$. Let $\epsilon > 0$ be arbitrary and choose $N$ such that $|\beta_n| < \epsilon$ for $n \ge N$. Also, let $\alpha = \sum |a_n|$. Then
\begin{align*}
|\gamma_n| &= |a_0\beta_n + a_1\beta_{n-1} + \dotsb + a_n\beta_0| \\
	&\le |a_0\beta_n + a_1\beta_{n-1} + \dotsb + a_N\beta_{n-N}| + |a_{N+1}\beta_{n-N-1} + \dotsb + a_n\beta_0| \\
	&\le |a_0\beta_n + a_1\beta_{n-1} + \dotsb + a_N\beta_{n-N}| + \epsilon \alpha
\end{align*}
so if we fix $N$ and let $n \to \infty$, then we have
\[
	\limsup_{n \to \infty} |\gamma_n| \le \epsilon \alpha
\]
so the result follows since $\epsilon$ was arbitrary.
\end{proof}
\end{theorem}

We now wonder whether this definition of product makes sense in the sense that if $\sum c_n$ converges, whether it will have the sum $AB$. Abel proved that this is true. 

\begin{theorem} % Theorem 3.51
If $\sum a_n$, $\sum b_n$, $\sum c_n$ converge to $A, B, C$ and $c_n = a_0 b_n + \dotsb + a_nb_0$, then $C = AB$.

\begin{proof}
\textbf{Note:} This is an incomplete proof, as it assumes that power series are continuous without justification. We will fill in this gap in Theorem 8.2. This proof will be replaced later, since it is most likely circular or wrong.

Let $a(z) = \sum a_nz^n$, $b(z) = \sum b_nz^n$, and $c(z) = \sum c_nz^n$. Then we (will) have seen that $c(z) = a(z)b(z)$ if $c_n = a_0b_n + \dotsb + a_nb_0$, if we consider partial sums of $c(z)$. Then the result follows by substituting $z = 1$.
\end{proof}
\end{theorem}

\section{Rearrangements}

\begin{definition}
Let $\{k_n\}$ be a bijection from $\N$ to itself. Then letting $a'_n = a_{k_n}$, we say that $\sum a'_n$ is a \textbf{rearrangement} of $\sum a_n$.

Notice that the partial sums of these have no reason to be the same, so the question arises: should they converge? Will their sums be the same if so?
\end{definition}

We prove Riemann's rearrangement theorem, which says that all hell breaks loose if our sequence doesn't converge absolutely:
\begin{theorem}[Riemann Rearrangement] % Theorem 3.54
Let $\sum a_n$ which converges non-absolutely, and $-\infty \le \alpha \le \beta \le +\infty$. Then, there exists a rearrangement $\sum a'_n$ with partial sums $s'_n$ such that
\[
	\liminf_{n \to \infty} s'_n = \alpha \text{ and } \limsup_{n \to \infty} s'_n = \beta.
\]

\begin{proof}
This proof is well-studied. We present an informal proof hopefully sufficient to provide intuition. The actual proof is long-winded.

Let $a^+_n$ and $a^-_n$ denote the subsequences of positive and negative terms of $a_n$. If either subsequence were finite, then the other would overpower it and eventually either diverge or converge (after which $a_n$ would converge absolutely since the subsequence has all the same sign). Thus both must be infinite.

If $\alpha \ge 0$, take positive terms until our partial sums go above $\alpha$. We must be able to do this, since both subseries diverge. Similarly, if $\alpha < 0$, take negative terms. Then, repeat the following process indefinitely. Take positive terms until our partial sums go above $\beta$, then negative terms until our partial sums return below $\alpha$. This is again made possible since both subsequences diverge. 

Taking the terms which are `turning points' on both sides, we have sequences which converge to $\alpha$ and $\beta$, so the result follows.
\end{proof}
\end{theorem}

Now, the following theorem states that absolutely convergent series do indeed behave nicely:
\begin{theorem} % Theorem 3.55
If $\sum a_n$ converges absolutely, then every rearrangement of $\sum a_n$ converges, and further they converge to the same sum.

\begin{proof}
Let $\sum a'_n = \sum a_{k_n}$ be a rearrangement of $\sum a_n$. Let $\epsilon > 0$. Take $N \in \N$ such that if $n \ge m \ge N$, then
\[
	\left|\sum_{k=m}^{n} |a_k| \right| < \epsilon.
\]
Then, take $N' = \max(k_1, \dotsc, k_N) + 1$, so that no $n' \ge m' \ge N'$ will be in $\{1, 2, \dotsc, N\}$. Then
\[
	\left|\sum_{k=m'}^{n'} |a'_k| \right| \le \limsup_{n \to \infty} \left|\sum_{k=N+1}^{n} |a'_k| \right| \le \epsilon
\]
so the result follows by the Cauchy criterion.
\end{proof}
\end{theorem}

\section{Exercises}

\begin{enumerate}
\item % Exercise 1
Prove that convergence of $\{s_n\}$ implies convergence of $|s_n|$. Is the converse true?

\begin{proof}
If $s_n \to 0$, then the result follows by definition. Otherwise, suppose $s_n \to s$ and $s > 0$. We can find $N$ such that $n \ge N$ implies $s/2 < s_n < 3s/2$, so that $||s_n| - |s|| = |s_n - s| < \epsilon$. The proof when $s < 0$ is similar, except we take $\epsilon = -s/2$.

The converse is not true: consider the sequence $s_n = (-1)^{n}$ for which $|s_n| = 1$ converges trivially, but for which no $N$ exists for $\epsilon < 2$.
\end{proof}

\item % Exercise 2
Calculate $\lim_{n \to \infty} (\sqrt{n^2 + n} - n)$.

\begin{proof}
We manipulate:
\[
	\sqrt{n^2 + n} - n = \frac{n^2 + n - n^2}{\sqrt{n^2 + n} + n} = \frac{n}{\sqrt{n^2 + n} + n} = \frac{1}{\sqrt{1 + 1/n} + 1}.
\]
We prove that $\sqrt{1+1/n} \to 1$: notice that
\[
	|\sqrt{1+1/n} - 1| = \left| \frac{1 + 1/n - 1}{\sqrt{1 + 1/n} + 1} \right| \le \frac{1}{2n} \to 0
\]
so 
\[
	\sqrt{n^2 + n} - n = \frac{1}{\sqrt{1 + 1/n} + 1} \to \frac{1}{1 + 1} = \frac{1}{2}.
\]
\end{proof}

\item % Exercise 3
If $s_1 = \sqrt{2}$ and $s_{n+1} = \sqrt{2 + \sqrt{s_n}}$, prove that $\{s_n\}$ converges and that $s_n < 2$.

\begin{proof}
Notice that the function $f(x) = \sqrt{2 + \sqrt{x}}$ is monotonic in the sense that if $a < b$, then $f(a) < f(b)$. Also, $s_2 = \sqrt{2 + \sqrt[4]{2}} \ge \sqrt{2} = s_1$. Also, if $s_{n-1} \le s_n$, then
\[
	s_n = \sqrt{2 + \sqrt{s_{n-1}}} \le \sqrt{2 + \sqrt{s_n}} = s_{n+1}.
\]
so it follows by induction that $s_n$ is an monotonically increasing sequence. 

We claim $s_n < 2$ inductively. The base case is true, and if $n \ge 1$,
\[
	s_{n+1} = \sqrt{2 + \sqrt{s_n}} < \sqrt{2 + \sqrt{2}} < 2.
\]
Thus $\{s_n\}$ converges by Theorem 3.14.
\end{proof}

\item % Exercise 4
Find the upper and lower limits of the sequence $\{s_n\}$ defined by
\[
	s_1 = 0; \quad s_{2m} = \frac{s_{2m-1}}{2}; \quad s_{2m+1} = \frac{1}{2} + s_{2m}.
\]

\begin{proof}
We claim that $s_* = 0$ and $s^* = 1$. First, the fact that $0 \le s_n \le 1$ with $s_{2m} \le 1/2$ can be shown inductively. The base case follows immediately. Otherwise, dividing by 2 preserves the conditions, and adding $1/2$ to $s_{2m}$ gives a number at most 1. It suffices now to find two sequences converging to $0$ and $1$.

the sequence $\{s_{2^k}\}$ is identically $0$. The sequence $\left\lbrace s_{2^{k+1} - 1}\right\rbrace = \left(0, \frac{1}{2}, \frac{3}{4}, \dotsc, \frac{2^k - 1}{2^k}, \dotsc\right)$ converges to 1. 
\end{proof}

\item % Exercise 5
For any two real sequences $\{a_n\}, \{b_n\}$, prove that
\[
	\limsup_{n \to \infty} (a_n + b_n) \le \limsup_{n \to \infty} a_n + \limsup_{n \to \infty} b_n,
\]
provided the sum on the right is not of the form $+\infty - \infty$.

\begin{proof}
If both $\alpha$ and $\beta$ are $+\infty$, the result proves itself. Likewise if $\alpha$ and $\beta$ are both $-\infty$, so it suffices to consider the finite cases.

Let $\alpha = \limsup_{n \to \infty} a_n$ and $\beta = \limsup_{n \to \infty} b_n$. Suppose that $\limsup_{n \to \infty} (a_n + b_n) = \gamma > \alpha + \beta$. Then, some sequence $\{s_n\}$ with $s_n = a_n + b_n$ converges to $\gamma$. For each $s_n$, either $a_n > \alpha$ or $b_n > \beta$. Thus, either $a_n > \alpha$ infinitely often, or $b_n > \beta$ infinitely often. In either of these cases, either $\limsup_{n \to \infty} a_n > \alpha$, or $\limsup_{n \to \infty} b_n > \beta$, a contradiction.
\end{proof}

\item % Exercise 6
Investigate the behaviour of $\sum a_n$ if
\begin{enumerate}[(a)]
\item $a_n = \sqrt{n + 1} - \sqrt{n}$.

\begin{proof}
The partial sums $s_n = \sqrt{n + 1} - 1$ diverge to $+\infty$, so the sum diverges.
\end{proof}

\item $a_n = \frac{\sqrt{n + 1} - \sqrt{n}}{n}$.

\begin{proof}
Manipulate:
\[
0 \le a_n = \frac{\sqrt{n + 1} - \sqrt{n}}{n} = \frac{(n + 1) - n}{n (\sqrt{n + 1} + \sqrt{n})} \le \frac{1}{n^{3/2}}
\]
so since $\sum n^{-3/2}$ converges, $\sum a_n$ converges by the comparison test.
\end{proof}

\item $a_n = \left(\sqrt[n]{n} - 1\right)^n$.

\begin{proof}
Since we have
\[
	\limsup_{n \to \infty} \sqrt[n]{a_n} = \limsup_{n \to \infty} \left(\sqrt[n]{n} - 1\right) = 0 < 1,
\]
the series $\sum a_n$ converges by the root test.
\end{proof}

\item $a_n = \frac{1}{1 + z^n}$ for complex $z$.

\begin{proof}
Notice that if $|z| < 1$, then $a_n \to 1 \ne 0$, so the sum does not converge. If $|z| > 1$, notice that the ratios
\[
	\left|\frac{a_n}{a_{n-1}}\right| = \left|\frac{1 + z^{n-1}}{1 + z^n}\right| \to \left|\frac{1}{z}\right| < 1
\]
so $\sum a_n$ converges by the ratio test. If $|z| = 1$, the sum diverges.
\end{proof}
\end{enumerate}

\item % Exercise 7
Prove that the convergence of $\sum a_n$ implies the convergence of $\sum \frac{\sqrt{a_n}}{n}$, if $a_n \ge 0$.

\begin{proof}
We consider the ratio:
\[
	\left| \frac{b_n}{b_{n-1}} \right| = \left| \frac{n-1}{n} \cdot \frac{\sqrt{a_n}}{\sqrt{a_{n-1}}} \right| < \left| \frac{\sqrt{a_n}}{\sqrt{a_{n-1}}} \right|
\]
so
\[
	\limsup_{n \to \infty} \left| \frac{b_n}{b_{n-1}} \right| \le \limsup_{n \to \infty} \sqrt{\frac{a_n}{a_{n-1}}} < 1
\]
since $\sum a_n$ converges by the ratio test.
\end{proof}

\item % Exercise 8
If $\sum a_n$ converges and $\{b_n\}$ is monotonic and bounded, prove that $\sum a_nb_n$ converges.

\begin{proof}
Let $B = \sum b_n$. We can write
\[
	\sum a_nb_n = \sum a_n(b_n - B) + B \sum a_n
\]
for which the first sum converges by Theorem 3.42, and the second sum converges as a scalar multiple of a convergent series.
\end{proof}
\item % Exercise 9
Find the radius of convergence of the following power series:
\begin{enumerate}[(a)]
\item $\sum n^3z^n$.

\begin{proof}
In order for $\sum n^3z^n$ to converge, we must have
\[
	\limsup_{n \to \infty} \left|\frac{n^3z^n}{(n-1)^3z^{n-1}}\right| = |z| < 1
\]
so the radius of convergence is 1.
\end{proof}
\item $\sum \frac{2^n}{n!}z^n$.
\begin{proof}
Using the ratio test, we must have
\[
	\limsup_{n \to \infty} \left|\frac{2^n (n-1)! z^n}{2^{n-1} n! z^{n-1}} \right| = \limsup_{n \to \infty} \frac{2}{n}|z| = 0 < 1
\]
which holds regardless of $z$, so the radius of convergence is $+\infty$.
\end{proof}
\item $\sum \frac{2^n}{n^2} z^n$.
\begin{proof}
Using the ratio test, we must have
\[
	\limsup_{n \to \infty} \left|\frac{2^n (n-1)^2 z^n}{2^{n-1} n^2 z^{n-1}} \right| = \limsup_{n \to \infty} 2 \left|\frac{(n-1)^2}{n^2} \right| |z| = 2|z| < 1
\]
so the radius of convergence is $1/2$.
\end{proof}
\item $\sum \frac{n^3}{3^n} z^n$.

\begin{proof}
By the ratio test, we must have
\[
	\limsup_{n \to \infty} \left|\frac{n^3 3^{n-1} z^n}{(n-1)^3 3^n z^{n-1}} \right| = \limsup_{n \to \infty} \frac{1}{3} \left|\frac{n^3}{(n-1)^3} \right| |z| = \frac{1}{3} |z| < 1
\]
so the radius of convergence is 3.
\end{proof}
\end{enumerate}

\item % Exercise 10
Suppose that the coefficients of the power series $\sum a_nz^n$ are integers, infinitely many of which are non-zero. Prove that the radius of convergence is at most 1.

\begin{proof}
Let $\{b_n\}$ be the sequence of non-zero coefficients. Then $|b_n| \ge 1$ so $\sqrt[n]{|b_n|} \ge 1$. Thus any subsequential limit of the $\sqrt[n]{|b_n|}$ will converge to a value at least 1, so
\[
	\limsup_{n \to \infty} \sqrt[n]{|b_n|} \ge 1
\]
and thus the radius of convergence is at most 1.
\end{proof}

\item % Exercise 11
Suppose $a_n > 0$ and $s_n = a_1 + \dotsb + a_n$ and $\sum a_n$ diverges.
\begin{enumerate}[(a)]
\item Prove that $\sum \frac{a_n}{1 + a_n}$ diverges.

\begin{proof}
We prove the contrapositive. Let $b_n = \frac{a_n}{1 + a_n}$ and suppose $\sum b_n$ converges. Then we know $b_n \to 0$ so $1 - b_n = \frac{1}{1 + a_n} \to 1$. Thus for $0 < \epsilon < \frac{1}{2}$, there exists $N \in \N$ such that if $n \ge N$, 
\[
	\left|\frac{1}{1 + a_n} - 1\right| = \left| \frac{b_n}{a_n} - 1 \right| < \frac{1}{2}
\]
so $a_n < 2b_n$ if $n \ge N$. This implies that
\[
	\sum_{n = N}^{m} a_n < 2\sum_{n = N}^{m} b_n < M
\]
where $m \ge N$ and $M$ is a bound on the partial sums of $\sum b_n$ which exists since $\sum b_n$ converges. So the partial sums of $\sum a_n$ monotonically increasing and bounded above, so $\sum a_n$ converges.
\end{proof}
\item Prove that
\[
	\frac{a_{N+1}}{s_{N+1}} + \dotsb + \frac{a_{N+k}}{s_{N+k}} \ge 1 - \frac{s_N}{s_{N+k}}
\]
and deduce that $\sum \frac{a_n}{s_n}$ diverges.

\begin{proof}
Notice that $s_n$ is a monotonically increasing sequence since $a_n > 0$, so
\begin{align*}
\frac{a_{N+1}}{s_{N+1}} + \frac{a_{N+2}}{s_{N+2}} + \dotsb + \frac{a_{N+k}}{s_{N+k}} &\ge \frac{a_{N+1}}{s_{N+k}} + \frac{a_{N+2}}{s_{N+k}} + \dotsb + \frac{a_{N+k}}{s_{N+k}} \\
	&= \frac{a_{N+1} + a_{N+2} + \dotsb + a_{N+k}}{s_{N+k}} \\
	&= 1 - \frac{s_N}{s_{N+k}}
\end{align*}
Then, letting $\epsilon = 1/2 > 0$, we can fix $N$ and choose $k \ge N$ such that $s_{N+k} > 2s_N$ since the $s_n$ are unbounded, so that
\[
	\frac{a_{N+1}}{s_{N+1}} + \frac{a_{N+2}}{s_{N+2}} + \dotsb + \frac{a_{N+k}}{s_{N+k}} \ge 1 - \frac{s_N}{s_{N+k}} > \frac12
\]
so $\sum \frac{a_n}{s_n}$ is not Cauchy and thus diverges.
\end{proof}
\item Prove that
\[
	\frac{a_n}{s_n^2} \le \frac{1}{s_{n-1}} - \frac{1}{s_n}
\]
and deduce that $\sum \frac{a_n}{s_n^2}$ converges.

\begin{proof}
We have $s_n > s_{n-1}$ so
\[
	\frac{a_n}{s_n^2} \le \frac{a_n}{s_n s_{n-1}} = \frac{s_n - s_{n-1}}{s_n s_{n-1}} = \frac{1}{s_{n-1}} - \frac{1}{s_n}
\]
so
\[
	\sum_{n=2}^{m} \frac{a_n}{s_n^2} \le \sum_{n=2}^{m} \frac{1}{s_{n-1}} - \frac{1}{s_n} = \frac{1}{s_1} - \frac{1}{s_m} \to \frac{1}{a_1}
\]
and thus $\sum \frac{a_n}{s_n^2}$ converges by the comparison test.
\end{proof}

\item What can be said about
\[
	\sum \frac{a_n}{1 + na_n} \text{ and } \sum \frac{a_n}{1 + n^2 a_n} \text{?}
\]

\begin{proof}
The first series converges for some $a_n$ and diverges for some other $a_n$. But $\frac{a_n}{1 + n^2 a_n} < \frac{a_n}{n^2 a_n} = \frac{1}{n^2}$ so the second series converges by the comparison test and the $p$-test.
\end{proof}
\end{enumerate}

\item % Exercise 12
Suppose $a_n > 0$ and $\sum a_n$ converges. Put
\[
	r_n = \sum_{m=n}^{\infty} a_m.
\]
\begin{enumerate}[(a)]
\item Prove that
\[
	\frac{a_m}{r_m} + \dotsb + \frac{a_n}{r_n} > 1 - \frac{r_n}{r_m}
\]
if $m < n$, and deduce that $\sum \frac{a_n}{r_n}$ diverges.

\begin{proof}
Since $a_n > 0$, the sequence $r_n$ is decreasing, so
\[
	\frac{a_m}{r_m} + \dotsb + \frac{a_n}{r_n} > \frac{a_m}{r_m} + \dotsb + \frac{a_n}{r_m} > \frac{a_m + \dotsb + a_{n-1}}{r_m} = \frac{r_m - r_n}{r_m} = 1 - \frac{r_n}{r_m}.
\]

Now for any $\epsilon > 0$, suppose $\epsilon < 1/2$ without loss of generality. Then, for any $n \in \N$, we can find $m \ge n$ such that $\frac{r_n}{r_m} < 1 - \epsilon$ since $r_n \to 0$, so $\sum_{k=m}^{n} \frac{a_k}{r_k} = 1 - \frac{r_n}{r_m} > \epsilon$. Then $\sum \frac{a_k}{r_k}$ is not Cauchy and thus diverges.
\end{proof}
\item Prove that
\[
	\frac{a_n}{\sqrt{r_n}} < 2 (\sqrt{r_n} - \sqrt{r_{n+1}})
\]
and deduce that $\sum \frac{a_n}{\sqrt{r_n}}$ converges.

\begin{proof}
Since $r_{n+1} < r_n$, we have $\frac{\sqrt{r_n} + \sqrt{r_{n+1}}}{\sqrt{r_n}} < 2$. Reorganizing yields
\[
    \frac{a_n}{\sqrt{r_n}} < 2 (\sqrt{r_n} - \sqrt{r_{n+1}})        
\]
since $a_n = r_n - r_{n+1}$. Now,
\[
    \left|\sum_{k=m}^{n} \frac{a_k}{\sqrt{r_k}}\right| < \left|2\sum_{k=m}^{n} (\sqrt{r_k} - \sqrt{r_{k+1}})\right| = \left|2\sqrt{r_m} - 2\sqrt{r_n}\right|
\]
which can be made arbitrarily small since $r_n \to 0$ so $\sqrt{r_n} \to 0$. Thus $\sum \frac{a_n}{\sqrt{r_n}}$ converges.
\end{proof}
\end{enumerate}

\item % Exercise 13
Let $\sum a_n$ and $\sum b_n$ converge absolutely. Then, letting $c_n = \sum_{k=1}^{n} a_k b_{n-k}$, prove that $\sum c_n$ converges absolutely.

\begin{proof}
Notice that
\[
    |c_n| = \left| \sum_{k=1}^{n} a_k b_{n-k} \right| \overset{\Delta}{\le} \sum_{k=1}^{n} |a_k| |b_{n-k}|.    
\]
and that letting $d_n$ be the positive terms on the right side, $\sum d_n$ converges by Merten's theorem. Thus, $\sum c_n$ converges absolutely by the comparison test.
\end{proof}

\item % Exercise 14
If $\{s_n\}$ is a complex sequence, define its arithmetic means $\sigma_n = \frac{1}{n + 1} (s_0 + \dotsc + s_n)$. 
\begin{enumerate}[(a)]
\item If $s_n \to s$, prove that $\sigma_n \to s$.

\begin{proof}
    Let $\epsilon > 0$ be arbitrary and $N_0 \in \N$ such that $|s_n - s| < \epsilon/2$ for $n \ge N_0$. Notice then that 
    \[
        |\sigma_n - s| \overset{\Delta}{\le} \sum_{k=0}^{N_0} \frac{|s_k - s|}{n + 1} + \sum_{k=N_0}^{n} \frac{|s_k - s|}{n + 1} < \frac{S}{n + 1} + \frac{\epsilon}{2}
    \]
    where $S = \sum_{k=0}^{N_0} |s_k - s|$ is finite. Then, letting $N = \max(N_0, 2S/\epsilon)$, we notice that
    \[
        |\sigma_n - s| \le \frac{S}{n + 1} + \frac{\epsilon}{2} \le \epsilon
    \]
    if $n \ge N$, so $\sigma_n \to s$.
\end{proof}

\item Construct a sequence $\{s_n\}$ which does not converge, but $\sigma_n$ does. 

\begin{proof}
Consider $s_n = (-1)^{n}$. Then clearly $s_n$ does not converge as the partial sums alternate between 0 and 1, but
\[
    \sigma_n = \begin{cases}
        0 & \text{ if $n$ even} \\
        \frac{1}{n + 1} & \text{ if $n$ odd}
    \end{cases}
\]
does.
\end{proof}
\item Can it happen that $s_n > 0$ for all $n$ and that $\limsup_{n \to \infty} s_n = +\infty$, but $\sigma_n \to 0$?

\begin{proof}
    Yes, let $s_0 = 1$, then $s_n = \sqrt[3]{n} > 0$ if $\sqrt[3]{n}$ is an integer, otherwise let $s_n = 1/n^2 > 0$. Then,
    \[
        \sigma_n = \frac{1}{n + 1} \sum_{k=0}^{n} s_n < \frac{1}{n + 1} \left(1 + 2n^{2/3} + \sum_{i=0}^{n} 1/i^2 \right) < 2n^{-1/3} + \frac{\pi^2}{6}n^{-1} \to 0
    \]
    but for any $M \in \R$, there exists some integer $k > M$, and thus $s_{(k-1)^2} > M$, so $\limsup_{n \to \infty} s_n = +\infty$, as required.
\end{proof}

\item Put $a_n = s_n - s_{n-1}$. Show that
\[
    s_n - \sigma_n = \frac{1}{n + 1} \sum_{k=1}^{n} ka_k.
\]
Assume that $na_n \to 0$ and $\{\sigma_n\}$ converges. Prove that $\{s_n\}$ converges. (Notice this provides a converse of (a) given $na_n \to 0$.

\begin{proof}
    We begin manipulating:
    \begin{align*}
        s_n - \sigma_n &= s_n - \frac{1}{n + 1} \sum_{k=0}^{n} s_k \\
            &= \frac{n}{n + 1} s_n - \frac{1}{n + 1} \sum_{k=0}^{n - 1} s_k \\
            &= \frac{1}{n + 1} \left[-\sum_{k=1}^{n-1} s_k + ns_n - s_0 \right] \\
            &= \frac{1}{n + 1} \left[ \sum_{k=1}^{n} ks_k - \sum_{k=1}^{n}ks_{k-1}\right] \\
            &= \frac{1}{n + 1} \sum_{k=1}^{n} ka_k.
    \end{align*}
    so clearly if $na_n \to 0$ and $\sigma_n \to \sigma$, then eventually $|\sigma_n - \sigma| < \epsilon/2$ and $\sum_{k=1}^{n} ka_k < (n+1)/2 \cdot ;\epsilon$, so $|s_n - s| < \epsilon$ for any $\epsilon > 0$, and thus $\{s_n\}$ converges.
\end{proof}

\item Prove (d) with the weaker hypothesis that $na_n$ is bounded by $M < \infty$ and $\sigma_n \to \sigma$. Show that $s_n \to \sigma$, by completing the following outline:
\begin{enumerate}[(i)]
\item If $m < n$, then
\[
	s_n - \sigma_n = \frac{m+1}{n-m}(\sigma_n - \sigma_m) + \frac{1}{n-m}\sum_{i=m+1}^{n} (s_n - s_i).
\]

\begin{proof}
    We manipulate:
    \begin{align*}
        s_n &= \frac{1}{n-m} \sum_{k=0}^{n} s_k - \frac{1}{n-m}\sum_{k=0}^{m} s_k + \frac{n-m}{n-m} \cdot s_n - \frac{1}{n-m} \sum_{k=0}^{n} s_k + \frac{1}{n-m} \sum_{k=0}^{m} s_k \\
            &= \frac{1}{n-m} \left[ \sum_{k=0}^{n} s_k - \sum_{k=0}^{m} s_k \right] + \frac{1}{n-m} \left[ \sum_{k=0}^{n} (s_n - s_k) - \sum_{k=0}^{m}(s_n - s_k) \right] \\
            &= \frac{1}{n-m} \left[ (n+1)\sigma_n - (m+1)\sigma_m \right] + \frac{1}{n-m} \sum_{k=m+1}^{n} (s_n - s_k) \\
            &= \frac{n+1}{n-m} \sigma_n - \frac{m+1}{n-m} \sigma_m + \frac{1}{n-m} \sum_{k=m+1}^{n} (s_n - s_k)
    \end{align*}
    so
    \begin{align*}
        s_n - \sigma_n &= \left( \frac{n+1}{n-m} - 1 \right) \sigma_n - \frac{m+1}{n-m} \sigma_n + \frac{1}{n-m} \sum_{k=m+1}^{n} (s_n - s_k) \\
            &= \frac{m+1}{n-m}(\sigma_n - \sigma_m) + \frac{1}{n-m} \sum_{i=m+1}^{n} (s_n - s_i),
    \end{align*}
    as required.
\end{proof}

\item For these $i$, 
\[
	|s_n - s_i| \le \frac{(n-i)M}{i+1} \le \frac{(n-m-1)M}{m+2}.
\]

\begin{proof}
    We can write $s_n - s_i$ as a telescoping sum of $a_n$:
    \begin{align*}
        |s_n - s_i| = \left|\sum_{k=i+1}^{n} (s_k - s_{k-1})\right| \overset{\Delta}{\le} \sum_{k=i+1}^{n} |a_k| \le \sum_{k=i+1}^{n} \frac{M}{i+1} = \frac{(n-i)M}{i+1}, 
    \end{align*}
    since we have $k \ge i+1$ and thus
    \[
        |a_k| \le \frac{M}{k} \le \frac{M}{i+1}.
    \]
    and the latter inequality follows immediately from the fact that $i \ge m+1$ in the previous part of the proof.
\end{proof}

\item Fix $\epsilon > 0$ and associate to every $n$ the integer $m$ such that
\[
	m \le \frac{n - \epsilon}{1 + \epsilon} < m + 1.
\]
Then $(m+1)/(n-m) \le 1/\epsilon$ and $|s_n - s_i| < M\epsilon$ so $\limsup_{n \to \infty} |s_n - \sigma| \le M\epsilon$ so the result follows.

\begin{proof}
    We have $m \le \frac{n-\epsilon}{1 + \epsilon}$, so $(m+1)/(n-m) \le 1/\epsilon$ follows from manipulation. Similarly, we have $\frac{n-m-1}{m+2} < \epsilon$. Thus, 
    \[
        |s_n - s_i| \le \frac{(n-m-1)M}{m+2} < M\epsilon
    \]
    and thus
    \[
        |s_n - \sigma_n| \overset{\Delta}{\le} \frac{m+1}{n-m} |\sigma_n - \sigma_m| + \frac{1}{n-m}|s_n - s_i| < M \epsilon
    \]
    for sufficiently large $m, n$ such that the first term vanishes (since $\sigma_n \to \sigma$). Thus 
    \[
        \limsup_{n \to \infty} |s_n - \sigma_n| \le M\epsilon,
    \]
    so $s_n$ converges to $\sigma$ since $\epsilon$ was arbitrary.
\end{proof}
\end{enumerate}
\end{enumerate}

\item % Exercise 15
Extend Definition 3.21 to points in $\R^k$. Show that Theorems 3.22, 3.23, 3.25(a), 3.33, 3.34, 3.42, 3.45, 3.47, 3.55 are true in this more general setting.

\begin{proof}
    Each proof is presented in a sufficiently general fashion such that replacing $|x - y|$ with the respective metric in $\R^k$ suffices to prove each theorem for infinite sums in $\R^k$.
\end{proof}

\item % Exercise 16
Fix $\alpha > 0$. Choose $x_1 > \sqrt{\alpha}$ and let
\[
	x_{n+1} = \frac{1}{2} \left(x_n + \frac{\alpha}{x_n}\right).
\]
\begin{enumerate}[(a)]
\item Prove that $\{x_n\}$ decreases monotonically and that $x_n \to \sqrt{\alpha}$.

\begin{proof}
    Notice that $x_n > \sqrt{\alpha}$ for each $n$ from the AM-GM inequality, and thus $\alpha/x_n < \sqrt{\alpha}$. Thus, $x_{n+1} < x_n$ and the sequence is monotonically decreasing and bounded below. Thus, it converges to some $L \ge \sqrt{\alpha}$. Then, notice that 
    \[
        L = \lim_{n \to \infty} x_{n+1} = \lim_{n \to \infty} \frac{1}{2} \left(x_n + \frac{\alpha}{x_n} \right) = \frac{1}{2} (L + \alpha/L)
    \]
    which has solutions $\pm \sqrt{\alpha}$, so $\lim_{n \to \infty} x_n = \sqrt{\alpha}$, as required.
\end{proof}

\item Put $\epsilon = x_n - \sqrt{\alpha}$ and show that
\[
	\epsilon_{n+1} = \frac{\epsilon_n^2}{2x_n} < \frac{\epsilon_n^2}{2\sqrt{\alpha}}
\]
so that if $\beta = 2\sqrt{\alpha}$,
\[
	\epsilon_{n+1} < \beta\left(\frac{\epsilon_1}{\beta}\right)^{2^n}.
\]

\begin{proof}
    We have
    \[
        \frac{\epsilon_n^2}{2x_n} = \frac{(x_n - \sqrt{\alpha})^2}{2x_n} = \frac{1}{2} \left( x_n - 2\sqrt{\alpha} + \frac{\alpha}{x_n} \right) = \frac{1}{2} \left( x_n + \frac{\alpha}{x_n} \right) - \sqrt{\alpha} = \epsilon_{n+1}.
    \]
    and the second part of the inequality follows from the fact proven in part (a) that $x_n > \sqrt{\alpha}$ for all $n$. The second fact follows inductively by the above statement.
\end{proof}

\item This presents a great algorithm for computing square roots. Show that if $\alpha = 3$ and $x_1 = 2$, that $\epsilon_1/\beta < 0.1$ so $\epsilon_5 < 4 \cdot 10^{-16}$ and $\epsilon_6 < 4 \cdot 10^{-32}$.

\begin{proof}
    We have $\beta = 2\sqrt{3}$ and $\epsilon_1 = 2 - \sqrt{3}$ so
    \[
        \frac{\epsilon_1}{\beta} = \frac{2 - \sqrt{3}}{2 \sqrt{3}} = \frac{4 - 3}{2 \sqrt{3} (2 + \sqrt{3})} < \frac{1}{10.5} < 0.1
    \]
    since $\sqrt{3} < 1.5$. Then $\epsilon_5 < \beta \cdot 10^{-2^4} < 4 \cdot 10^{-16}$ and similarly $\epsilon_6 < \beta \cdot 10^{-2^5} < 4 \cdot 10^{-32}$ as required.
\end{proof}
\end{enumerate}

\item % Exercise 17
Fix $\alpha > 1$ and take $x_1 > \sqrt{\alpha}$ and
\[
	x_{n+1} = \frac{\alpha + x_n}{1 + x_n} = x_n + \frac{\alpha - x_n^2}{1 + x_n}.
\]
\begin{enumerate}[(a)]
\item Prove that $x_1 > x_3 > x_5 > \dotsb$.
\item Prove that $x_2 < x_4 < x_6 < \dotsb$.
\begin{proof}
    Manipulating, we have
    \[
        x_{n+2} = \frac{\alpha + x_{n+1}}{1 + x_{n+1}} = \frac{(1 + x_n)(\alpha + x_{n+1})}{(1 + x_n)(1 + x_{n+1})} = \frac{\alpha + \alpha x_n + \alpha + x_n}{1 + x_n + \alpha + x_n} < x_n
    \]
    if and only if
    \[
        \alpha + \alpha x_n + \alpha + x_n < x_n + x_n^2 + \alpha x_n + x_n^2 \iff 0 < \alpha < x_n^2
    \]
    so it suffices to show that $x_{2k+1} > \sqrt{\alpha}$ and $x_{2k} < \sqrt{\alpha}$ inductively to conclude both results.

    Now, if $x_n > \sqrt{\alpha}$, then 
    \[
        x_{n+1} - x_n = \frac{\alpha - x_n^2}{1 + x_n} = (x_n - \sqrt{\alpha}) \frac{\sqrt{\alpha} + x_n}{1 + x_n} > x_n - \sqrt{\alpha}
    \]
    since $\sqrt{\alpha} > 1$. Then $x_{n+1} < \sqrt{\alpha}$. The argument is symmetric for the other condition, completing the proof.
\end{proof}

\item Prove that $x_n \to \sqrt{\alpha}$.
    \begin{proof}
        The subsequence $\{x_{2k+1}\}$ is decreasing and bounded below by $\sqrt{\alpha}$, and is thus convergent. It must converge to a value $L \ge \sqrt{\alpha}$ such that
        \[
            L = \lim_{n \to \infty} x_{n+2} = \lim_{n \to \infty} \frac{\alpha + x_n}{1 + x_n} = \frac{\alpha + L}{1 + L},
        \]
        whose solutions are $\pm \sqrt{\alpha}$. Thus, $L = \sqrt{\alpha}$.
    \end{proof}
\item Compare the rapidity of convergence of this process with the previous one.

\begin{proof}
    TODO: It converges slower, but I'm not able to show this...
\end{proof}
\end{enumerate}

\item % Exercise 18
Replace the recursive definition in Exercise 16 by
\[
	x_{n+1} = \frac{p-1}{p} x_n + \frac{1}{p} \cdot \frac{\alpha}{x_n^{p-1}}
\]
where $p$ is a fixed positive integer. Describe the behaviour of the resulting sequences $\{x_n\}$. 

\begin{proof}
    Notice that according to the definition, we must have $x_{n+1} \ge \sqrt[p]{\alpha}$ by the AM-GM inequality. Then let $x_1 > \sqrt[p]{\alpha}$ without loss of generality, then by a similar argument as above, $x_{n+1} < x_n$ so the sequence converges since it is monotonically decreasing and bounded below. It must converge to its unique fixed point at least $\sqrt[p]{\alpha}$, namely $x_n \to \sqrt[p]{\alpha}$.
\end{proof}

\item % Exercise 19
Associate to each sequence $a = \{\alpha_n\} \in \{0, 2\}^{\N}$ the real number
\[
	x(a) = \sum_{n=1}^{\infty} \frac{\alpha_n}{3^n}.
\]
Prove that the set of all $x(a)$ is the Cantor set.

\begin{proof}
    First, notice that for any real number $r \in [0, 1]$, we can associate a ternary representation $\{a_n\} \in \{0, 1, 2\}^{\N}$ such that $r = \sum_{n=0}^{\infty} a_n 3^{-n}$, so this question reduces to showing that $r$ is in the Cantor set iff it contains no 1s in its ternary representation.

    Notice that by construction, the middle thirds of each segment that we remove in the $i$-th iteration have a 1 as the $i$-th trit. So $\{0, 2\}^{\N} \supseteq C$. The converse follows again by noticing that any $r \in \{0, 2\}^{\N}$ is in each closed partial $C_n$, and thus in its infinite intersection $C$.
\end{proof}

\item % Exercise 20
Suppose $\{p_n\}$ is a Cauchy sequence in a metric space $X$ and some subsequence $\{p_{n_i}\}$ converges to a point $p \in X$. Prove that the full sequence $\{p_n\}$ converges to $p$.

\begin{proof}
    Let $\epsilon > 0$ be arbitrary and let $I \in \N$ such that $d(p_{n_i}, p) < \epsilon / 2$ for all $i \ge I$. Also, let $N \in \N$ such that for all $n \ge m \ge N$, we have $d(p_n, p_m) < \epsilon / 2$. Let $N_1$ be some $n_i$ for $i \ge I$ such that $n_i \ge N$. Then for all $n \ge N_1$, we have $d(p_n, p) \le d(p_n, p_{N_1}) + d(p_{n_I}, p) \le \epsilon$ so $p_n \to p$ as required.
\end{proof}

\item % Exercise 21
Prove the following analogue of Theorem 3.10(b): If $\{E_n\}$ is a sequence of closed non-empty and bounded sets in a \underline{complete} metric space $X$, if $E_n \supseteq E_{n+1}$, and if $\diam E_n \to 0$, then $\bigcap_{n=1}^{\infty} E_n$ contains a single point.

\item % Exercise 22
Suppose $X$ is a non-empty complete metric space, and $\{G_n\}$ is a sequence of dense open subsets of $X$. Prove Baire's theorem, namely that $\bigcap_{n=1}^{\infty} G_n$ is non-empty, and in fact dense in $X$.

\item % Exercise 23
Suppose $\{p_n\}, \{q_n\}$ are Cauchy sequences in a metric space $X$. Show that the sequence $\{d(p_n, q_n)\}$ converges.

\begin{proof}
    Let $\epsilon > 0$ be arbitrary. Let $N_p \in \N$ such that if $n \ge m \ge N_p$, then $d(p_n, p_m) < \epsilon / 2$. Define $N_q$ similarly. Then, for any $n \ge m \ge \max(N_p, N_q)$, we have
    \[
        d(p_n, q_n) \le d(p_m, q_m) + d(p_n, p_m) + d(q_n, q_m) < d(p_m, q_m) + \epsilon,
    \]
    and similarly $d(p_m, q_m) \le d(p_n, q_n) + \epsilon$, so $|d(p_n, q_n) - d(p_m, q_m)| < \epsilon$, so the sequence $\{d(p_n, q_n)\}$ is Cauchy in $\R$ and thus convergent since $\R$ is complete. 
\end{proof}

\item % Exercise 24
Let $X$ be a metric space.
\begin{enumerate}[(a)]
\item Call two Cauchy sequences $\{p_n\}, \{q_n\}$ \underline{equivalent} if $d(p_n, q_n) \to 0$. Show that this is an equivalence relation.

\begin{proof}
    Clearly $d(p_n, p_n) \to 0$ so $\{p_n\} \sim \{p_n\}$. Also, since $d(p_n, q_n) = d(q_n, p_n)$, the relation is symmetric. Finally, if $\{p_n\} \sim \{q_n\}$ and $\{q_n\} \sim \{r_n\}$, then $0 \le d(p_n, r_n) \le d(p_n, q_n) + d(q_n, r_n) \to 0$ converges to 0 by the comparison test. Thus the relation is transitive. These properties together make $\sim$ an equivalence relation on the Cauchy sequences in $X$.
\end{proof}

\item Let $X^*$ be the set of equivalence classes under the above relation. If $P, Q \in X^*$ and $\{p_n\} \in P$, $\{q_n\} \in Q$, define
\[
	\Delta(P, Q) = \lim_{n \to \infty} d(p_n, q_n),
\]
which exists from Exercise 23. Show that the number $\Delta(P, Q)$ is unchanged if we replace $\{p_n\}$ or $\{q_n\}$ by equivalent sequences, so that $\Delta$ is a distance function in $X^*$.

\begin{proof}
    Suppose $D = \Delta(P, Q) = \lim_{n \to \infty} d(p_n, q_n)$ for Cauchy sequences $\{p_n\} \in P$, $\{q_n\} \in Q$. Suppose that $\{r_n\} \in P$. Then, notice that
    \[  
        d(p_n, q_n) - d(p_n, r_n) \overset{\Delta}{\le} d(r_n, q_n) \overset{\Delta}{\le} d(p_n, r_n) + d(p_n, q_n)
    \]
    so $\lim_{n \to \infty} d(r_n, q_n) = D$ by the Squeeze theorem so we are done.
\end{proof}
\item Prove that the resulting metric space $X^*$ is complete.

\begin{proof}
    It is always true that convergent sequences are Cauchy. It suffices to show that Cauchy sequences in $X^*$ converge in $X^*$. Suppose that $\{P_n\}$ is Cauchy with respect to the distance metric $\Delta$. Define a sequence $\{y_n\}$ such that $y_n = p_{n,n}$. We claim that $\{y_n\}$ is Cauchy, and that $P_n \to \{y_n\}$.
   
    First, let $\epsilon > 0$ be arbitrary. Then, since $\{P_n\}$ is Cauchy with respect to $\Delta$, there exists some $N$ such that if $m \ge n \ge N$, then
    \[
        \Delta(P_n, P_m) = \lim_{k \to \infty} d(p_{n,k}, p_{m,k}) < \epsilon.
    \]
    In particular, there exists some $K$ such that $d(p_{n,k}, p_{m.k}) < \epsilon$ for all $k \ge K$ and $m,n \ge N$. Then, for all $k \ge \max(K, N)$, we have
    \[
        d(p_{n,k}, p_{k,k}) = d(p_{n,k}, y_k) < \epsilon
    \]
    so
    \[
        \Delta(P_n, Y) = \lim_{k \to \infty} d(p_{n, k}, y_k) \le \epsilon.
    \]
    Since $\epsilon$ was arbitrary, $P_n \to \{y_n\}$, as required.
\end{proof}
\item For each $p \in X$, there is a Cauchy sequence all of whose terms are $p$. Let $P_p$ be the element of $X^*$ which contains this sequence. Prove that
\[
	\Delta(P_p, P_q) = d(p, q)
\]
for all $p, q \in X$, so that $\phi: p \mapsto P_p$ is an \textbf{isometry} (a distance-preserving mapping) of $X$ onto $X^*$.

\begin{proof}
This is trivial if we take the representative sequence to be the constant sequence of $p$ and $q$: the limit is that of a constant sequence.
\end{proof}

\item Prove that $\phi(X)$ is dense in $X^*$, and that $\phi(X) = X^*$ if $X$ is complete. By (d), we may identify $X$ and $\phi(X)$ and thus regard $X$ as embedded in the complete metric space $X^*$. We call $X^*$ the \textbf{completion} of $X$
\end{enumerate}

\item % Exercise 25
Let $X$ be a metric space whose points are the rational numbers, with the metric $d(x, y) = |x - y|$. What is the completion of this space? (Compare Exercise 24).


\end{enumerate}


\chapter{TODOs}

\begin{enumerate}
\item Finish the proof for multiplicative inverses in Appendix 1
\item Exercise 1.20
\item Exercise 2.11
\item Exercise 3.7 has a weird $\le$ vs. $<$ problem. See if you can spot it.
\item Exercise 3.17d
\item Exercise 3.21
\item Exercise 3.22
\item Exercise 3.24c
\item Fix the theorem/example/etc. numbers so they match with Rudin
\end{enumerate}
\end{document}
